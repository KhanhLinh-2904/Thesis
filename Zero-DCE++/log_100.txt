Total training examples: 3546
Loss at iteration 50 : 0.7298251390457153
Loss at iteration 100 : 0.6863267421722412
Loss at iteration 150 : 0.45562314987182617
Loss at iteration 200 : 0.785631000995636
Loss at iteration 250 : 1.0392122268676758
Loss at iteration 300 : 0.8337559700012207
Loss at iteration 350 : 0.5485663414001465
Loss at iteration 400 : 1.083461880683899
Mean training loss eporch  0 :  0.7001407441456575
Loss at iteration 50 : 0.9294072389602661
Loss at iteration 100 : 0.5948376059532166
Loss at iteration 150 : 0.6681334972381592
Loss at iteration 200 : 0.6821856498718262
Loss at iteration 250 : 0.5303417444229126
Loss at iteration 300 : 0.9027861952781677
Loss at iteration 350 : 0.7260502576828003
Loss at iteration 400 : 0.6147858500480652
Mean training loss eporch  1 :  0.6606874711274564
Loss at iteration 50 : 0.7780474424362183
Loss at iteration 100 : 0.5344251990318298
Loss at iteration 150 : 0.5326517224311829
Loss at iteration 200 : 0.748424768447876
Loss at iteration 250 : 0.6795249581336975
Loss at iteration 300 : 0.6614084243774414
Loss at iteration 350 : 0.4779987633228302
Loss at iteration 400 : 0.5569747686386108
Mean training loss eporch  2 :  0.6553559052917335
Loss at iteration 50 : 0.39705270528793335
Loss at iteration 100 : 0.44060131907463074
Loss at iteration 150 : 0.2527032494544983
Loss at iteration 200 : 0.9397437572479248
Loss at iteration 250 : 0.5649048089981079
Loss at iteration 300 : 0.7413928508758545
Loss at iteration 350 : 0.5851167440414429
Loss at iteration 400 : 0.6209677457809448
Mean training loss eporch  3 :  0.6524690631273631
Loss at iteration 50 : 0.3685831129550934
Loss at iteration 100 : 0.8572621941566467
Loss at iteration 150 : 0.6235480308532715
Loss at iteration 200 : 0.9326460957527161
Loss at iteration 250 : 0.4007129669189453
Loss at iteration 300 : 0.6946989297866821
Loss at iteration 350 : 0.4235531687736511
Loss at iteration 400 : 0.7198532819747925
Mean training loss eporch  4 :  0.6504602267801225
Loss at iteration 50 : 0.4097995162010193
Loss at iteration 100 : 0.6449840068817139
Loss at iteration 150 : 0.7744548320770264
Loss at iteration 200 : 0.7005321979522705
Loss at iteration 250 : 0.30946749448776245
Loss at iteration 300 : 0.5556917786598206
Loss at iteration 350 : 1.181215524673462
Loss at iteration 400 : 0.2254122793674469
Mean training loss eporch  5 :  0.6479362003035374
Loss at iteration 50 : 0.7529853582382202
Loss at iteration 100 : 1.1177408695220947
Loss at iteration 150 : 0.9477272629737854
Loss at iteration 200 : 0.7976936101913452
Loss at iteration 250 : 0.5695047974586487
Loss at iteration 300 : 0.6667475700378418
Loss at iteration 350 : 1.0765800476074219
Loss at iteration 400 : 0.657710075378418
Mean training loss eporch  6 :  0.6463181386861179
Loss at iteration 50 : 0.5546549558639526
Loss at iteration 100 : 0.4398844838142395
Loss at iteration 150 : 0.5452561378479004
Loss at iteration 200 : 0.7052377462387085
Loss at iteration 250 : 0.6293971538543701
Loss at iteration 300 : 0.36767837405204773
Loss at iteration 350 : 0.8604714870452881
Loss at iteration 400 : 0.4324909448623657
Mean training loss eporch  7 :  0.6443066764119509
Loss at iteration 50 : 0.6727926731109619
Loss at iteration 100 : 0.3310859501361847
Loss at iteration 150 : 0.6869829297065735
Loss at iteration 200 : 0.8204513788223267
Loss at iteration 250 : 0.7351856827735901
Loss at iteration 300 : 0.7841787338256836
Loss at iteration 350 : 1.0908912420272827
Loss at iteration 400 : 0.6063929796218872
Mean training loss eporch  8 :  0.6422074748924723
Loss at iteration 50 : 0.6793148517608643
Loss at iteration 100 : 0.4657362699508667
Loss at iteration 150 : 0.4960240125656128
Loss at iteration 200 : 0.7522170543670654
Loss at iteration 250 : 0.4668004512786865
Loss at iteration 300 : 0.8423539400100708
Loss at iteration 350 : 1.1623414754867554
Loss at iteration 400 : 0.48200586438179016
Mean training loss eporch  9 :  0.6415860531096523
Loss at iteration 50 : 0.6843028664588928
Loss at iteration 100 : 0.43995535373687744
Loss at iteration 150 : 0.709531307220459
Loss at iteration 200 : 0.6895512342453003
Loss at iteration 250 : 0.6830164194107056
Loss at iteration 300 : 1.0793166160583496
Loss at iteration 350 : 0.6377687454223633
Loss at iteration 400 : 0.7780569791793823
Mean training loss eporch  10 :  0.6385398021152427
Loss at iteration 50 : 0.6887454986572266
Loss at iteration 100 : 0.6105524897575378
Loss at iteration 150 : 0.3613441288471222
Loss at iteration 200 : 0.6174875497817993
Loss at iteration 250 : 0.8295090794563293
Loss at iteration 300 : 0.9274177551269531
Loss at iteration 350 : 0.2891152501106262
Loss at iteration 400 : 0.7862341403961182
Mean training loss eporch  11 :  0.6354799232034533
Loss at iteration 50 : 0.8979381918907166
Loss at iteration 100 : 1.2151427268981934
Loss at iteration 150 : 0.48611658811569214
Loss at iteration 200 : 0.5719738006591797
Loss at iteration 250 : 0.7857654690742493
Loss at iteration 300 : 1.0750648975372314
Loss at iteration 350 : 0.45160964131355286
Loss at iteration 400 : 0.6169986128807068
Mean training loss eporch  12 :  0.6309506866980243
Loss at iteration 50 : 0.7072948217391968
Loss at iteration 100 : 0.6307804584503174
Loss at iteration 150 : 1.0536127090454102
Loss at iteration 200 : 0.8416765928268433
Loss at iteration 250 : 0.46555888652801514
Loss at iteration 300 : 0.6828239560127258
Loss at iteration 350 : 0.47654709219932556
Loss at iteration 400 : 0.6654525995254517
Mean training loss eporch  13 :  0.6267509817204497
Loss at iteration 50 : 0.7016682624816895
Loss at iteration 100 : 0.6464933753013611
Loss at iteration 150 : 0.9916974306106567
Loss at iteration 200 : 0.8986362218856812
Loss at iteration 250 : 0.7117810845375061
Loss at iteration 300 : 0.7243646383285522
Loss at iteration 350 : 0.8842666149139404
Loss at iteration 400 : 0.3338693380355835
Mean training loss eporch  14 :  0.6237826652422145
Loss at iteration 50 : 0.7045066356658936
Loss at iteration 100 : 0.4730987548828125
Loss at iteration 150 : 0.6729527711868286
Loss at iteration 200 : 0.6266472935676575
Loss at iteration 250 : 0.7127718925476074
Loss at iteration 300 : 0.7222809195518494
Loss at iteration 350 : 0.8402324318885803
Loss at iteration 400 : 0.27724775671958923
Mean training loss eporch  15 :  0.6197924014885683
Loss at iteration 50 : 0.5584251880645752
Loss at iteration 100 : 0.7704899907112122
Loss at iteration 150 : 0.9104390740394592
Loss at iteration 200 : 0.38517966866493225
Loss at iteration 250 : 0.7474518418312073
Loss at iteration 300 : 0.8853915333747864
Loss at iteration 350 : 0.6266939640045166
Loss at iteration 400 : 0.44871747493743896
Mean training loss eporch  16 :  0.6158596916241689
Loss at iteration 50 : 0.5848214030265808
Loss at iteration 100 : 0.3840710520744324
Loss at iteration 150 : 0.7385756969451904
Loss at iteration 200 : 0.667248547077179
Loss at iteration 250 : 0.7864171266555786
Loss at iteration 300 : 1.0788739919662476
Loss at iteration 350 : 0.43965598940849304
Loss at iteration 400 : 0.5977718830108643
Mean training loss eporch  17 :  0.6139839001939641
Loss at iteration 50 : 0.40426090359687805
Loss at iteration 100 : 0.8257771730422974
Loss at iteration 150 : 0.24211879074573517
Loss at iteration 200 : 0.8693782687187195
Loss at iteration 250 : 0.9107372760772705
Loss at iteration 300 : 0.7975114583969116
Loss at iteration 350 : 0.850814163684845
Loss at iteration 400 : 0.666303813457489
Mean training loss eporch  18 :  0.6101193625043642
Loss at iteration 50 : 0.32643288373947144
Loss at iteration 100 : 0.5509675145149231
Loss at iteration 150 : 0.7816121578216553
Loss at iteration 200 : 0.8161965608596802
Loss at iteration 250 : 0.7834184765815735
Loss at iteration 300 : 0.5197862386703491
Loss at iteration 350 : 0.5881819725036621
Loss at iteration 400 : 0.6895447969436646
Mean training loss eporch  19 :  0.6084700058642272
Loss at iteration 50 : 1.2211647033691406
Loss at iteration 100 : 0.26272279024124146
Loss at iteration 150 : 0.2788652777671814
Loss at iteration 200 : 0.29392245411872864
Loss at iteration 250 : 0.4938250184059143
Loss at iteration 300 : 0.7671187520027161
Loss at iteration 350 : 0.3622874319553375
Loss at iteration 400 : 0.34957370162010193
Mean training loss eporch  20 :  0.6056459805852658
Loss at iteration 50 : 0.5138983130455017
Loss at iteration 100 : 0.38454490900039673
Loss at iteration 150 : 0.6383087635040283
Loss at iteration 200 : 0.4770021438598633
Loss at iteration 250 : 0.42050492763519287
Loss at iteration 300 : 0.6103354692459106
Loss at iteration 350 : 0.9435381293296814
Loss at iteration 400 : 0.5901733636856079
Mean training loss eporch  21 :  0.6054380560914675
Loss at iteration 50 : 0.55011385679245
Loss at iteration 100 : 0.49423766136169434
Loss at iteration 150 : 0.39027562737464905
Loss at iteration 200 : 0.6367536783218384
Loss at iteration 250 : 0.4941169023513794
Loss at iteration 300 : 0.3642580509185791
Loss at iteration 350 : 0.7635737657546997
Loss at iteration 400 : 0.6575444340705872
Mean training loss eporch  22 :  0.6036182774214057
Loss at iteration 50 : 0.6654131412506104
Loss at iteration 100 : 0.7643059492111206
Loss at iteration 150 : 0.8007152080535889
Loss at iteration 200 : 0.2946118116378784
Loss at iteration 250 : 0.6278560757637024
Loss at iteration 300 : 0.5794360637664795
Loss at iteration 350 : 0.7432776689529419
Loss at iteration 400 : 0.7054515480995178
Mean training loss eporch  23 :  0.6024890812869007
Loss at iteration 50 : 0.44238990545272827
Loss at iteration 100 : 0.8356030583381653
Loss at iteration 150 : 0.7479192018508911
Loss at iteration 200 : 1.0580369234085083
Loss at iteration 250 : 0.509528636932373
Loss at iteration 300 : 0.6062386631965637
Loss at iteration 350 : 0.770864725112915
Loss at iteration 400 : 0.496273934841156
Mean training loss eporch  24 :  0.6017915457151495
Loss at iteration 50 : 0.5358701944351196
Loss at iteration 100 : 0.4910694360733032
Loss at iteration 150 : 0.5963351726531982
Loss at iteration 200 : 0.813738226890564
Loss at iteration 250 : 0.9704806208610535
Loss at iteration 300 : 0.8536989092826843
Loss at iteration 350 : 0.39667758345603943
Loss at iteration 400 : 0.7675817608833313
Mean training loss eporch  25 :  0.6025915255619062
Loss at iteration 50 : 0.6924477219581604
Loss at iteration 100 : 0.421714723110199
Loss at iteration 150 : 0.7410409450531006
Loss at iteration 200 : 0.5781279802322388
Loss at iteration 250 : 0.4093781113624573
Loss at iteration 300 : 0.42000117897987366
Loss at iteration 350 : 0.7565444707870483
Loss at iteration 400 : 0.4327479302883148
Mean training loss eporch  26 :  0.6009393308211017
Loss at iteration 50 : 0.5740207433700562
Loss at iteration 100 : 0.5158972144126892
Loss at iteration 150 : 0.7130298018455505
Loss at iteration 200 : 0.24444463849067688
Loss at iteration 250 : 0.4342232942581177
Loss at iteration 300 : 0.3132259249687195
Loss at iteration 350 : 0.4508152902126312
Loss at iteration 400 : 0.8388189077377319
Mean training loss eporch  27 :  0.6001477350254316
Loss at iteration 50 : 0.523880124092102
Loss at iteration 100 : 0.3946661949157715
Loss at iteration 150 : 0.5794436931610107
Loss at iteration 200 : 0.47948095202445984
Loss at iteration 250 : 0.5753861665725708
Loss at iteration 300 : 0.46868008375167847
Loss at iteration 350 : 0.20273831486701965
Loss at iteration 400 : 0.86216801404953
Mean training loss eporch  28 :  0.5985269179013936
Loss at iteration 50 : 0.7439863085746765
Loss at iteration 100 : 0.6242502927780151
Loss at iteration 150 : 0.51129150390625
Loss at iteration 200 : 0.5217829346656799
Loss at iteration 250 : 0.303710013628006
Loss at iteration 300 : 0.893619179725647
Loss at iteration 350 : 0.37640905380249023
Loss at iteration 400 : 0.4195939600467682
Mean training loss eporch  29 :  0.5981393113463849
Loss at iteration 50 : 0.2716691792011261
Loss at iteration 100 : 0.40138891339302063
Loss at iteration 150 : 0.6285577416419983
Loss at iteration 200 : 0.7464839816093445
