Total training examples: 3021
Loss at iteration 50 : 0.7794636487960815
Loss at iteration 100 : 0.873216986656189
Loss at iteration 150 : 1.2472152709960938
Loss at iteration 200 : 0.7092015743255615
Loss at iteration 250 : 1.4116365909576416
Loss at iteration 300 : 0.8432576656341553
Loss at iteration 350 : 1.0335646867752075
Mean training loss eporch  0 :  0.8957273934884046
Loss at iteration 50 : 0.8653112053871155
Loss at iteration 100 : 0.8581283688545227
Loss at iteration 150 : 1.0463746786117554
Loss at iteration 200 : 1.1019704341888428
Loss at iteration 250 : 0.7393521070480347
Loss at iteration 300 : 0.800657331943512
Loss at iteration 350 : 0.7324526309967041
Mean training loss eporch  1 :  0.8901246243683749
Loss at iteration 50 : 0.6472790241241455
Loss at iteration 100 : 1.317865252494812
Loss at iteration 150 : 0.9332157373428345
Loss at iteration 200 : 0.938365638256073
Loss at iteration 250 : 0.7784221172332764
Loss at iteration 300 : 0.8349669575691223
Loss at iteration 350 : 1.0885870456695557
Mean training loss eporch  2 :  0.8885069421674839
Loss at iteration 50 : 0.7226502895355225
Loss at iteration 100 : 0.8058530688285828
Loss at iteration 150 : 0.7949986457824707
Loss at iteration 200 : 0.9441774487495422
Loss at iteration 250 : 1.0657488107681274
Loss at iteration 300 : 0.6301436424255371
Loss at iteration 350 : 0.5452289581298828
Mean training loss eporch  3 :  0.8875658833791339
Loss at iteration 50 : 0.9722080230712891
Loss at iteration 100 : 0.6976748108863831
Loss at iteration 150 : 0.7406522035598755
Loss at iteration 200 : 1.1804454326629639
Loss at iteration 250 : 1.149208426475525
Loss at iteration 300 : 0.7463656663894653
Loss at iteration 350 : 1.2118244171142578
Mean training loss eporch  4 :  0.8868537163608289
Loss at iteration 50 : 1.2573875188827515
Loss at iteration 100 : 0.7931944131851196
Loss at iteration 150 : 0.7457660436630249
Loss at iteration 200 : 0.9323546886444092
Loss at iteration 250 : 0.8374686241149902
Loss at iteration 300 : 1.1052422523498535
Loss at iteration 350 : 0.8661730289459229
Mean training loss eporch  5 :  0.8839079072235754
Loss at iteration 50 : 1.0574108362197876
Loss at iteration 100 : 0.98680579662323
Loss at iteration 150 : 0.9360471963882446
Loss at iteration 200 : 0.6319857239723206
Loss at iteration 250 : 1.0916805267333984
Loss at iteration 300 : 0.8545563817024231
Loss at iteration 350 : 0.8542323112487793
Mean training loss eporch  6 :  0.8833626221727442
Loss at iteration 50 : 1.2574856281280518
Loss at iteration 100 : 0.7883250713348389
Loss at iteration 150 : 0.7451515197753906
Loss at iteration 200 : 0.810153067111969
Loss at iteration 250 : 0.9753267765045166
Loss at iteration 300 : 1.0075798034667969
Loss at iteration 350 : 1.0084865093231201
Mean training loss eporch  7 :  0.8818910695888378
Loss at iteration 50 : 0.668720006942749
Loss at iteration 100 : 1.080580234527588
Loss at iteration 150 : 0.6861061453819275
Loss at iteration 200 : 1.5161631107330322
Loss at iteration 250 : 0.687220573425293
Loss at iteration 300 : 0.5726385116577148
Loss at iteration 350 : 1.0400521755218506
Mean training loss eporch  8 :  0.8812442598519502
Loss at iteration 50 : 0.9225671291351318
Loss at iteration 100 : 0.6361338496208191
Loss at iteration 150 : 0.884798526763916
Loss at iteration 200 : 1.2549395561218262
Loss at iteration 250 : 0.7609949111938477
Loss at iteration 300 : 0.8032104969024658
Loss at iteration 350 : 1.1726707220077515
Mean training loss eporch  9 :  0.881058859446692
Loss at iteration 50 : 0.9723818898200989
Loss at iteration 100 : 0.6861831545829773
Loss at iteration 150 : 0.7483776807785034
Loss at iteration 200 : 1.1169301271438599
Loss at iteration 250 : 1.0540865659713745
Loss at iteration 300 : 0.7582294940948486
Loss at iteration 350 : 0.964491605758667
Mean training loss eporch  10 :  0.8798581675562278
Loss at iteration 50 : 0.805580198764801
Loss at iteration 100 : 0.688721776008606
Loss at iteration 150 : 0.9053968787193298
Loss at iteration 200 : 0.8087166547775269
Loss at iteration 250 : 0.6882288455963135
Loss at iteration 300 : 0.9711897373199463
Loss at iteration 350 : 0.7673696875572205
Mean training loss eporch  11 :  0.8785170764519424
Loss at iteration 50 : 0.753899335861206
Loss at iteration 100 : 0.8000905513763428
Loss at iteration 150 : 0.9530768394470215
Loss at iteration 200 : 0.923944354057312
Loss at iteration 250 : 0.9231330156326294
Loss at iteration 300 : 0.744140625
Loss at iteration 350 : 0.7729507684707642
Mean training loss eporch  12 :  0.878696202285706
Loss at iteration 50 : 1.2638185024261475
Loss at iteration 100 : 0.8053778409957886
Loss at iteration 150 : 0.5807033777236938
Loss at iteration 200 : 0.7362173795700073
Loss at iteration 250 : 0.8756181001663208
Loss at iteration 300 : 1.1476738452911377
Loss at iteration 350 : 0.719780445098877
Mean training loss eporch  13 :  0.8774005365434778
Loss at iteration 50 : 0.8552538156509399
Loss at iteration 100 : 1.450350046157837
Loss at iteration 150 : 1.0512489080429077
Loss at iteration 200 : 1.075967788696289
Loss at iteration 250 : 0.8613067865371704
Loss at iteration 300 : 0.8278994560241699
Loss at iteration 350 : 0.683810830116272
Mean training loss eporch  14 :  0.8763669111110546
Loss at iteration 50 : 1.097424030303955
Loss at iteration 100 : 0.8273677229881287
Loss at iteration 150 : 0.6663722991943359
Loss at iteration 200 : 0.6858188509941101
Loss at iteration 250 : 1.0389326810836792
Loss at iteration 300 : 0.7314276695251465
Loss at iteration 350 : 0.8671530485153198
Mean training loss eporch  15 :  0.8760214003305586
Loss at iteration 50 : 0.6791657209396362
Loss at iteration 100 : 0.6962579488754272
Loss at iteration 150 : 0.8217730522155762
Loss at iteration 200 : 0.7883598804473877
Loss at iteration 250 : 0.5981019735336304
Loss at iteration 300 : 0.9692250490188599
Loss at iteration 350 : 1.181381106376648
Mean training loss eporch  16 :  0.8750477502585718
Loss at iteration 50 : 1.0155510902404785
Loss at iteration 100 : 0.9789818525314331
Loss at iteration 150 : 0.9854502081871033
Loss at iteration 200 : 0.7094669342041016
Loss at iteration 250 : 0.8344917297363281
Loss at iteration 300 : 0.7977156639099121
Loss at iteration 350 : 0.6562012434005737
Mean training loss eporch  17 :  0.8741996740064923
Loss at iteration 50 : 0.9689602851867676
Loss at iteration 100 : 0.8965561389923096
Loss at iteration 150 : 0.8898212909698486
Loss at iteration 200 : 0.7532420754432678
Loss at iteration 250 : 0.8798221349716187
Loss at iteration 300 : 0.5919121503829956
Loss at iteration 350 : 0.854162871837616
Mean training loss eporch  18 :  0.8738291582102498
Loss at iteration 50 : 0.9693612456321716
Loss at iteration 100 : 0.9614677429199219
Loss at iteration 150 : 0.9214968681335449
Loss at iteration 200 : 0.7128198146820068
Loss at iteration 250 : 0.9344164729118347
Loss at iteration 300 : 0.828835666179657
Loss at iteration 350 : 0.687440037727356
Mean training loss eporch  19 :  0.8731200013841901
Loss at iteration 50 : 0.6232048273086548
Loss at iteration 100 : 0.8458974957466125
Loss at iteration 150 : 0.8047045469284058
Loss at iteration 200 : 0.8036431074142456
Loss at iteration 250 : 1.439455509185791
Loss at iteration 300 : 0.7159087061882019
Loss at iteration 350 : 1.1926180124282837
Mean training loss eporch  20 :  0.8732866100848667
Loss at iteration 50 : 0.8114110231399536
Loss at iteration 100 : 0.916700005531311
Loss at iteration 150 : 0.9687265157699585
Loss at iteration 200 : 0.7694729566574097
Loss at iteration 250 : 0.7849025726318359
Loss at iteration 300 : 0.732207179069519
Loss at iteration 350 : 0.7987525463104248
Mean training loss eporch  21 :  0.872508463090059
Loss at iteration 50 : 1.3464312553405762
Loss at iteration 100 : 0.7048936486244202
Loss at iteration 150 : 0.6485320329666138
Loss at iteration 200 : 0.7997969388961792
Loss at iteration 250 : 1.219081163406372
Loss at iteration 300 : 1.067827582359314
Loss at iteration 350 : 0.6662490367889404
Mean training loss eporch  22 :  0.8718943040837687
Loss at iteration 50 : 1.2337217330932617
Loss at iteration 100 : 0.8834881782531738
Loss at iteration 150 : 1.0799641609191895
Loss at iteration 200 : 0.8746449947357178
Loss at iteration 250 : 0.8169734477996826
Loss at iteration 300 : 0.661125659942627
Loss at iteration 350 : 0.8858255743980408
Mean training loss eporch  23 :  0.8711006880279571
Loss at iteration 50 : 0.7502685785293579
Loss at iteration 100 : 0.8827177882194519
Loss at iteration 150 : 0.778962254524231
Loss at iteration 200 : 0.7133771181106567
Loss at iteration 250 : 0.7251767516136169
Loss at iteration 300 : 0.8541923761367798
Loss at iteration 350 : 0.9631997346878052
Mean training loss eporch  24 :  0.8705502183979781
Loss at iteration 50 : 0.9123611450195312
Loss at iteration 100 : 1.092177152633667
Loss at iteration 150 : 0.7895359992980957
Loss at iteration 200 : 0.6119906306266785
Loss at iteration 250 : 0.8236226439476013
Loss at iteration 300 : 1.0732864141464233
Loss at iteration 350 : 0.7448418140411377
Mean training loss eporch  25 :  0.8704994740309538
Loss at iteration 50 : 0.8177885413169861
Loss at iteration 100 : 0.8696231245994568
Loss at iteration 150 : 0.9056276082992554
Loss at iteration 200 : 0.6595165729522705
Loss at iteration 250 : 1.0750263929367065
Loss at iteration 300 : 1.1337696313858032
Loss at iteration 350 : 0.9598364233970642
Mean training loss eporch  26 :  0.8696527312356959
Loss at iteration 50 : 0.7648124694824219
Loss at iteration 100 : 0.9673882126808167
Loss at iteration 150 : 0.694596529006958
Loss at iteration 200 : 1.0858491659164429
Loss at iteration 250 : 0.891551673412323
Loss at iteration 300 : 1.2823106050491333
Loss at iteration 350 : 0.9690393209457397
Mean training loss eporch  27 :  0.8698587487772028
Loss at iteration 50 : 0.8410210609436035
Loss at iteration 100 : 0.6098805069923401
Loss at iteration 150 : 1.1038223505020142
Loss at iteration 200 : 1.0094761848449707
Loss at iteration 250 : 0.6720327734947205
Loss at iteration 300 : 0.598393440246582
Loss at iteration 350 : 0.870126485824585
Mean training loss eporch  28 :  0.8704733348712719
Loss at iteration 50 : 1.2619582414627075
Loss at iteration 100 : 1.1249079704284668
Loss at iteration 150 : 1.0380834341049194
Loss at iteration 200 : 0.8538389205932617
Loss at iteration 250 : 0.7694439888000488
Loss at iteration 300 : 0.817816436290741
Loss at iteration 350 : 0.8905340433120728
Mean training loss eporch  29 :  0.8677965957651693
Loss at iteration 50 : 0.9234611988067627
Loss at iteration 100 : 0.5971434712409973
Loss at iteration 150 : 0.7424107789993286
Loss at iteration 200 : 1.0074890851974487
Loss at iteration 250 : 0.6997835636138916
Loss at iteration 300 : 0.7330431938171387
Loss at iteration 350 : 0.9915432333946228
Mean training loss eporch  30 :  0.869179529960824
Loss at iteration 50 : 0.9123532772064209
Loss at iteration 100 : 1.1339012384414673
Loss at iteration 150 : 0.7416864633560181
Loss at iteration 200 : 0.7339662313461304
Loss at iteration 250 : 1.4939830303192139
Loss at iteration 300 : 0.9196912050247192
Loss at iteration 350 : 0.6457350254058838
Mean training loss eporch  31 :  0.8679789168336404
Loss at iteration 50 : 0.6668825149536133
Loss at iteration 100 : 0.8000341653823853
Loss at iteration 150 : 0.9634687304496765
Loss at iteration 200 : 0.9189135432243347
Loss at iteration 250 : 0.8333134651184082
Loss at iteration 300 : 0.9858765006065369
Loss at iteration 350 : 1.0247868299484253
Mean training loss eporch  32 :  0.867440902997577
Loss at iteration 50 : 0.7538658380508423
Loss at iteration 100 : 0.8330389261245728
Loss at iteration 150 : 0.8430382013320923
Loss at iteration 200 : 1.0126886367797852
Loss at iteration 250 : 0.9403654932975769
Loss at iteration 300 : 0.5333764553070068
Loss at iteration 350 : 0.8274731040000916
Mean training loss eporch  33 :  0.8664173491732784
Loss at iteration 50 : 0.848179817199707
Loss at iteration 100 : 0.7273448705673218
Loss at iteration 150 : 0.8622303605079651
Loss at iteration 200 : 0.8343168497085571
Loss at iteration 250 : 0.7495613098144531
Loss at iteration 300 : 0.5836508870124817
Loss at iteration 350 : 0.8966587781906128
Mean training loss eporch  34 :  0.8665064201153144
Loss at iteration 50 : 0.7353794574737549
Loss at iteration 100 : 0.7314591407775879
Loss at iteration 150 : 0.8424811363220215
Loss at iteration 200 : 0.6527904272079468
Loss at iteration 250 : 0.8639357686042786
Loss at iteration 300 : 0.9667204022407532
Loss at iteration 350 : 0.6873457431793213
Mean training loss eporch  35 :  0.8659559155582751
Loss at iteration 50 : 0.6522229909896851
Loss at iteration 100 : 0.7684862613677979
Loss at iteration 150 : 0.48636364936828613
Loss at iteration 200 : 0.8799533247947693
Loss at iteration 250 : 0.8478448390960693
Loss at iteration 300 : 1.1268062591552734
Loss at iteration 350 : 0.7150283455848694
Mean training loss eporch  36 :  0.8668503048558714
Loss at iteration 50 : 0.6842010617256165
Loss at iteration 100 : 0.8334429264068604
Loss at iteration 150 : 1.1377354860305786
Loss at iteration 200 : 0.7890720367431641
Loss at iteration 250 : 0.9416484832763672
Loss at iteration 300 : 1.1764600276947021
Loss at iteration 350 : 0.8329708576202393
Mean training loss eporch  37 :  0.8664371866397756
Loss at iteration 50 : 0.79190593957901
Loss at iteration 100 : 0.8401314616203308
Loss at iteration 150 : 1.2438437938690186
Loss at iteration 200 : 0.8917046785354614
Loss at iteration 250 : 1.016998291015625
Loss at iteration 300 : 0.7750844955444336
Loss at iteration 350 : 0.627423882484436
Mean training loss eporch  38 :  0.864648178062111
Loss at iteration 50 : 1.021346926689148
Loss at iteration 100 : 0.8615540266036987
Loss at iteration 150 : 0.8944811820983887
Loss at iteration 200 : 0.7116659283638
Loss at iteration 250 : 0.9707294702529907
Loss at iteration 300 : 1.0711308717727661
Loss at iteration 350 : 0.9326164722442627
Mean training loss eporch  39 :  0.8653821897885156
Loss at iteration 50 : 0.7141492366790771
Loss at iteration 100 : 1.0325769186019897
Loss at iteration 150 : 0.6219254732131958
Loss at iteration 200 : 0.873338520526886
Loss at iteration 250 : 0.7773923873901367
Loss at iteration 300 : 0.8602628707885742
Loss at iteration 350 : 0.9199858903884888
Mean training loss eporch  40 :  0.864834114278435
Loss at iteration 50 : 1.0784380435943604
Loss at iteration 100 : 0.7219067811965942
Loss at iteration 150 : 1.0574876070022583
Loss at iteration 200 : 0.997268557548523
Loss at iteration 250 : 1.1315529346466064
Loss at iteration 300 : 0.6898791193962097
Loss at iteration 350 : 0.9546396732330322
Mean training loss eporch  41 :  0.8646060562638379
Loss at iteration 50 : 1.0198349952697754
Loss at iteration 100 : 0.937068521976471
Loss at iteration 150 : 0.784832239151001
Loss at iteration 200 : 0.7959214448928833
Loss at iteration 250 : 0.590896725654602
Loss at iteration 300 : 0.7770533561706543
Loss at iteration 350 : 1.1134873628616333
Mean training loss eporch  42 :  0.8636649925872762
Loss at iteration 50 : 0.9165029525756836
Loss at iteration 100 : 1.128880500793457
Loss at iteration 150 : 0.8037838935852051
Loss at iteration 200 : 1.0167280435562134
Loss at iteration 250 : 1.0715115070343018
Loss at iteration 300 : 0.811897873878479
Loss at iteration 350 : 0.7734021544456482
Mean training loss eporch  43 :  0.8633439868846268
Loss at iteration 50 : 0.8539004325866699
Loss at iteration 100 : 1.0716956853866577
Loss at iteration 150 : 0.7139658331871033
Loss at iteration 200 : 0.7723948359489441
Loss at iteration 250 : 0.970587968826294
Loss at iteration 300 : 0.9391902685165405
Loss at iteration 350 : 0.7611058354377747
Mean training loss eporch  44 :  0.8630122700065532
Loss at iteration 50 : 0.7953757047653198
Loss at iteration 100 : 0.8349977135658264
Loss at iteration 150 : 0.9623419046401978
Loss at iteration 200 : 0.6587267518043518
Loss at iteration 250 : 0.7253999710083008
Loss at iteration 300 : 0.9387633800506592
Loss at iteration 350 : 0.7449659109115601
Mean training loss eporch  45 :  0.8636176354355283
Loss at iteration 50 : 0.8260917067527771
Loss at iteration 100 : 0.7718087434768677
Loss at iteration 150 : 0.912542998790741
Loss at iteration 200 : 1.013288974761963
Loss at iteration 250 : 0.8547692894935608
Loss at iteration 300 : 0.8914264440536499
Loss at iteration 350 : 1.2216675281524658
Mean training loss eporch  46 :  0.8628027730833285
Loss at iteration 50 : 0.9745250344276428
Loss at iteration 100 : 0.8667716979980469
Loss at iteration 150 : 0.9747077822685242
Loss at iteration 200 : 0.8053226470947266
Loss at iteration 250 : 0.8134732842445374
Loss at iteration 300 : 0.7373723983764648
Loss at iteration 350 : 0.68926602602005
Mean training loss eporch  47 :  0.8625156588497616
Loss at iteration 50 : 0.9786088466644287
Loss at iteration 100 : 1.142869234085083
Loss at iteration 150 : 0.72248375415802
Loss at iteration 200 : 1.3489205837249756
Loss at iteration 250 : 1.0893566608428955
Loss at iteration 300 : 0.5708715915679932
Loss at iteration 350 : 0.9828667044639587
Mean training loss eporch  48 :  0.8616735354144737
Loss at iteration 50 : 0.70570969581604
Loss at iteration 100 : 0.8990343809127808
Loss at iteration 150 : 0.838925838470459
Loss at iteration 200 : 0.6841604709625244
Loss at iteration 250 : 0.9896880984306335
Loss at iteration 300 : 1.002888560295105
Loss at iteration 350 : 0.7618628144264221
Mean training loss eporch  49 :  0.8633927087146769
Loss at iteration 50 : 0.6501097083091736
Loss at iteration 100 : 1.1661396026611328
Loss at iteration 150 : 0.8119843006134033
Loss at iteration 200 : 0.8025380969047546
Loss at iteration 250 : 0.7657387852668762
Loss at iteration 300 : 0.7367221117019653
Loss at iteration 350 : 0.9370483160018921
Mean training loss eporch  50 :  0.8621697383267539
Loss at iteration 50 : 1.0275208950042725
Loss at iteration 100 : 0.841748833656311
Loss at iteration 150 : 0.6746708154678345
Loss at iteration 200 : 0.7820645570755005
Loss at iteration 250 : 0.6958972215652466
Loss at iteration 300 : 0.8150498867034912
Loss at iteration 350 : 0.7652619481086731
Mean training loss eporch  51 :  0.8624329237395494
Loss at iteration 50 : 0.9126718044281006
Loss at iteration 100 : 0.709205687046051
Loss at iteration 150 : 1.1473642587661743
Loss at iteration 200 : 0.6275947093963623
Loss at iteration 250 : 1.1434051990509033
Loss at iteration 300 : 0.9029878377914429
Loss at iteration 350 : 0.7260361909866333
Mean training loss eporch  52 :  0.8608508072202168
Loss at iteration 50 : 1.0055160522460938
Loss at iteration 100 : 0.8983027935028076
Loss at iteration 150 : 0.7369210720062256
Loss at iteration 200 : 0.9344007968902588
Loss at iteration 250 : 0.9537533521652222
Loss at iteration 300 : 0.927449643611908
Loss at iteration 350 : 0.8939263820648193
Mean training loss eporch  53 :  0.8612357132018559
Loss at iteration 50 : 0.8338961601257324
Loss at iteration 100 : 0.8457533121109009
Loss at iteration 150 : 0.666487455368042
Loss at iteration 200 : 0.8823111057281494
Loss at iteration 250 : 0.7998067140579224
Loss at iteration 300 : 0.7259378433227539
Loss at iteration 350 : 0.9281129837036133
Mean training loss eporch  54 :  0.8607200866653806
Loss at iteration 50 : 0.9053675532341003
Loss at iteration 100 : 1.0403939485549927
Loss at iteration 150 : 1.013994574546814
Loss at iteration 200 : 0.7897204160690308
Loss at iteration 250 : 0.9817497134208679
Loss at iteration 300 : 0.8679081201553345
Loss at iteration 350 : 0.8968112468719482
Mean training loss eporch  55 :  0.8616246611037582
Loss at iteration 50 : 1.0331840515136719
Loss at iteration 100 : 0.7774236798286438
Loss at iteration 150 : 0.5985100269317627
Loss at iteration 200 : 0.5746700763702393
Loss at iteration 250 : 0.981052041053772
Loss at iteration 300 : 1.035998821258545
Loss at iteration 350 : 1.0110893249511719
Mean training loss eporch  56 :  0.8611457417250941
Loss at iteration 50 : 1.040425419807434
Loss at iteration 100 : 0.7303152084350586
Loss at iteration 150 : 0.7073972821235657
Loss at iteration 200 : 0.9770973324775696
Loss at iteration 250 : 0.7730697393417358
Loss at iteration 300 : 0.8042845129966736
Loss at iteration 350 : 0.6238099336624146
Mean training loss eporch  57 :  0.8610153567223322
Loss at iteration 50 : 0.7772659063339233
Loss at iteration 100 : 0.5337153077125549
Loss at iteration 150 : 0.9044903516769409
Loss at iteration 200 : 0.8613890409469604
Loss at iteration 250 : 0.9678502678871155
Loss at iteration 300 : 0.6412957310676575
Loss at iteration 350 : 0.49537193775177
Mean training loss eporch  58 :  0.8609403640662552
Loss at iteration 50 : 0.7557973861694336
Loss at iteration 100 : 0.8168513774871826
Loss at iteration 150 : 0.799323320388794
Loss at iteration 200 : 0.9028327465057373
Loss at iteration 250 : 1.3941552639007568
Loss at iteration 300 : 0.6405321359634399
Loss at iteration 350 : 1.0623180866241455
Mean training loss eporch  59 :  0.8610276653968468
Loss at iteration 50 : 0.6749656796455383
Loss at iteration 100 : 0.7649451494216919
Loss at iteration 150 : 0.7560911178588867
Loss at iteration 200 : 0.953350305557251
Loss at iteration 250 : 0.8764693737030029
Loss at iteration 300 : 0.7735946178436279
Loss at iteration 350 : 0.8862613439559937
Mean training loss eporch  60 :  0.86012795362523
Loss at iteration 50 : 0.8282644748687744
Loss at iteration 100 : 0.7867714762687683
Loss at iteration 150 : 0.8121346831321716
Loss at iteration 200 : 0.8752281665802002
Loss at iteration 250 : 0.9901054501533508
Loss at iteration 300 : 1.4268046617507935
Loss at iteration 350 : 1.091844916343689
Mean training loss eporch  61 :  0.8588797537580369
Loss at iteration 50 : 1.024085521697998
Loss at iteration 100 : 1.0048863887786865
Loss at iteration 150 : 0.7208297252655029
Loss at iteration 200 : 0.729101300239563
Loss at iteration 250 : 1.2364449501037598
Loss at iteration 300 : 0.7733299732208252
Loss at iteration 350 : 1.0747816562652588
Mean training loss eporch  62 :  0.8596824811249183
Loss at iteration 50 : 0.9872285723686218
Loss at iteration 100 : 0.7833915948867798
Loss at iteration 150 : 0.7106623649597168
Loss at iteration 200 : 0.5728048086166382
Loss at iteration 250 : 0.6981819868087769
Loss at iteration 300 : 0.8392506837844849
Loss at iteration 350 : 0.791434645652771
Mean training loss eporch  63 :  0.8597373922981283
Loss at iteration 50 : 0.8980609178543091
Loss at iteration 100 : 0.8869462609291077
Loss at iteration 150 : 1.0085511207580566
Loss at iteration 200 : 0.9470978379249573
Loss at iteration 250 : 0.77321857213974
Loss at iteration 300 : 0.8708821535110474
Loss at iteration 350 : 0.9619004130363464
Mean training loss eporch  64 :  0.8592461707888457
Loss at iteration 50 : 0.8753210306167603
Loss at iteration 100 : 0.9921702146530151
Loss at iteration 150 : 0.7786316871643066
Loss at iteration 200 : 0.929207444190979
Loss at iteration 250 : 0.8490291833877563
Loss at iteration 300 : 0.8042247891426086
Loss at iteration 350 : 0.6352670192718506
Mean training loss eporch  65 :  0.8595795689751862
Loss at iteration 50 : 0.8258010149002075
Loss at iteration 100 : 0.9487899541854858
Loss at iteration 150 : 0.6004075407981873
Loss at iteration 200 : 0.7547132968902588
Loss at iteration 250 : 1.0188579559326172
Loss at iteration 300 : 0.9585302472114563
Loss at iteration 350 : 0.7359125018119812
Mean training loss eporch  66 :  0.8586421628635397
Loss at iteration 50 : 1.515337347984314
Loss at iteration 100 : 0.7967792749404907
Loss at iteration 150 : 1.2341545820236206
Loss at iteration 200 : 0.8795958757400513
Loss at iteration 250 : 1.0394400358200073
Loss at iteration 300 : 0.8636265993118286
Loss at iteration 350 : 0.713140606880188
Mean training loss eporch  67 :  0.8584678103684118
Loss at iteration 50 : 0.903136670589447
Loss at iteration 100 : 1.0191359519958496
Loss at iteration 150 : 0.9934949278831482
Loss at iteration 200 : 0.9616207480430603
Loss at iteration 250 : 0.7438113689422607
Loss at iteration 300 : 1.0468192100524902
Loss at iteration 350 : 0.7549023628234863
Mean training loss eporch  68 :  0.8583141015793281
Loss at iteration 50 : 0.9287086129188538
Loss at iteration 100 : 0.9559087753295898
Loss at iteration 150 : 0.989925742149353
Loss at iteration 200 : 0.9200918674468994
Loss at iteration 250 : 0.8357712626457214
Loss at iteration 300 : 0.7976847887039185
Loss at iteration 350 : 0.8216074109077454
Mean training loss eporch  69 :  0.8584042057473823
Loss at iteration 50 : 0.8590413928031921
Loss at iteration 100 : 1.0952322483062744
Loss at iteration 150 : 0.5869647264480591
Loss at iteration 200 : 0.871371865272522
Loss at iteration 250 : 0.9599810838699341
Loss at iteration 300 : 0.8319635987281799
Loss at iteration 350 : 0.7731785774230957
Mean training loss eporch  70 :  0.8587027119581031
Loss at iteration 50 : 1.2412409782409668
Loss at iteration 100 : 0.9052637815475464
Loss at iteration 150 : 0.6091245412826538
Loss at iteration 200 : 0.6038941144943237
Loss at iteration 250 : 0.7471439838409424
Loss at iteration 300 : 0.6042881608009338
Loss at iteration 350 : 0.7217751741409302
Mean training loss eporch  71 :  0.8583267264107548
Loss at iteration 50 : 0.7418681383132935
Loss at iteration 100 : 0.6596587896347046
Loss at iteration 150 : 0.8982943892478943
Loss at iteration 200 : 1.0312083959579468
Loss at iteration 250 : 0.8803210258483887
Loss at iteration 300 : 0.6474897265434265
Loss at iteration 350 : 0.7663768529891968
Mean training loss eporch  72 :  0.858129267812406
Loss at iteration 50 : 1.0470361709594727
Loss at iteration 100 : 0.8980156779289246
Loss at iteration 150 : 0.9913332462310791
Loss at iteration 200 : 0.5932385921478271
Loss at iteration 250 : 0.7187869548797607
Loss at iteration 300 : 0.7277275919914246
Loss at iteration 350 : 0.8829434514045715
Mean training loss eporch  73 :  0.857774391218468
Loss at iteration 50 : 0.8522178530693054
Loss at iteration 100 : 0.7467981576919556
Loss at iteration 150 : 0.8170826435089111
Loss at iteration 200 : 0.5486029386520386
Loss at iteration 250 : 0.7439731359481812
Loss at iteration 300 : 0.8870258331298828
Loss at iteration 350 : 0.8375629186630249
Mean training loss eporch  74 :  0.8585842751636708
Loss at iteration 50 : 0.8647458553314209
Loss at iteration 100 : 0.9022004008293152
Loss at iteration 150 : 0.947261393070221
Loss at iteration 200 : 1.0456587076187134
Loss at iteration 250 : 0.7636945247650146
Loss at iteration 300 : 0.8699029088020325
Loss at iteration 350 : 0.66856849193573
Mean training loss eporch  75 :  0.8572324254210033
Loss at iteration 50 : 0.625368595123291
Loss at iteration 100 : 1.003735899925232
Loss at iteration 150 : 0.9641473293304443
Loss at iteration 200 : 0.6031059622764587
Loss at iteration 250 : 0.9984319806098938
Loss at iteration 300 : 0.9666982889175415
Loss at iteration 350 : 0.8325384855270386
Mean training loss eporch  76 :  0.857703021436772
Loss at iteration 50 : 0.6452740430831909
Loss at iteration 100 : 0.7104386687278748
Loss at iteration 150 : 0.937909722328186
Loss at iteration 200 : 0.8072946071624756
Loss at iteration 250 : 0.6058694124221802
Loss at iteration 300 : 1.024075984954834
Loss at iteration 350 : 0.7095016241073608
Mean training loss eporch  77 :  0.8584780186887772
Loss at iteration 50 : 0.8612788915634155
Loss at iteration 100 : 0.5632520914077759
Loss at iteration 150 : 1.0138506889343262
Loss at iteration 200 : 0.919059157371521
Loss at iteration 250 : 0.7912216186523438
Loss at iteration 300 : 0.7130134105682373
Loss at iteration 350 : 0.9331308007240295
Mean training loss eporch  78 :  0.8566377041516481
Loss at iteration 50 : 0.6612239480018616
Loss at iteration 100 : 0.6843029260635376
Loss at iteration 150 : 0.6437851786613464
Loss at iteration 200 : 0.8191677331924438
Loss at iteration 250 : 1.0442392826080322
Loss at iteration 300 : 1.0795385837554932
Loss at iteration 350 : 0.8746281266212463
Mean training loss eporch  79 :  0.8568024649506524
Loss at iteration 50 : 0.8405335545539856
Loss at iteration 100 : 0.9643666744232178
Loss at iteration 150 : 0.7080782651901245
Loss at iteration 200 : 0.7969259023666382
Loss at iteration 250 : 0.6783494353294373
Loss at iteration 300 : 0.9536349773406982
Loss at iteration 350 : 0.7438901662826538
Mean training loss eporch  80 :  0.8569242952677308
Loss at iteration 50 : 0.6440996527671814
Loss at iteration 100 : 0.8806976079940796
Loss at iteration 150 : 0.8109328746795654
Loss at iteration 200 : 0.8130315542221069
Loss at iteration 250 : 0.8881287574768066
Loss at iteration 300 : 0.8207617998123169
Loss at iteration 350 : 0.8471965789794922
Mean training loss eporch  81 :  0.8576853283971706
Loss at iteration 50 : 0.942462682723999
Loss at iteration 100 : 1.002163290977478
Loss at iteration 150 : 0.9843239188194275
Loss at iteration 200 : 0.9038830995559692
Loss at iteration 250 : 0.8727006912231445
Loss at iteration 300 : 1.1265437602996826
Loss at iteration 350 : 1.17737877368927
Mean training loss eporch  82 :  0.8580225696639409
Loss at iteration 50 : 1.0312579870224
Loss at iteration 100 : 0.8587886095046997
Loss at iteration 150 : 0.9040230512619019
Loss at iteration 200 : 1.0011086463928223
Loss at iteration 250 : 1.3221255540847778
Loss at iteration 300 : 0.7713168263435364
Loss at iteration 350 : 0.7988662719726562
Mean training loss eporch  83 :  0.8566328690796302
Loss at iteration 50 : 0.8224526047706604
Loss at iteration 100 : 0.9986149668693542
Loss at iteration 150 : 1.0669136047363281
Loss at iteration 200 : 0.7858959436416626
Loss at iteration 250 : 0.6624858379364014
Loss at iteration 300 : 0.9541938900947571
Loss at iteration 350 : 0.9104893803596497
Mean training loss eporch  84 :  0.8561103742116343
Loss at iteration 50 : 0.8746487498283386
Loss at iteration 100 : 1.0604026317596436
Loss at iteration 150 : 1.003309726715088
Loss at iteration 200 : 0.7054683566093445
Loss at iteration 250 : 1.0469108819961548
Loss at iteration 300 : 0.6734753847122192
Loss at iteration 350 : 0.802819550037384
Mean training loss eporch  85 :  0.8560390563868971
Loss at iteration 50 : 0.708209216594696
Loss at iteration 100 : 0.7649844288825989
Loss at iteration 150 : 0.7375725507736206
Loss at iteration 200 : 0.7973752617835999
Loss at iteration 250 : 0.570928156375885
Loss at iteration 300 : 0.8075905442237854
Loss at iteration 350 : 0.785668671131134
Mean training loss eporch  86 :  0.8560329336653311
Loss at iteration 50 : 0.7677469253540039
Loss at iteration 100 : 1.0413823127746582
Loss at iteration 150 : 0.8905395865440369
Loss at iteration 200 : 0.9359791278839111
Loss at iteration 250 : 0.6888726949691772
Loss at iteration 300 : 1.0101854801177979
Loss at iteration 350 : 0.8696922063827515
Mean training loss eporch  87 :  0.8569051405740162
Loss at iteration 50 : 0.9869356155395508
Loss at iteration 100 : 0.905684232711792
Loss at iteration 150 : 0.9616130590438843
Loss at iteration 200 : 0.6620373725891113
Loss at iteration 250 : 0.8477909564971924
Loss at iteration 300 : 0.8732864856719971
Loss at iteration 350 : 0.8516037464141846
Mean training loss eporch  88 :  0.8560111462754547
Loss at iteration 50 : 1.2052024602890015
Loss at iteration 100 : 0.8914985060691833
Loss at iteration 150 : 1.1037571430206299
Loss at iteration 200 : 0.7568347454071045
Loss at iteration 250 : 0.8095890283584595
Loss at iteration 300 : 0.7260606288909912
Loss at iteration 350 : 1.2522133588790894
Mean training loss eporch  89 :  0.8555193655389958
Loss at iteration 50 : 1.1041874885559082
Loss at iteration 100 : 0.9878319501876831
Loss at iteration 150 : 1.0448087453842163
Loss at iteration 200 : 0.821873664855957
Loss at iteration 250 : 0.8076949119567871
Loss at iteration 300 : 0.8448231220245361
Loss at iteration 350 : 0.9510642886161804
Mean training loss eporch  90 :  0.8554534185973425
Loss at iteration 50 : 1.1765152215957642
Loss at iteration 100 : 0.7137835621833801
Loss at iteration 150 : 1.181924819946289
Loss at iteration 200 : 0.8563767671585083
Loss at iteration 250 : 0.7941461801528931
Loss at iteration 300 : 0.8542118072509766
Loss at iteration 350 : 0.6940701007843018
Mean training loss eporch  91 :  0.8555494050184885
Loss at iteration 50 : 1.0669658184051514
Loss at iteration 100 : 0.9645165205001831
Loss at iteration 150 : 0.6991733312606812
Loss at iteration 200 : 0.7385031580924988
Loss at iteration 250 : 0.7517906427383423
Loss at iteration 300 : 0.5867593288421631
Loss at iteration 350 : 0.9045525789260864
Mean training loss eporch  92 :  0.85563044604801
Loss at iteration 50 : 0.5899598002433777
Loss at iteration 100 : 0.9832745790481567
Loss at iteration 150 : 0.786406934261322
Loss at iteration 200 : 0.7250166535377502
Loss at iteration 250 : 0.7059265375137329
Loss at iteration 300 : 0.6917067766189575
Loss at iteration 350 : 0.8975244760513306
Mean training loss eporch  93 :  0.8551223199991953
Loss at iteration 50 : 0.6636284589767456
Loss at iteration 100 : 0.9038189649581909
Loss at iteration 150 : 0.909558892250061
Loss at iteration 200 : 0.7899287939071655
Loss at iteration 250 : 0.9158632159233093
Loss at iteration 300 : 0.6135700941085815
Loss at iteration 350 : 0.7757981419563293
Mean training loss eporch  94 :  0.8567434142506312
Loss at iteration 50 : 0.980219304561615
Loss at iteration 100 : 0.6152606010437012
Loss at iteration 150 : 0.8618193864822388
Loss at iteration 200 : 0.8477985858917236
Loss at iteration 250 : 0.9609577655792236
Loss at iteration 300 : 0.9330229759216309
Loss at iteration 350 : 1.0641649961471558
Mean training loss eporch  95 :  0.8553324493150862
Loss at iteration 50 : 0.7448871731758118
Loss at iteration 100 : 0.7164543271064758
Loss at iteration 150 : 1.2017627954483032
Loss at iteration 200 : 0.8380820751190186
Loss at iteration 250 : 0.7716321349143982
Loss at iteration 300 : 0.8862544894218445
Loss at iteration 350 : 0.7181751132011414
Mean training loss eporch  96 :  0.8551564770085471
Loss at iteration 50 : 0.9074976444244385
Loss at iteration 100 : 0.7792536020278931
Loss at iteration 150 : 0.8356757164001465
Loss at iteration 200 : 1.150713324546814
Loss at iteration 250 : 0.7377330660820007
Loss at iteration 300 : 0.8506717085838318
Loss at iteration 350 : 0.6681581139564514
Mean training loss eporch  97 :  0.8550017881330358
Loss at iteration 50 : 0.7598342299461365
Loss at iteration 100 : 0.8523038029670715
Loss at iteration 150 : 0.8743252754211426
Loss at iteration 200 : 1.1283923387527466
Loss at iteration 250 : 0.8470858335494995
Loss at iteration 300 : 0.7757073640823364
Loss at iteration 350 : 0.8499963283538818
Mean training loss eporch  98 :  0.8552613789757724
Loss at iteration 50 : 0.778095006942749
Loss at iteration 100 : 0.851820707321167
Loss at iteration 150 : 1.1123344898223877
Loss at iteration 200 : 0.7849307060241699
Loss at iteration 250 : 0.8010212182998657
Loss at iteration 300 : 1.0444988012313843
Loss at iteration 350 : 0.9573448896408081
Mean training loss eporch  99 :  0.8557749760371668
Loss at iteration 50 : 0.667974054813385
Loss at iteration 100 : 0.8793689608573914
Loss at iteration 150 : 0.8964687585830688
Loss at iteration 200 : 0.751782238483429
Loss at iteration 250 : 0.9088115692138672
Loss at iteration 300 : 0.7932643294334412
Loss at iteration 350 : 0.9887694120407104
Mean training loss eporch  100 :  0.8544289295477842
Loss at iteration 50 : 1.0054247379302979
Loss at iteration 100 : 0.7726322412490845
Loss at iteration 150 : 0.7951170206069946
Loss at iteration 200 : 1.2309308052062988
Loss at iteration 250 : 1.0136604309082031
Loss at iteration 300 : 0.6913310289382935
Loss at iteration 350 : 0.8387075066566467
Mean training loss eporch  101 :  0.8542015655803933
Loss at iteration 50 : 0.8016306161880493
Loss at iteration 100 : 1.1422991752624512
Loss at iteration 150 : 0.8094117641448975
Loss at iteration 200 : 0.7118644714355469
Loss at iteration 250 : 1.1582890748977661
Loss at iteration 300 : 0.7038190364837646
Loss at iteration 350 : 0.9051990509033203
Mean training loss eporch  102 :  0.8548574061305435
Loss at iteration 50 : 0.7319959998130798
Loss at iteration 100 : 0.8916078805923462
Loss at iteration 150 : 1.0086631774902344
Loss at iteration 200 : 0.7007046341896057
Loss at iteration 250 : 0.8598076105117798
Loss at iteration 300 : 1.6609065532684326
Loss at iteration 350 : 0.7808690071105957
Mean training loss eporch  103 :  0.855306320247196
Loss at iteration 50 : 1.0199681520462036
Loss at iteration 100 : 0.7811630964279175
Loss at iteration 150 : 0.9040825366973877
Loss at iteration 200 : 0.7375568151473999
Loss at iteration 250 : 0.8496941328048706
Loss at iteration 300 : 0.6482649445533752
Loss at iteration 350 : 1.0030972957611084
Mean training loss eporch  104 :  0.8546393802241673
Loss at iteration 50 : 1.011812686920166
Loss at iteration 100 : 0.81605064868927
Loss at iteration 150 : 0.5461464524269104
Loss at iteration 200 : 0.7595362663269043
Loss at iteration 250 : 0.8254061937332153
Loss at iteration 300 : 0.722559928894043
Loss at iteration 350 : 0.7678799629211426
Mean training loss eporch  105 :  0.854957354920251
Loss at iteration 50 : 0.8693540096282959
Loss at iteration 100 : 0.8285302519798279
Loss at iteration 150 : 0.8257275819778442
Loss at iteration 200 : 0.9358679056167603
Loss at iteration 250 : 0.7745076417922974
Loss at iteration 300 : 1.0690720081329346
Loss at iteration 350 : 0.5319442749023438
Mean training loss eporch  106 :  0.8554234708112384
Loss at iteration 50 : 0.8570148944854736
Loss at iteration 100 : 0.7367062568664551
Loss at iteration 150 : 1.0505433082580566
Loss at iteration 200 : 0.8235725164413452
Loss at iteration 250 : 1.0362014770507812
Loss at iteration 300 : 0.7706488370895386
Loss at iteration 350 : 1.107607126235962
Mean training loss eporch  107 :  0.8543079947195356
Loss at iteration 50 : 1.1624720096588135
Loss at iteration 100 : 0.9577085375785828
Loss at iteration 150 : 0.8742091655731201
Loss at iteration 200 : 0.7634827494621277
Loss at iteration 250 : 1.0510632991790771
Loss at iteration 300 : 0.9046250581741333
Loss at iteration 350 : 0.9607122540473938
Mean training loss eporch  108 :  0.8543401012029598
Loss at iteration 50 : 0.803328275680542
Loss at iteration 100 : 1.0205947160720825
Loss at iteration 150 : 0.889651358127594
Loss at iteration 200 : 0.6751829385757446
Loss at iteration 250 : 0.9402250051498413
Loss at iteration 300 : 1.0524197816848755
Loss at iteration 350 : 1.0278922319412231
Mean training loss eporch  109 :  0.85428250726884
Loss at iteration 50 : 1.0230488777160645
Loss at iteration 100 : 0.8332116603851318
Loss at iteration 150 : 0.7161415219306946
Loss at iteration 200 : 0.8780099749565125
Loss at iteration 250 : 0.5467768907546997
Loss at iteration 300 : 0.9804505109786987
Loss at iteration 350 : 0.7734798789024353
Mean training loss eporch  110 :  0.8538306046415258
Loss at iteration 50 : 0.719444751739502
Loss at iteration 100 : 1.2912704944610596
Loss at iteration 150 : 0.9475681781768799
Loss at iteration 200 : 0.8308156132698059
Loss at iteration 250 : 1.0457324981689453
Loss at iteration 300 : 1.1041843891143799
Loss at iteration 350 : 0.9886670112609863
Mean training loss eporch  111 :  0.8542584851778373
Loss at iteration 50 : 0.9933342933654785
Loss at iteration 100 : 1.122058629989624
Loss at iteration 150 : 0.8166519999504089
Loss at iteration 200 : 0.9100397825241089
Loss at iteration 250 : 0.9396845102310181
Loss at iteration 300 : 0.8187828063964844
Loss at iteration 350 : 0.8115959167480469
Mean training loss eporch  112 :  0.8534006651431795
Loss at iteration 50 : 0.8281821608543396
Loss at iteration 100 : 0.8613146543502808
Loss at iteration 150 : 0.900156557559967
Loss at iteration 200 : 0.8366291522979736
Loss at iteration 250 : 1.002406358718872
Loss at iteration 300 : 0.83527010679245
Loss at iteration 350 : 1.015272617340088
Mean training loss eporch  113 :  0.8537744502857249
Loss at iteration 50 : 0.7762624621391296
Loss at iteration 100 : 0.6167470812797546
Loss at iteration 150 : 0.9062744379043579
Loss at iteration 200 : 0.760843813419342
Loss at iteration 250 : 0.9745602607727051
Loss at iteration 300 : 0.901110053062439
Loss at iteration 350 : 1.0037318468093872
Mean training loss eporch  114 :  0.8534360415248013
Loss at iteration 50 : 0.8307586908340454
Loss at iteration 100 : 0.6763314008712769
Loss at iteration 150 : 0.8725134134292603
Loss at iteration 200 : 0.6427760720252991
Loss at iteration 250 : 0.859967827796936
Loss at iteration 300 : 0.8206018805503845
Loss at iteration 350 : 0.6875956654548645
Mean training loss eporch  115 :  0.8527442226334224
Loss at iteration 50 : 1.2374565601348877
Loss at iteration 100 : 0.9729613065719604
Loss at iteration 150 : 1.1149766445159912
Loss at iteration 200 : 1.094667673110962
Loss at iteration 250 : 1.0788906812667847
Loss at iteration 300 : 0.7220531702041626
Loss at iteration 350 : 1.4702179431915283
Mean training loss eporch  116 :  0.8530733275508123
Loss at iteration 50 : 0.6929875612258911
Loss at iteration 100 : 1.1177533864974976
Loss at iteration 150 : 0.7778164744377136
Loss at iteration 200 : 0.6798310875892639
Loss at iteration 250 : 0.7704252004623413
Loss at iteration 300 : 0.8647599220275879
Loss at iteration 350 : 0.9104669094085693
Mean training loss eporch  117 :  0.8533159510168449
Loss at iteration 50 : 0.5867486596107483
Loss at iteration 100 : 0.8948163986206055
Loss at iteration 150 : 0.6778042316436768
Loss at iteration 200 : 0.9165894985198975
Loss at iteration 250 : 1.0539671182632446
Loss at iteration 300 : 0.6830712556838989
Loss at iteration 350 : 0.6693477630615234
Mean training loss eporch  118 :  0.8539151089689719
Loss at iteration 50 : 0.8264061212539673
Loss at iteration 100 : 1.2037198543548584
Loss at iteration 150 : 0.9526160359382629
Loss at iteration 200 : 0.7323020696640015
Loss at iteration 250 : 1.0208014249801636
Loss at iteration 300 : 0.7520005702972412
Loss at iteration 350 : 0.7165845036506653
Mean training loss eporch  119 :  0.853076628907017
Loss at iteration 50 : 0.8743903040885925
Loss at iteration 100 : 0.7263909578323364
Loss at iteration 150 : 0.6039037704467773
Loss at iteration 200 : 0.716469407081604
Loss at iteration 250 : 1.2509607076644897
Loss at iteration 300 : 0.6583027243614197
Loss at iteration 350 : 0.7570074796676636
Mean training loss eporch  120 :  0.8528666575118978
Loss at iteration 50 : 0.9359639286994934
Loss at iteration 100 : 0.6893569231033325
Loss at iteration 150 : 0.8562304377555847
Loss at iteration 200 : 0.8441846370697021
Loss at iteration 250 : 0.8461601138114929
Loss at iteration 300 : 0.7623640298843384
Loss at iteration 350 : 0.9433480501174927
Mean training loss eporch  121 :  0.8531827611267251
Loss at iteration 50 : 0.9316598773002625
Loss at iteration 100 : 0.7657994031906128
Loss at iteration 150 : 0.713629424571991
Loss at iteration 200 : 0.9401298761367798
Loss at iteration 250 : 0.6811807751655579
Loss at iteration 300 : 0.7051540613174438
Loss at iteration 350 : 0.9165158271789551
Mean training loss eporch  122 :  0.8539355904179275
Loss at iteration 50 : 0.8699017763137817
Loss at iteration 100 : 0.9144530296325684
Loss at iteration 150 : 0.7753640413284302
Loss at iteration 200 : 1.2604005336761475
Loss at iteration 250 : 0.7490772008895874
Loss at iteration 300 : 1.0090527534484863
Loss at iteration 350 : 0.7531128525733948
Mean training loss eporch  123 :  0.853416392254451
Loss at iteration 50 : 0.7402864694595337
Loss at iteration 100 : 0.562820315361023
Loss at iteration 150 : 1.196141242980957
Loss at iteration 200 : 0.7156094312667847
Loss at iteration 250 : 0.8911739587783813
Loss at iteration 300 : 0.9657880067825317
Loss at iteration 350 : 0.7177910804748535
Mean training loss eporch  124 :  0.8533910652474751
Loss at iteration 50 : 0.8345585465431213
Loss at iteration 100 : 0.8294572830200195
Loss at iteration 150 : 0.9790117740631104
Loss at iteration 200 : 1.1302366256713867
Loss at iteration 250 : 0.8454768657684326
Loss at iteration 300 : 0.7740660309791565
Loss at iteration 350 : 0.6135386228561401
Mean training loss eporch  125 :  0.8525973663285926
Loss at iteration 50 : 0.7373002767562866
Loss at iteration 100 : 0.5889300107955933
Loss at iteration 150 : 0.6809993982315063
Loss at iteration 200 : 0.728059709072113
Loss at iteration 250 : 0.8242892026901245
Loss at iteration 300 : 0.932535707950592
Loss at iteration 350 : 0.7367411255836487
Mean training loss eporch  126 :  0.8533015855090328
Loss at iteration 50 : 0.8595719933509827
Loss at iteration 100 : 0.7568093538284302
Loss at iteration 150 : 0.9752751588821411
Loss at iteration 200 : 0.7358741760253906
Loss at iteration 250 : 0.6028509140014648
Loss at iteration 300 : 0.9643187522888184
Loss at iteration 350 : 0.8607438802719116
Mean training loss eporch  127 :  0.8526998351490687
Loss at iteration 50 : 1.0723797082901
Loss at iteration 100 : 0.7581139206886292
Loss at iteration 150 : 0.9883076548576355
Loss at iteration 200 : 0.5615648031234741
Loss at iteration 250 : 0.867121696472168
Loss at iteration 300 : 0.8741855621337891
Loss at iteration 350 : 0.9946781992912292
Mean training loss eporch  128 :  0.8532133617256054
Loss at iteration 50 : 0.924280047416687
Loss at iteration 100 : 0.6874655485153198
Loss at iteration 150 : 0.7777905464172363
Loss at iteration 200 : 1.1110386848449707
Loss at iteration 250 : 0.8458518981933594
Loss at iteration 300 : 0.7394149303436279
Loss at iteration 350 : 0.6960965394973755
Mean training loss eporch  129 :  0.8538832374350734
Loss at iteration 50 : 1.2521015405654907
Loss at iteration 100 : 1.0636060237884521
Loss at iteration 150 : 1.1624572277069092
Loss at iteration 200 : 0.752384603023529
Loss at iteration 250 : 0.8915682435035706
Loss at iteration 300 : 1.025275468826294
Loss at iteration 350 : 0.7073484063148499
Mean training loss eporch  130 :  0.8528790240565305
Loss at iteration 50 : 1.0835001468658447
Loss at iteration 100 : 0.8735597133636475
Loss at iteration 150 : 0.8761879205703735
Loss at iteration 200 : 1.165994644165039
Loss at iteration 250 : 0.7699289321899414
Loss at iteration 300 : 0.5997992157936096
Loss at iteration 350 : 0.9511950016021729
Mean training loss eporch  131 :  0.8530979558588967
Loss at iteration 50 : 0.5845637321472168
Loss at iteration 100 : 0.7628884315490723
Loss at iteration 150 : 1.2877333164215088
Loss at iteration 200 : 1.1175978183746338
Loss at iteration 250 : 0.9860315322875977
Loss at iteration 300 : 0.841016411781311
Loss at iteration 350 : 0.9864661693572998
Mean training loss eporch  132 :  0.8532071371400167
Loss at iteration 50 : 0.7669377326965332
Loss at iteration 100 : 1.0857371091842651
Loss at iteration 150 : 0.7094436883926392
Loss at iteration 200 : 0.7809957265853882
Loss at iteration 250 : 0.7535383701324463
Loss at iteration 300 : 1.003296136856079
Loss at iteration 350 : 0.9636971354484558
Mean training loss eporch  133 :  0.8526617036294685
Loss at iteration 50 : 0.9382005929946899
Loss at iteration 100 : 0.9968489408493042
Loss at iteration 150 : 0.7917120456695557
Loss at iteration 200 : 1.5264370441436768
Loss at iteration 250 : 0.8492014408111572
Loss at iteration 300 : 0.8691852688789368
Loss at iteration 350 : 0.9951224327087402
Mean training loss eporch  134 :  0.8522237822334603
Loss at iteration 50 : 0.927057147026062
Loss at iteration 100 : 0.9207901358604431
Loss at iteration 150 : 0.7685920000076294
Loss at iteration 200 : 0.755311906337738
Loss at iteration 250 : 0.8663750290870667
Loss at iteration 300 : 0.6174147129058838
Loss at iteration 350 : 0.6872245073318481
Mean training loss eporch  135 :  0.8525048720615881
Loss at iteration 50 : 1.0325541496276855
Loss at iteration 100 : 0.9893127083778381
Loss at iteration 150 : 0.7751830220222473
Loss at iteration 200 : 0.6527864933013916
Loss at iteration 250 : 0.8513318300247192
Loss at iteration 300 : 0.7144222259521484
Loss at iteration 350 : 0.576613187789917
Mean training loss eporch  136 :  0.8523665234525367
Loss at iteration 50 : 0.5894472599029541
Loss at iteration 100 : 1.0162453651428223
Loss at iteration 150 : 0.5733194947242737
Loss at iteration 200 : 0.9514962434768677
Loss at iteration 250 : 0.6105092763900757
Loss at iteration 300 : 0.9810953736305237
Loss at iteration 350 : 0.8515027761459351
Mean training loss eporch  137 :  0.8523269887008365
Loss at iteration 50 : 0.7265720367431641
Loss at iteration 100 : 0.7163537740707397
Loss at iteration 150 : 0.6103787422180176
Loss at iteration 200 : 0.7300808429718018
Loss at iteration 250 : 0.74220210313797
Loss at iteration 300 : 0.5831640958786011
Loss at iteration 350 : 0.6186481714248657
Mean training loss eporch  138 :  0.8520148461142545
Loss at iteration 50 : 0.7608089447021484
Loss at iteration 100 : 0.8454553484916687
Loss at iteration 150 : 1.086921215057373
Loss at iteration 200 : 0.9260631799697876
Loss at iteration 250 : 0.7369555830955505
Loss at iteration 300 : 0.547484278678894
Loss at iteration 350 : 0.7807171940803528
Mean training loss eporch  139 :  0.8515289201149865
Loss at iteration 50 : 1.0593925714492798
Loss at iteration 100 : 1.1233325004577637
Loss at iteration 150 : 0.9786747694015503
Loss at iteration 200 : 0.6773572564125061
Loss at iteration 250 : 0.9848126173019409
Loss at iteration 300 : 0.8680329918861389
Loss at iteration 350 : 0.7313327789306641
Mean training loss eporch  140 :  0.8515638885674653
Loss at iteration 50 : 0.9742389917373657
Loss at iteration 100 : 0.7721022367477417
Loss at iteration 150 : 0.7989983558654785
Loss at iteration 200 : 0.7905537486076355
Loss at iteration 250 : 0.732529878616333
Loss at iteration 300 : 0.7537647485733032
Loss at iteration 350 : 1.08185613155365
Mean training loss eporch  141 :  0.8516012176319405
Loss at iteration 50 : 0.7480674982070923
Loss at iteration 100 : 0.8358758091926575
Loss at iteration 150 : 0.8306408524513245
Loss at iteration 200 : 0.7104701399803162
Loss at iteration 250 : 1.1507444381713867
Loss at iteration 300 : 0.8549247980117798
Loss at iteration 350 : 0.9260708093643188
Mean training loss eporch  142 :  0.8514364697630443
Loss at iteration 50 : 0.8197356462478638
Loss at iteration 100 : 1.0559170246124268
Loss at iteration 150 : 0.7944098711013794
Loss at iteration 200 : 0.9351811408996582
Loss at iteration 250 : 0.635948896408081
Loss at iteration 300 : 0.7777042388916016
Loss at iteration 350 : 0.6646977663040161
Mean training loss eporch  143 :  0.8512710351004171
Loss at iteration 50 : 0.5673757195472717
Loss at iteration 100 : 0.8532318472862244
Loss at iteration 150 : 1.0279181003570557
Loss at iteration 200 : 0.7115428447723389
Loss at iteration 250 : 0.8251254558563232
Loss at iteration 300 : 1.1336958408355713
Loss at iteration 350 : 1.0438541173934937
Mean training loss eporch  144 :  0.8515962535742099
Loss at iteration 50 : 0.6745682954788208
Loss at iteration 100 : 0.8587979674339294
Loss at iteration 150 : 0.8300101161003113
Loss at iteration 200 : 0.8633027672767639
Loss at iteration 250 : 1.0792131423950195
Loss at iteration 300 : 0.9535391330718994
Loss at iteration 350 : 0.6916103959083557
Mean training loss eporch  145 :  0.852246977507122
Loss at iteration 50 : 0.6380080580711365
Loss at iteration 100 : 0.8888163566589355
Loss at iteration 150 : 0.7045736908912659
Loss at iteration 200 : 0.7543689608573914
Loss at iteration 250 : 0.8490396738052368
Loss at iteration 300 : 0.9591575264930725
Loss at iteration 350 : 0.774243175983429
Mean training loss eporch  146 :  0.8512501246714718
Loss at iteration 50 : 1.0124356746673584
Loss at iteration 100 : 1.1227569580078125
Loss at iteration 150 : 0.9374120831489563
Loss at iteration 200 : 0.645868718624115
Loss at iteration 250 : 0.5888183116912842
Loss at iteration 300 : 0.857390284538269
Loss at iteration 350 : 0.9548835754394531
Mean training loss eporch  147 :  0.8516847723060184
Loss at iteration 50 : 1.058835506439209
Loss at iteration 100 : 0.7265444993972778
Loss at iteration 150 : 0.9879207611083984
Loss at iteration 200 : 0.8110707402229309
Loss at iteration 250 : 1.2572684288024902
Loss at iteration 300 : 0.896827220916748
Loss at iteration 350 : 0.8491761684417725
Mean training loss eporch  148 :  0.8508315073750007
Loss at iteration 50 : 0.6339266300201416
Loss at iteration 100 : 0.879988431930542
Loss at iteration 150 : 0.49680984020233154
Loss at iteration 200 : 0.6357458829879761
Loss at iteration 250 : 0.9290932416915894
Loss at iteration 300 : 0.7296456098556519
Loss at iteration 350 : 0.9556386470794678
Mean training loss eporch  149 :  0.8520237454976985
Loss at iteration 50 : 0.6838123798370361
Loss at iteration 100 : 1.0751513242721558
Loss at iteration 150 : 1.031693696975708
Loss at iteration 200 : 0.804689884185791
Loss at iteration 250 : 1.0586843490600586
Loss at iteration 300 : 0.8140475153923035
Loss at iteration 350 : 1.0252052545547485
Mean training loss eporch  150 :  0.8511018951733907
Loss at iteration 50 : 0.8733347654342651
Loss at iteration 100 : 0.9002144932746887
Loss at iteration 150 : 0.6668150424957275
Loss at iteration 200 : 0.7187598347663879
Loss at iteration 250 : 0.7813945412635803
Loss at iteration 300 : 0.6923879384994507
Loss at iteration 350 : 0.6521542072296143
Mean training loss eporch  151 :  0.8512075076658259
Loss at iteration 50 : 0.8472160696983337
Loss at iteration 100 : 0.813399076461792
Loss at iteration 150 : 0.4343622028827667
Loss at iteration 200 : 0.8693974018096924
Loss at iteration 250 : 0.8259020447731018
Loss at iteration 300 : 0.6700105667114258
Loss at iteration 350 : 0.9931261539459229
Mean training loss eporch  152 :  0.8513459262866823
Loss at iteration 50 : 0.8878473043441772
Loss at iteration 100 : 0.9537376165390015
Loss at iteration 150 : 0.4925646185874939
Loss at iteration 200 : 0.802053689956665
Loss at iteration 250 : 0.7496511340141296
Loss at iteration 300 : 0.7364108562469482
Loss at iteration 350 : 0.9241708517074585
Mean training loss eporch  153 :  0.8505680084859253
Loss at iteration 50 : 0.9608624577522278
Loss at iteration 100 : 0.7213597297668457
Loss at iteration 150 : 1.0120190382003784
Loss at iteration 200 : 0.8001185059547424
Loss at iteration 250 : 0.8841793537139893
Loss at iteration 300 : 0.93193519115448
Loss at iteration 350 : 0.8336641788482666
Mean training loss eporch  154 :  0.8504278155230971
Loss at iteration 50 : 0.867497980594635
Loss at iteration 100 : 0.7789266109466553
Loss at iteration 150 : 1.1955976486206055
Loss at iteration 200 : 0.5942124128341675
Loss at iteration 250 : 0.7644405364990234
Loss at iteration 300 : 0.812663733959198
Loss at iteration 350 : 0.5387104153633118
Mean training loss eporch  155 :  0.8501266621881061
Loss at iteration 50 : 0.6230491399765015
Loss at iteration 100 : 0.8885002136230469
Loss at iteration 150 : 0.8088484406471252
Loss at iteration 200 : 0.7964835166931152
Loss at iteration 250 : 0.8798155784606934
Loss at iteration 300 : 0.6773064136505127
Loss at iteration 350 : 0.5342206358909607
Mean training loss eporch  156 :  0.8508839757038803
Loss at iteration 50 : 0.7484739422798157
Loss at iteration 100 : 0.9646404385566711
Loss at iteration 150 : 1.0565621852874756
Loss at iteration 200 : 0.8208801746368408
Loss at iteration 250 : 0.942949116230011
Loss at iteration 300 : 0.9131930470466614
Loss at iteration 350 : 0.7961192727088928
Mean training loss eporch  157 :  0.8512526818368801
Loss at iteration 50 : 0.9316226840019226
Loss at iteration 100 : 1.0604876279830933
Loss at iteration 150 : 0.8286484479904175
Loss at iteration 200 : 0.6517890691757202
Loss at iteration 250 : 0.7726277112960815
Loss at iteration 300 : 0.6506072878837585
Loss at iteration 350 : 0.8174912929534912
Mean training loss eporch  158 :  0.8508642491682497
Loss at iteration 50 : 0.7875332832336426
Loss at iteration 100 : 0.8127036094665527
Loss at iteration 150 : 0.525587797164917
Loss at iteration 200 : 1.0488218069076538
Loss at iteration 250 : 0.9500309228897095
Loss at iteration 300 : 0.7519916892051697
Loss at iteration 350 : 0.7639137506484985
Mean training loss eporch  159 :  0.8506731819854212
Loss at iteration 50 : 0.8330178260803223
Loss at iteration 100 : 0.8897021412849426
Loss at iteration 150 : 0.9053460359573364
Loss at iteration 200 : 0.9914558529853821
Loss at iteration 250 : 1.0288301706314087
Loss at iteration 300 : 0.9695881605148315
Loss at iteration 350 : 1.1337542533874512
Mean training loss eporch  160 :  0.8522050881354266
Loss at iteration 50 : 0.7586971521377563
Loss at iteration 100 : 0.6701427698135376
Loss at iteration 150 : 0.7269375920295715
Loss at iteration 200 : 0.7976219654083252
Loss at iteration 250 : 0.8444472551345825
Loss at iteration 300 : 0.7712972164154053
Loss at iteration 350 : 0.7253508567810059
Mean training loss eporch  161 :  0.8509700161124033
Loss at iteration 50 : 1.0335290431976318
Loss at iteration 100 : 1.0274102687835693
Loss at iteration 150 : 0.7737489938735962
Loss at iteration 200 : 1.0871021747589111
Loss at iteration 250 : 0.5339503288269043
Loss at iteration 300 : 0.9731895327568054
Loss at iteration 350 : 0.7924073934555054
Mean training loss eporch  162 :  0.8514943323122761
Loss at iteration 50 : 0.8536729216575623
Loss at iteration 100 : 0.8424838185310364
Loss at iteration 150 : 0.9419244527816772
Loss at iteration 200 : 0.8222407102584839
Loss at iteration 250 : 0.8103034496307373
Loss at iteration 300 : 0.918519139289856
Loss at iteration 350 : 0.6708272099494934
Mean training loss eporch  163 :  0.8505800957717593
Loss at iteration 50 : 0.8662853240966797
Loss at iteration 100 : 0.8037197589874268
Loss at iteration 150 : 0.7876996994018555
Loss at iteration 200 : 0.6277586817741394
Loss at iteration 250 : 0.9439170360565186
Loss at iteration 300 : 0.7735024690628052
Loss at iteration 350 : 0.6059913039207458
Mean training loss eporch  164 :  0.8509659420245539
Loss at iteration 50 : 1.0679367780685425
Loss at iteration 100 : 0.8165031671524048
Loss at iteration 150 : 0.6913553476333618
Loss at iteration 200 : 0.8739664554595947
Loss at iteration 250 : 0.7062662839889526
Loss at iteration 300 : 1.221569538116455
Loss at iteration 350 : 0.9212580323219299
Mean training loss eporch  165 :  0.8510477857457267
Loss at iteration 50 : 0.7682339549064636
Loss at iteration 100 : 0.8922159671783447
Loss at iteration 150 : 0.8613810539245605
Loss at iteration 200 : 0.6776851415634155
Loss at iteration 250 : 0.7644259929656982
Loss at iteration 300 : 0.7302210927009583
Loss at iteration 350 : 0.7512496113777161
Mean training loss eporch  166 :  0.8509447341242795
Loss at iteration 50 : 0.9464436769485474
Loss at iteration 100 : 0.8779425621032715
Loss at iteration 150 : 1.0917795896530151
Loss at iteration 200 : 0.8003239631652832
Loss at iteration 250 : 1.0350751876831055
Loss at iteration 300 : 0.9155644774436951
Loss at iteration 350 : 0.9811767935752869
Mean training loss eporch  167 :  0.850919098923446
Loss at iteration 50 : 0.8858613967895508
Loss at iteration 100 : 1.1088759899139404
Loss at iteration 150 : 0.6046111583709717
Loss at iteration 200 : 0.8469927906990051
Loss at iteration 250 : 1.0720270872116089
Loss at iteration 300 : 0.6570355892181396
Loss at iteration 350 : 0.8161944150924683
Mean training loss eporch  168 :  0.8498196174543371
Loss at iteration 50 : 0.6160327196121216
Loss at iteration 100 : 1.1801429986953735
Loss at iteration 150 : 0.7551872730255127
Loss at iteration 200 : 0.8013669848442078
Loss at iteration 250 : 0.7837458848953247
Loss at iteration 300 : 0.8203004598617554
Loss at iteration 350 : 1.05177903175354
Mean training loss eporch  169 :  0.8516337101263974
Loss at iteration 50 : 0.6692965030670166
Loss at iteration 100 : 1.2602112293243408
Loss at iteration 150 : 1.0774421691894531
Loss at iteration 200 : 0.7014586329460144
Loss at iteration 250 : 0.610170304775238
Loss at iteration 300 : 0.9960957169532776
Loss at iteration 350 : 0.7977561950683594
Mean training loss eporch  170 :  0.8506164996239244
Loss at iteration 50 : 0.725709855556488
Loss at iteration 100 : 0.8617181777954102
Loss at iteration 150 : 1.0611618757247925
Loss at iteration 200 : 0.6818954944610596
Loss at iteration 250 : 0.8765543699264526
Loss at iteration 300 : 0.887519121170044
Loss at iteration 350 : 0.9013553857803345
Mean training loss eporch  171 :  0.8503442099170079
Loss at iteration 50 : 0.7683149576187134
Loss at iteration 100 : 0.5332694053649902
Loss at iteration 150 : 0.7842510938644409
Loss at iteration 200 : 0.6062862277030945
Loss at iteration 250 : 0.5610141754150391
Loss at iteration 300 : 0.8291876316070557
Loss at iteration 350 : 1.1426751613616943
Mean training loss eporch  172 :  0.8494804955664135
Loss at iteration 50 : 0.8231836557388306
Loss at iteration 100 : 0.7893762588500977
Loss at iteration 150 : 0.749585747718811
Loss at iteration 200 : 0.9117776155471802
Loss at iteration 250 : 0.6887414455413818
Loss at iteration 300 : 0.6468584537506104
Loss at iteration 350 : 0.6975473761558533
Mean training loss eporch  173 :  0.8496946093266603
Loss at iteration 50 : 1.0458166599273682
Loss at iteration 100 : 1.055452823638916
Loss at iteration 150 : 1.0354187488555908
Loss at iteration 200 : 1.1410980224609375
Loss at iteration 250 : 0.8985983729362488
Loss at iteration 300 : 0.7286689877510071
Loss at iteration 350 : 0.5784496068954468
Mean training loss eporch  174 :  0.8504417153893324
Loss at iteration 50 : 0.5524839162826538
Loss at iteration 100 : 0.6708793640136719
Loss at iteration 150 : 0.8091620802879333
Loss at iteration 200 : 0.9720302820205688
Loss at iteration 250 : 1.083601713180542
Loss at iteration 300 : 1.1121150255203247
Loss at iteration 350 : 0.7088034152984619
Mean training loss eporch  175 :  0.8505691976616623
Loss at iteration 50 : 0.831961989402771
Loss at iteration 100 : 0.813418984413147
Loss at iteration 150 : 0.7034843564033508
Loss at iteration 200 : 0.7694961428642273
Loss at iteration 250 : 0.6327106952667236
Loss at iteration 300 : 0.9135763049125671
Loss at iteration 350 : 0.786014199256897
Mean training loss eporch  176 :  0.8501089683600834
Loss at iteration 50 : 0.7699014544487
Loss at iteration 100 : 0.7194676399230957
Loss at iteration 150 : 0.9179643988609314
Loss at iteration 200 : 0.9280165433883667
Loss at iteration 250 : 1.1466195583343506
Loss at iteration 300 : 1.010480523109436
Loss at iteration 350 : 1.0346728563308716
Mean training loss eporch  177 :  0.8497903868950233
Loss at iteration 50 : 0.5793878436088562
Loss at iteration 100 : 0.9039516448974609
Loss at iteration 150 : 0.8993709683418274
Loss at iteration 200 : 0.8501121997833252
Loss at iteration 250 : 0.7087113857269287
Loss at iteration 300 : 0.7701418399810791
Loss at iteration 350 : 1.075630784034729
Mean training loss eporch  178 :  0.8493026863172571
Loss at iteration 50 : 0.8918395638465881
Loss at iteration 100 : 0.9596361517906189
Loss at iteration 150 : 1.205784797668457
Loss at iteration 200 : 0.7617585062980652
Loss at iteration 250 : 0.8001805543899536
Loss at iteration 300 : 0.777400016784668
Loss at iteration 350 : 1.0714716911315918
Mean training loss eporch  179 :  0.84947850164913
Loss at iteration 50 : 0.9835872650146484
Loss at iteration 100 : 0.589781641960144
Loss at iteration 150 : 0.6154094934463501
Loss at iteration 200 : 0.5708825588226318
Loss at iteration 250 : 0.9037691354751587
Loss at iteration 300 : 0.7797908186912537
Loss at iteration 350 : 0.6272293329238892
Mean training loss eporch  180 :  0.8497502023265475
Loss at iteration 50 : 0.7490413188934326
Loss at iteration 100 : 0.7485932111740112
Loss at iteration 150 : 0.6626657843589783
Loss at iteration 200 : 0.7578684687614441
Loss at iteration 250 : 0.7301526665687561
Loss at iteration 300 : 0.5521920323371887
Loss at iteration 350 : 0.9650646448135376
Mean training loss eporch  181 :  0.8499909071695237
Loss at iteration 50 : 0.615174412727356
Loss at iteration 100 : 0.845098078250885
Loss at iteration 150 : 0.6937739849090576
Loss at iteration 200 : 0.9680209159851074
Loss at iteration 250 : 0.6858587265014648
Loss at iteration 300 : 0.7754481434822083
Loss at iteration 350 : 0.7217023372650146
Mean training loss eporch  182 :  0.8492634498253071
Loss at iteration 50 : 0.8692586421966553
Loss at iteration 100 : 0.8784042596817017
Loss at iteration 150 : 0.8333993554115295
Loss at iteration 200 : 1.189010500907898
Loss at iteration 250 : 1.0517480373382568
Loss at iteration 300 : 0.8295308351516724
Loss at iteration 350 : 0.7637382745742798
Mean training loss eporch  183 :  0.8498956480669597
Loss at iteration 50 : 0.8961933255195618
Loss at iteration 100 : 0.5207051634788513
Loss at iteration 150 : 1.0923662185668945
Loss at iteration 200 : 0.7510969042778015
Loss at iteration 250 : 1.197493314743042
Loss at iteration 300 : 0.7294039130210876
Loss at iteration 350 : 0.6044818162918091
Mean training loss eporch  184 :  0.8496590616211058
Loss at iteration 50 : 0.8531029224395752
Loss at iteration 100 : 0.7219853401184082
Loss at iteration 150 : 0.7526878714561462
Loss at iteration 200 : 0.8930177092552185
Loss at iteration 250 : 0.8413299918174744
Loss at iteration 300 : 0.7692299485206604
Loss at iteration 350 : 0.7182080745697021
Mean training loss eporch  185 :  0.8497108214746707
Loss at iteration 50 : 0.8875457048416138
Loss at iteration 100 : 0.9817885756492615
Loss at iteration 150 : 0.9387741088867188
Loss at iteration 200 : 0.9462921619415283
Loss at iteration 250 : 0.7590255737304688
Loss at iteration 300 : 0.8262501955032349
Loss at iteration 350 : 0.7475447654724121
Mean training loss eporch  186 :  0.8509572192474648
Loss at iteration 50 : 0.6651744842529297
Loss at iteration 100 : 0.9462279081344604
Loss at iteration 150 : 1.273768424987793
Loss at iteration 200 : 0.8147450685501099
Loss at iteration 250 : 0.8112597465515137
Loss at iteration 300 : 0.9361540079116821
Loss at iteration 350 : 1.0865135192871094
Mean training loss eporch  187 :  0.8507709013564246
Loss at iteration 50 : 0.7192103862762451
Loss at iteration 100 : 0.8791103363037109
Loss at iteration 150 : 0.9575648903846741
Loss at iteration 200 : 1.103806972503662
Loss at iteration 250 : 0.7312051057815552
Loss at iteration 300 : 0.6191647052764893
Loss at iteration 350 : 0.7495510578155518
Mean training loss eporch  188 :  0.8500533100789186
Loss at iteration 50 : 0.8226340413093567
Loss at iteration 100 : 0.7038771510124207
Loss at iteration 150 : 1.2761621475219727
Loss at iteration 200 : 1.043015718460083
Loss at iteration 250 : 0.7988764047622681
Loss at iteration 300 : 0.881249189376831
Loss at iteration 350 : 0.6936643719673157
Mean training loss eporch  189 :  0.8493612664874899
Loss at iteration 50 : 0.9678896069526672
Loss at iteration 100 : 0.6625733971595764
Loss at iteration 150 : 0.7018465399742126
Loss at iteration 200 : 0.7368729710578918
Loss at iteration 250 : 0.7214081287384033
Loss at iteration 300 : 0.9289565086364746
Loss at iteration 350 : 0.8374301195144653
Mean training loss eporch  190 :  0.8490839704634652
Loss at iteration 50 : 0.884166955947876
Loss at iteration 100 : 0.7629482746124268
Loss at iteration 150 : 1.0268179178237915
Loss at iteration 200 : 1.0754504203796387
Loss at iteration 250 : 0.8408015370368958
Loss at iteration 300 : 0.9245133399963379
Loss at iteration 350 : 0.8674138188362122
Mean training loss eporch  191 :  0.8492114584912699
Loss at iteration 50 : 1.2294832468032837
Loss at iteration 100 : 0.8133249282836914
Loss at iteration 150 : 1.093267560005188
Loss at iteration 200 : 0.8339841961860657
Loss at iteration 250 : 0.8132302761077881
Loss at iteration 300 : 0.673935055732727
Loss at iteration 350 : 0.8438973426818848
Mean training loss eporch  192 :  0.8513597287040539
Loss at iteration 50 : 1.0172003507614136
Loss at iteration 100 : 0.9174449443817139
Loss at iteration 150 : 1.0907886028289795
Loss at iteration 200 : 0.938290536403656
Loss at iteration 250 : 1.0465612411499023
Loss at iteration 300 : 1.0889843702316284
Loss at iteration 350 : 1.200812578201294
Mean training loss eporch  193 :  0.8489660004932413
Loss at iteration 50 : 0.8914331793785095
Loss at iteration 100 : 0.9076865315437317
Loss at iteration 150 : 0.500015377998352
Loss at iteration 200 : 0.8319334983825684
Loss at iteration 250 : 0.7129382491111755
Loss at iteration 300 : 1.0826678276062012
Loss at iteration 350 : 0.9625004529953003
Mean training loss eporch  194 :  0.8499439829398715
Loss at iteration 50 : 0.8507211804389954
Loss at iteration 100 : 0.935113787651062
Loss at iteration 150 : 0.7632061839103699
Loss at iteration 200 : 0.6160343885421753
Loss at iteration 250 : 0.9413477778434753
Loss at iteration 300 : 0.8387895226478577
Loss at iteration 350 : 0.8470984697341919
Mean training loss eporch  195 :  0.8504015344475943
Loss at iteration 50 : 0.7500408887863159
Loss at iteration 100 : 0.8370823860168457
Loss at iteration 150 : 0.9406883120536804
Loss at iteration 200 : 0.7909635901451111
Loss at iteration 250 : 1.1222443580627441
Loss at iteration 300 : 0.6781287789344788
Loss at iteration 350 : 1.0333974361419678
Mean training loss eporch  196 :  0.8490378044585072
Loss at iteration 50 : 1.1742759943008423
Loss at iteration 100 : 0.782039999961853
Loss at iteration 150 : 0.5592184066772461
Loss at iteration 200 : 0.7522749900817871
Loss at iteration 250 : 1.245370626449585
Loss at iteration 300 : 0.7314701080322266
Loss at iteration 350 : 0.8358145952224731
Mean training loss eporch  197 :  0.8504203790552401
Loss at iteration 50 : 1.0464013814926147
Loss at iteration 100 : 0.8153181076049805
Loss at iteration 150 : 0.6763131618499756
Loss at iteration 200 : 1.1122699975967407
Loss at iteration 250 : 0.9037963151931763
Loss at iteration 300 : 0.6330493688583374
Loss at iteration 350 : 0.7910414338111877
Mean training loss eporch  198 :  0.8491260527618347
Loss at iteration 50 : 0.8637510538101196
Loss at iteration 100 : 0.596581220626831
Loss at iteration 150 : 0.9053444862365723
Loss at iteration 200 : 1.0083565711975098
Loss at iteration 250 : 0.8894364833831787
Loss at iteration 300 : 0.822325587272644
Loss at iteration 350 : 0.8132431507110596
Mean training loss eporch  199 :  0.8493751315843492
Loss at iteration 50 : 0.8410227298736572
Loss at iteration 100 : 0.9640908241271973
Loss at iteration 150 : 0.7000143527984619
Loss at iteration 200 : 1.0139133930206299
Loss at iteration 250 : 0.8203411102294922
Loss at iteration 300 : 1.0229735374450684
Loss at iteration 350 : 0.8366976976394653
Mean training loss eporch  200 :  0.8498050516875333
Loss at iteration 50 : 0.8348398804664612
Loss at iteration 100 : 1.1408069133758545
Loss at iteration 150 : 0.4836922883987427
Loss at iteration 200 : 0.7105634808540344
Loss at iteration 250 : 0.9291170835494995
Loss at iteration 300 : 0.8572062849998474
Loss at iteration 350 : 0.9165661334991455
Mean training loss eporch  201 :  0.8504891596616261
Loss at iteration 50 : 0.8032727241516113
Loss at iteration 100 : 0.7458393573760986
Loss at iteration 150 : 0.7276866436004639
Loss at iteration 200 : 0.8990421295166016
Loss at iteration 250 : 0.5576998591423035
Loss at iteration 300 : 0.646276593208313
Loss at iteration 350 : 1.0090084075927734
Mean training loss eporch  202 :  0.8492343955569797
Loss at iteration 50 : 0.9055900573730469
Loss at iteration 100 : 0.7995063066482544
Loss at iteration 150 : 0.7793626189231873
Loss at iteration 200 : 1.141964316368103
Loss at iteration 250 : 0.9223730564117432
Loss at iteration 300 : 0.8542314767837524
Loss at iteration 350 : 1.1913132667541504
Mean training loss eporch  203 :  0.8489977335803723
Loss at iteration 50 : 0.5703624486923218
Loss at iteration 100 : 1.1267346143722534
Loss at iteration 150 : 0.8315359950065613
Loss at iteration 200 : 0.6701655387878418
Loss at iteration 250 : 0.9061063528060913
Loss at iteration 300 : 0.6123676300048828
Loss at iteration 350 : 0.690941333770752
Mean training loss eporch  204 :  0.8502020840606992
Loss at iteration 50 : 0.8142496347427368
Loss at iteration 100 : 0.6060512065887451
Loss at iteration 150 : 0.7234611511230469
Loss at iteration 200 : 1.1004002094268799
Loss at iteration 250 : 0.7756913900375366
Loss at iteration 300 : 0.800797164440155
Loss at iteration 350 : 0.9210654497146606
Mean training loss eporch  205 :  0.8489376396413834
Loss at iteration 50 : 0.8179081678390503
Loss at iteration 100 : 0.6451082229614258
Loss at iteration 150 : 0.7049644589424133
Loss at iteration 200 : 0.8136204481124878
Loss at iteration 250 : 0.9581019878387451
Loss at iteration 300 : 0.6481959819793701
Loss at iteration 350 : 0.8616090416908264
Mean training loss eporch  206 :  0.8494234164713552
Loss at iteration 50 : 0.7710268497467041
Loss at iteration 100 : 0.7382873296737671
Loss at iteration 150 : 0.7828922271728516
Loss at iteration 200 : 0.9918727278709412
Loss at iteration 250 : 1.088632583618164
Loss at iteration 300 : 0.8830951452255249
Loss at iteration 350 : 0.8773773312568665
Mean training loss eporch  207 :  0.8482602472816195
Loss at iteration 50 : 1.0322233438491821
Loss at iteration 100 : 0.7940258979797363
Loss at iteration 150 : 0.766576886177063
Loss at iteration 200 : 0.8795850872993469
Loss at iteration 250 : 0.755347728729248
Loss at iteration 300 : 0.6791873574256897
Loss at iteration 350 : 0.8253909945487976
Mean training loss eporch  208 :  0.8491215419674677
Loss at iteration 50 : 1.0490779876708984
Loss at iteration 100 : 0.8461729288101196
Loss at iteration 150 : 0.816149890422821
Loss at iteration 200 : 1.0846998691558838
Loss at iteration 250 : 0.9577178359031677
Loss at iteration 300 : 1.03290855884552
Loss at iteration 350 : 0.8584029078483582
Mean training loss eporch  209 :  0.8489704929173939
Loss at iteration 50 : 0.9451984763145447
Loss at iteration 100 : 0.8683077692985535
Loss at iteration 150 : 0.6583486795425415
Loss at iteration 200 : 0.9045343995094299
Loss at iteration 250 : 0.6175587177276611
Loss at iteration 300 : 1.0467348098754883
Loss at iteration 350 : 0.9959063529968262
Mean training loss eporch  210 :  0.8505684481884437
Loss at iteration 50 : 0.8392787575721741
Loss at iteration 100 : 0.7485306262969971
Loss at iteration 150 : 1.0988775491714478
Loss at iteration 200 : 0.6356112957000732
Loss at iteration 250 : 0.7375843524932861
Loss at iteration 300 : 0.692999005317688
Loss at iteration 350 : 0.9706933498382568
Mean training loss eporch  211 :  0.8483772465476284
Loss at iteration 50 : 1.036118745803833
Loss at iteration 100 : 0.6465768814086914
Loss at iteration 150 : 0.7081038951873779
Loss at iteration 200 : 0.9552890658378601
Loss at iteration 250 : 0.876961350440979
Loss at iteration 300 : 0.8851741552352905
Loss at iteration 350 : 0.8308670520782471
Mean training loss eporch  212 :  0.849056594428562
Loss at iteration 50 : 1.028167724609375
Loss at iteration 100 : 0.755251407623291
Loss at iteration 150 : 0.6771838665008545
Loss at iteration 200 : 1.0079692602157593
Loss at iteration 250 : 1.2402698993682861
Loss at iteration 300 : 0.6311804056167603
Loss at iteration 350 : 0.7180012464523315
Mean training loss eporch  213 :  0.8491148968379965
Loss at iteration 50 : 0.6446810960769653
Loss at iteration 100 : 0.739043116569519
Loss at iteration 150 : 0.6932622790336609
Loss at iteration 200 : 0.8542163372039795
Loss at iteration 250 : 0.8646656274795532
Loss at iteration 300 : 0.8771517276763916
Loss at iteration 350 : 0.9011901617050171
Mean training loss eporch  214 :  0.8486812797488359
Loss at iteration 50 : 1.1510164737701416
Loss at iteration 100 : 0.7577381134033203
Loss at iteration 150 : 0.8945556879043579
Loss at iteration 200 : 0.9100666642189026
Loss at iteration 250 : 1.0072643756866455
Loss at iteration 300 : 1.410622477531433
Loss at iteration 350 : 0.48178431391716003
Mean training loss eporch  215 :  0.8487764562248553
Loss at iteration 50 : 0.5576729774475098
Loss at iteration 100 : 0.7709179520606995
Loss at iteration 150 : 0.6826291084289551
Loss at iteration 200 : 0.7947473526000977
Loss at iteration 250 : 0.749018669128418
Loss at iteration 300 : 0.7833672761917114
Loss at iteration 350 : 0.7979485988616943
Mean training loss eporch  216 :  0.8498351939771541
Loss at iteration 50 : 0.9977229833602905
Loss at iteration 100 : 0.7713451981544495
Loss at iteration 150 : 1.0903029441833496
Loss at iteration 200 : 0.9451707005500793
Loss at iteration 250 : 0.9940664768218994
Loss at iteration 300 : 0.7620339393615723
Loss at iteration 350 : 0.8281087875366211
Mean training loss eporch  217 :  0.849457234301895
Loss at iteration 50 : 1.039336085319519
Loss at iteration 100 : 0.8511770367622375
Loss at iteration 150 : 0.9331539273262024
Loss at iteration 200 : 0.6907283663749695
Loss at iteration 250 : 0.7574480175971985
Loss at iteration 300 : 0.9485031366348267
Loss at iteration 350 : 0.9297677278518677
Mean training loss eporch  218 :  0.8500418330311145
Loss at iteration 50 : 0.846036970615387
Loss at iteration 100 : 0.7746849060058594
Loss at iteration 150 : 0.7526865005493164
Loss at iteration 200 : 1.0049481391906738
Loss at iteration 250 : 0.5745987892150879
Loss at iteration 300 : 0.5799371004104614
Loss at iteration 350 : 0.8645716309547424
Mean training loss eporch  219 :  0.8482502120197135
Loss at iteration 50 : 0.7654263973236084
Loss at iteration 100 : 0.5992735028266907
Loss at iteration 150 : 0.9477043747901917
Loss at iteration 200 : 0.7862460613250732
Loss at iteration 250 : 0.9108133316040039
Loss at iteration 300 : 0.9583730697631836
Loss at iteration 350 : 0.9580338001251221
Mean training loss eporch  220 :  0.8486792755820763
Loss at iteration 50 : 0.9240889549255371
Loss at iteration 100 : 0.7138510942459106
Loss at iteration 150 : 1.0493135452270508
Loss at iteration 200 : 0.9596336483955383
Loss at iteration 250 : 1.0975720882415771
Loss at iteration 300 : 0.938593864440918
Loss at iteration 350 : 0.8514535427093506
Mean training loss eporch  221 :  0.8487375510275048
Loss at iteration 50 : 0.9912490844726562
Loss at iteration 100 : 1.0910866260528564
Loss at iteration 150 : 0.8918731212615967
Loss at iteration 200 : 0.7399910092353821
Loss at iteration 250 : 0.8190066814422607
Loss at iteration 300 : 0.7974115014076233
Loss at iteration 350 : 0.7791084051132202
Mean training loss eporch  222 :  0.8488318173500596
Loss at iteration 50 : 1.016715168952942
Loss at iteration 100 : 0.9187611937522888
Loss at iteration 150 : 0.6671649217605591
Loss at iteration 200 : 0.7557141780853271
Loss at iteration 250 : 1.0279572010040283
Loss at iteration 300 : 0.5549478530883789
Loss at iteration 350 : 0.9318898916244507
Mean training loss eporch  223 :  0.8483288467088074
Loss at iteration 50 : 0.7463101148605347
Loss at iteration 100 : 0.5767345428466797
Loss at iteration 150 : 0.6697747111320496
Loss at iteration 200 : 0.8121325969696045
Loss at iteration 250 : 0.8634570240974426
Loss at iteration 300 : 1.0595905780792236
Loss at iteration 350 : 1.2199478149414062
Mean training loss eporch  224 :  0.8499616237859877
Loss at iteration 50 : 0.8315339088439941
Loss at iteration 100 : 0.8619072437286377
Loss at iteration 150 : 0.6750986576080322
Loss at iteration 200 : 0.9307805299758911
Loss at iteration 250 : 0.9648674726486206
Loss at iteration 300 : 0.8538850545883179
Loss at iteration 350 : 1.0125330686569214
Mean training loss eporch  225 :  0.8480177064421316
Loss at iteration 50 : 0.7909847497940063
Loss at iteration 100 : 0.8553162813186646
Loss at iteration 150 : 0.9071239829063416
Loss at iteration 200 : 0.8772761821746826
Loss at iteration 250 : 0.6589603424072266
Loss at iteration 300 : 0.7947556972503662
Loss at iteration 350 : 0.8179541826248169
Mean training loss eporch  226 :  0.8494769917436378
Loss at iteration 50 : 0.7925249934196472
Loss at iteration 100 : 1.1758971214294434
Loss at iteration 150 : 0.6602038145065308
Loss at iteration 200 : 0.9788194894790649
Loss at iteration 250 : 0.7819638252258301
Loss at iteration 300 : 0.6740520596504211
Loss at iteration 350 : 0.9348500967025757
Mean training loss eporch  227 :  0.8496159275688192
Loss at iteration 50 : 0.6239858269691467
Loss at iteration 100 : 0.8108945488929749
Loss at iteration 150 : 0.8456559777259827
Loss at iteration 200 : 0.8326607942581177
Loss at iteration 250 : 0.6647940874099731
Loss at iteration 300 : 1.236415982246399
Loss at iteration 350 : 1.049546241760254
Mean training loss eporch  228 :  0.8485477804822266
Loss at iteration 50 : 0.5830373167991638
Loss at iteration 100 : 1.0155748128890991
Loss at iteration 150 : 0.8261057734489441
Loss at iteration 200 : 1.1818516254425049
Loss at iteration 250 : 0.6450769901275635
Loss at iteration 300 : 0.6169958114624023
Loss at iteration 350 : 0.7061269879341125
Mean training loss eporch  229 :  0.850087468113218
Loss at iteration 50 : 1.0807925462722778
Loss at iteration 100 : 0.601929783821106
Loss at iteration 150 : 0.7753589153289795
Loss at iteration 200 : 0.7634024024009705
Loss at iteration 250 : 0.9586721658706665
Loss at iteration 300 : 0.6056137084960938
Loss at iteration 350 : 0.7612981796264648
Mean training loss eporch  230 :  0.8490506952244138
Loss at iteration 50 : 0.7649595141410828
Loss at iteration 100 : 0.826444685459137
Loss at iteration 150 : 1.0899949073791504
Loss at iteration 200 : 0.9830600619316101
Loss at iteration 250 : 0.595765233039856
Loss at iteration 300 : 0.7925091981887817
Loss at iteration 350 : 1.075209379196167
Mean training loss eporch  231 :  0.8486111645029966
Loss at iteration 50 : 0.7622593641281128
Loss at iteration 100 : 1.0979758501052856
Loss at iteration 150 : 0.8594728112220764
Loss at iteration 200 : 0.4720340073108673
Loss at iteration 250 : 1.1326277256011963
Loss at iteration 300 : 0.8751055002212524
Loss at iteration 350 : 0.7543968558311462
Mean training loss eporch  232 :  0.8486956224712745
Loss at iteration 50 : 1.3817594051361084
Loss at iteration 100 : 0.4550764560699463
Loss at iteration 150 : 0.8544788360595703
Loss at iteration 200 : 0.7355484962463379
Loss at iteration 250 : 0.8378602862358093
Loss at iteration 300 : 0.8245598077774048
Loss at iteration 350 : 0.8223947882652283
Mean training loss eporch  233 :  0.8490582882727264
Loss at iteration 50 : 0.8869287967681885
Loss at iteration 100 : 0.7604411840438843
Loss at iteration 150 : 0.9320623874664307
Loss at iteration 200 : 0.8411469459533691
Loss at iteration 250 : 1.0690007209777832
Loss at iteration 300 : 0.9530229568481445
Loss at iteration 350 : 0.7033067345619202
Mean training loss eporch  234 :  0.8488200701103008
Loss at iteration 50 : 0.9648808240890503
Loss at iteration 100 : 0.7728604674339294
Loss at iteration 150 : 1.0086324214935303
Loss at iteration 200 : 1.0410159826278687
Loss at iteration 250 : 0.8035570979118347
Loss at iteration 300 : 0.7790651321411133
Loss at iteration 350 : 0.6595092415809631
Mean training loss eporch  235 :  0.8487360349723271
Loss at iteration 50 : 1.0847522020339966
Loss at iteration 100 : 1.162426233291626
Loss at iteration 150 : 1.0639617443084717
Loss at iteration 200 : 0.7851782441139221
Loss at iteration 250 : 1.2997727394104004
Loss at iteration 300 : 0.7466118335723877
Loss at iteration 350 : 0.6214138269424438
Mean training loss eporch  236 :  0.8484582339645063
Loss at iteration 50 : 0.8736305236816406
Loss at iteration 100 : 0.9741508960723877
Loss at iteration 150 : 0.8465670943260193
Loss at iteration 200 : 0.8542826175689697
Loss at iteration 250 : 0.6313621997833252
Loss at iteration 300 : 0.694315493106842
Loss at iteration 350 : 1.102248191833496
Mean training loss eporch  237 :  0.8496886371147065
Loss at iteration 50 : 0.45852184295654297
Loss at iteration 100 : 0.8256492018699646
Loss at iteration 150 : 0.5070202946662903
Loss at iteration 200 : 0.7218417525291443
Loss at iteration 250 : 0.7829613089561462
Loss at iteration 300 : 0.9423431158065796
Loss at iteration 350 : 0.7306095361709595
Mean training loss eporch  238 :  0.8484813090039309
Loss at iteration 50 : 0.6995207667350769
Loss at iteration 100 : 1.2749347686767578
Loss at iteration 150 : 0.7891135811805725
Loss at iteration 200 : 0.8094828724861145
Loss at iteration 250 : 0.8574147820472717
Loss at iteration 300 : 0.9245812296867371
Loss at iteration 350 : 0.8414088487625122
Mean training loss eporch  239 :  0.848286695187054
Loss at iteration 50 : 0.6882555484771729
Loss at iteration 100 : 0.8800969123840332
Loss at iteration 150 : 0.6895228624343872
Loss at iteration 200 : 1.0758038759231567
Loss at iteration 250 : 0.805142879486084
Loss at iteration 300 : 0.7555978298187256
Loss at iteration 350 : 0.674071729183197
Mean training loss eporch  240 :  0.8485338388296663
Loss at iteration 50 : 1.0081276893615723
Loss at iteration 100 : 0.6906216144561768
Loss at iteration 150 : 0.6606224775314331
Loss at iteration 200 : 0.7202204465866089
Loss at iteration 250 : 0.7506452798843384
Loss at iteration 300 : 0.5468079447746277
Loss at iteration 350 : 0.874458372592926
Mean training loss eporch  241 :  0.8486882960670209
Loss at iteration 50 : 0.5395315885543823
Loss at iteration 100 : 0.7267236709594727
Loss at iteration 150 : 0.7964800596237183
Loss at iteration 200 : 0.7388142347335815
Loss at iteration 250 : 0.9006566405296326
Loss at iteration 300 : 0.8354758024215698
Loss at iteration 350 : 0.9059586524963379
Mean training loss eporch  242 :  0.8481681778948144
Loss at iteration 50 : 1.0508265495300293
Loss at iteration 100 : 0.7132523059844971
Loss at iteration 150 : 0.8726811408996582
Loss at iteration 200 : 0.7688777446746826
Loss at iteration 250 : 0.9664914608001709
Loss at iteration 300 : 0.5016342997550964
Loss at iteration 350 : 1.1010677814483643
Mean training loss eporch  243 :  0.8480787086423742
Loss at iteration 50 : 1.0671436786651611
Loss at iteration 100 : 0.8082718849182129
Loss at iteration 150 : 0.8768155574798584
Loss at iteration 200 : 0.5242182612419128
Loss at iteration 250 : 0.7645773887634277
Loss at iteration 300 : 0.863928496837616
Loss at iteration 350 : 0.6549195051193237
Mean training loss eporch  244 :  0.8485042123252122
Loss at iteration 50 : 0.8753110766410828
Loss at iteration 100 : 0.47690528631210327
Loss at iteration 150 : 0.6852989792823792
Loss at iteration 200 : 1.0569868087768555
Loss at iteration 250 : 0.8077129125595093
Loss at iteration 300 : 0.8857933282852173
Loss at iteration 350 : 0.7323116064071655
Mean training loss eporch  245 :  0.8474680736424431
Loss at iteration 50 : 1.0922069549560547
Loss at iteration 100 : 0.9510908722877502
Loss at iteration 150 : 0.7885358333587646
Loss at iteration 200 : 1.0325689315795898
Loss at iteration 250 : 0.9417052268981934
Loss at iteration 300 : 0.7743823528289795
Loss at iteration 350 : 0.7689600586891174
Mean training loss eporch  246 :  0.848443354406054
Loss at iteration 50 : 0.941295862197876
Loss at iteration 100 : 0.8845914602279663
Loss at iteration 150 : 1.024298071861267
Loss at iteration 200 : 0.6819247007369995
Loss at iteration 250 : 0.7573464512825012
Loss at iteration 300 : 1.0661994218826294
Loss at iteration 350 : 1.0153051614761353
Mean training loss eporch  247 :  0.8476737302447123
Loss at iteration 50 : 0.8125587105751038
Loss at iteration 100 : 0.9949092864990234
Loss at iteration 150 : 0.6112338304519653
Loss at iteration 200 : 0.7116152048110962
Loss at iteration 250 : 0.7912105917930603
Loss at iteration 300 : 1.2319159507751465
Loss at iteration 350 : 0.7543660402297974
Mean training loss eporch  248 :  0.8489616331126955
Loss at iteration 50 : 0.8074432611465454
Loss at iteration 100 : 0.6717908978462219
Loss at iteration 150 : 0.8639676570892334
Loss at iteration 200 : 1.230550765991211
Loss at iteration 250 : 0.915812611579895
Loss at iteration 300 : 0.9565510749816895
Loss at iteration 350 : 0.8202673196792603
Mean training loss eporch  249 :  0.8478050457422065
Loss at iteration 50 : 0.6951919794082642
Loss at iteration 100 : 1.110667109489441
Loss at iteration 150 : 0.9323017597198486
Loss at iteration 200 : 0.3347228169441223
Loss at iteration 250 : 0.8216385841369629
Loss at iteration 300 : 0.7861075401306152
Loss at iteration 350 : 0.9513187408447266
Mean training loss eporch  250 :  0.8486051877181997
Loss at iteration 50 : 1.1586154699325562
Loss at iteration 100 : 0.6554555892944336
Loss at iteration 150 : 0.6614161133766174
Loss at iteration 200 : 0.6362779140472412
Loss at iteration 250 : 0.9128984212875366
Loss at iteration 300 : 1.0316587686538696
Loss at iteration 350 : 1.0437452793121338
Mean training loss eporch  251 :  0.8483801799476463
Loss at iteration 50 : 0.943092942237854
Loss at iteration 100 : 0.769410252571106
Loss at iteration 150 : 0.5790068507194519
Loss at iteration 200 : 0.7825720906257629
Loss at iteration 250 : 0.7451839447021484
Loss at iteration 300 : 1.1835626363754272
Loss at iteration 350 : 1.0167180299758911
Mean training loss eporch  252 :  0.8485624973105375
Loss at iteration 50 : 1.0684998035430908
Loss at iteration 100 : 0.9686021208763123
Loss at iteration 150 : 0.7848267555236816
Loss at iteration 200 : 1.0511200428009033
Loss at iteration 250 : 0.9593714475631714
Loss at iteration 300 : 1.0356791019439697
Loss at iteration 350 : 0.8067623376846313
Mean training loss eporch  253 :  0.848835187929648
Loss at iteration 50 : 1.166412591934204
Loss at iteration 100 : 0.623468279838562
Loss at iteration 150 : 0.7408607006072998
Loss at iteration 200 : 0.9057328701019287
Loss at iteration 250 : 0.7919765114784241
Loss at iteration 300 : 0.6027035713195801
Loss at iteration 350 : 1.0014338493347168
Mean training loss eporch  254 :  0.8487146236593761
Loss at iteration 50 : 0.9126068353652954
Loss at iteration 100 : 0.9871660470962524
Loss at iteration 150 : 0.7197915315628052
Loss at iteration 200 : 0.8795639276504517
Loss at iteration 250 : 1.1513100862503052
Loss at iteration 300 : 1.104112982749939
Loss at iteration 350 : 0.8508776426315308
Mean training loss eporch  255 :  0.8481946720017327
Loss at iteration 50 : 0.9781684875488281
Loss at iteration 100 : 0.784692645072937
Loss at iteration 150 : 0.5321850776672363
Loss at iteration 200 : 0.9525704979896545
Loss at iteration 250 : 1.0726369619369507
Loss at iteration 300 : 0.6317376494407654
Loss at iteration 350 : 0.7283097505569458
Mean training loss eporch  256 :  0.8476601413318089
Loss at iteration 50 : 0.895620584487915
Loss at iteration 100 : 0.7879735827445984
Loss at iteration 150 : 0.805030107498169
Loss at iteration 200 : 0.5890626907348633
Loss at iteration 250 : 0.8056639432907104
Loss at iteration 300 : 0.769946813583374
Loss at iteration 350 : 0.7276886105537415
Mean training loss eporch  257 :  0.847899336978872
Loss at iteration 50 : 0.5638591051101685
Loss at iteration 100 : 0.7740417718887329
Loss at iteration 150 : 0.677635669708252
Loss at iteration 200 : 0.9269834160804749
Loss at iteration 250 : 0.9753460884094238
Loss at iteration 300 : 0.756609320640564
Loss at iteration 350 : 0.5948343276977539
Mean training loss eporch  258 :  0.8480750452431421
Loss at iteration 50 : 0.8090105652809143
Loss at iteration 100 : 0.7704924941062927
Loss at iteration 150 : 0.7815930843353271
Loss at iteration 200 : 0.9750341176986694
Loss at iteration 250 : 0.7486913204193115
Loss at iteration 300 : 0.673341691493988
Loss at iteration 350 : 0.5986195802688599
Mean training loss eporch  259 :  0.8478987050592584
Loss at iteration 50 : 0.8589552044868469
Loss at iteration 100 : 0.9264184832572937
Loss at iteration 150 : 0.7743388414382935
Loss at iteration 200 : 0.762543797492981
Loss at iteration 250 : 1.1528441905975342
Loss at iteration 300 : 0.8624956607818604
Loss at iteration 350 : 0.7531635761260986
Mean training loss eporch  260 :  0.8479845452087896
Loss at iteration 50 : 0.9386257529258728
Loss at iteration 100 : 0.9024039506912231
Loss at iteration 150 : 0.6298268437385559
Loss at iteration 200 : 0.7228818535804749
Loss at iteration 250 : 0.8307603597640991
Loss at iteration 300 : 1.1270859241485596
Loss at iteration 350 : 0.8362114429473877
Mean training loss eporch  261 :  0.8483048226467516
Loss at iteration 50 : 1.2466778755187988
Loss at iteration 100 : 0.7401050329208374
Loss at iteration 150 : 0.823784351348877
Loss at iteration 200 : 0.740227460861206
Loss at iteration 250 : 0.8180583119392395
Loss at iteration 300 : 0.8740867972373962
Loss at iteration 350 : 0.8869286775588989
Mean training loss eporch  262 :  0.8476597326142448
Loss at iteration 50 : 0.6228646039962769
Loss at iteration 100 : 0.9662232398986816
Loss at iteration 150 : 0.9867100119590759
Loss at iteration 200 : 0.906550407409668
Loss at iteration 250 : 0.9327567219734192
Loss at iteration 300 : 0.9005531668663025
Loss at iteration 350 : 0.743798017501831
Mean training loss eporch  263 :  0.8471557472748731
Loss at iteration 50 : 0.7266499996185303
Loss at iteration 100 : 0.8034478425979614
Loss at iteration 150 : 0.7283115983009338
Loss at iteration 200 : 0.651090681552887
Loss at iteration 250 : 0.7043031454086304
Loss at iteration 300 : 0.6004736423492432
Loss at iteration 350 : 0.6752628684043884
Mean training loss eporch  264 :  0.8478835239296868
Loss at iteration 50 : 0.9305410981178284
Loss at iteration 100 : 0.6895387172698975
Loss at iteration 150 : 1.342456340789795
Loss at iteration 200 : 0.8361281156539917
Loss at iteration 250 : 1.0355169773101807
Loss at iteration 300 : 0.9984245896339417
Loss at iteration 350 : 0.9569017291069031
Mean training loss eporch  265 :  0.8477050776361789
Loss at iteration 50 : 0.7225602865219116
Loss at iteration 100 : 1.0178052186965942
Loss at iteration 150 : 0.8714814186096191
Loss at iteration 200 : 0.9027596712112427
Loss at iteration 250 : 0.7414146661758423
Loss at iteration 300 : 0.8442654609680176
Loss at iteration 350 : 1.112473487854004
Mean training loss eporch  266 :  0.8471469258662885
Loss at iteration 50 : 1.0960038900375366
Loss at iteration 100 : 0.8644279837608337
Loss at iteration 150 : 0.7808948755264282
Loss at iteration 200 : 0.9229217767715454
Loss at iteration 250 : 0.7104366421699524
Loss at iteration 300 : 0.7263271808624268
Loss at iteration 350 : 0.6508887410163879
Mean training loss eporch  267 :  0.8476371310217671
Loss at iteration 50 : 0.7124863862991333
Loss at iteration 100 : 0.920316755771637
Loss at iteration 150 : 0.661443829536438
Loss at iteration 200 : 0.9626056551933289
Loss at iteration 250 : 0.6975709795951843
Loss at iteration 300 : 0.9650810956954956
Loss at iteration 350 : 1.0288562774658203
Mean training loss eporch  268 :  0.8483199249342005
Loss at iteration 50 : 0.6810163259506226
Loss at iteration 100 : 1.0821003913879395
Loss at iteration 150 : 0.6404655575752258
Loss at iteration 200 : 0.867322564125061
Loss at iteration 250 : 1.3304363489151
Loss at iteration 300 : 0.8761566877365112
Loss at iteration 350 : 0.7726349830627441
Mean training loss eporch  269 :  0.8476862837240179
Loss at iteration 50 : 0.8848093748092651
Loss at iteration 100 : 0.6529052257537842
Loss at iteration 150 : 0.9123650193214417
Loss at iteration 200 : 0.8287146687507629
Loss at iteration 250 : 0.9225600957870483
Loss at iteration 300 : 0.7864959836006165
Loss at iteration 350 : 0.9977060556411743
Mean training loss eporch  270 :  0.847815184129609
Loss at iteration 50 : 0.8078227043151855
Loss at iteration 100 : 0.6894954442977905
Loss at iteration 150 : 0.7263996005058289
Loss at iteration 200 : 1.0477149486541748
Loss at iteration 250 : 0.8422404527664185
Loss at iteration 300 : 0.624726414680481
Loss at iteration 350 : 0.9848277568817139
Mean training loss eporch  271 :  0.8481348900410234
Loss at iteration 50 : 0.761356770992279
Loss at iteration 100 : 0.6353635787963867
Loss at iteration 150 : 0.6323585510253906
Loss at iteration 200 : 1.0039353370666504
Loss at iteration 250 : 0.8030951023101807
Loss at iteration 300 : 1.0030772686004639
Loss at iteration 350 : 0.7928255796432495
Mean training loss eporch  272 :  0.8482258550073735
Loss at iteration 50 : 0.9944058656692505
Loss at iteration 100 : 0.7477685213088989
Loss at iteration 150 : 0.7588679790496826
Loss at iteration 200 : 0.9312105178833008
Loss at iteration 250 : 0.6779491901397705
Loss at iteration 300 : 0.9432785511016846
Loss at iteration 350 : 0.8757150173187256
Mean training loss eporch  273 :  0.8474430260519502
Loss at iteration 50 : 0.8103773593902588
Loss at iteration 100 : 0.9921514391899109
Loss at iteration 150 : 0.8632111549377441
Loss at iteration 200 : 1.1952171325683594
Loss at iteration 250 : 0.6022374033927917
Loss at iteration 300 : 0.6277376413345337
Loss at iteration 350 : 0.8527549505233765
Mean training loss eporch  274 :  0.8475834495491452
Loss at iteration 50 : 0.6705571413040161
Loss at iteration 100 : 0.8332865834236145
Loss at iteration 150 : 0.7056772708892822
Loss at iteration 200 : 0.7897320985794067
Loss at iteration 250 : 0.9845413565635681
Loss at iteration 300 : 1.0926324129104614
Loss at iteration 350 : 0.7877572774887085
Mean training loss eporch  275 :  0.8472337030544483
Loss at iteration 50 : 0.5222774744033813
Loss at iteration 100 : 0.7991743087768555
Loss at iteration 150 : 0.7686060070991516
Loss at iteration 200 : 0.881496787071228
Loss at iteration 250 : 0.8969143033027649
Loss at iteration 300 : 0.8090794086456299
Loss at iteration 350 : 0.7602089643478394
Mean training loss eporch  276 :  0.8480561725677006
Loss at iteration 50 : 1.026479959487915
Loss at iteration 100 : 0.9826957583427429
Loss at iteration 150 : 0.7068407535552979
Loss at iteration 200 : 0.8503335118293762
Loss at iteration 250 : 0.709836483001709
Loss at iteration 300 : 0.8282395601272583
Loss at iteration 350 : 0.9723829627037048
Mean training loss eporch  277 :  0.8480092128590931
Loss at iteration 50 : 1.0687721967697144
Loss at iteration 100 : 0.6467474699020386
Loss at iteration 150 : 0.9376726150512695
Loss at iteration 200 : 0.6566154360771179
Loss at iteration 250 : 1.0302551984786987
Loss at iteration 300 : 0.6604422926902771
Loss at iteration 350 : 0.7288980484008789
Mean training loss eporch  278 :  0.8484522688483435
Loss at iteration 50 : 0.7023469805717468
Loss at iteration 100 : 0.9455827474594116
Loss at iteration 150 : 0.7348505258560181
Loss at iteration 200 : 0.7222933769226074
Loss at iteration 250 : 0.5791575908660889
Loss at iteration 300 : 0.7831951379776001
Loss at iteration 350 : 0.8180035352706909
Mean training loss eporch  279 :  0.8480267130508625
Loss at iteration 50 : 0.5635881423950195
Loss at iteration 100 : 0.6065554618835449
Loss at iteration 150 : 0.7117115259170532
Loss at iteration 200 : 1.1111667156219482
Loss at iteration 250 : 0.8613874912261963
Loss at iteration 300 : 0.7729719877243042
Loss at iteration 350 : 0.8069711923599243
Mean training loss eporch  280 :  0.8476731378250021
Loss at iteration 50 : 1.2101869583129883
Loss at iteration 100 : 0.7881009578704834
Loss at iteration 150 : 0.5199695825576782
Loss at iteration 200 : 0.9447789192199707
Loss at iteration 250 : 0.8839541673660278
Loss at iteration 300 : 0.9739941358566284
Loss at iteration 350 : 1.1847937107086182
Mean training loss eporch  281 :  0.8475825807089528
Loss at iteration 50 : 0.7983811497688293
Loss at iteration 100 : 0.8458669185638428
Loss at iteration 150 : 1.007719874382019
Loss at iteration 200 : 0.8693751096725464
Loss at iteration 250 : 0.7898250222206116
Loss at iteration 300 : 0.7118605375289917
Loss at iteration 350 : 1.0818941593170166
Mean training loss eporch  282 :  0.8474615012842511
Loss at iteration 50 : 1.134354829788208
Loss at iteration 100 : 0.6244229078292847
Loss at iteration 150 : 0.8131624460220337
Loss at iteration 200 : 0.9838804006576538
Loss at iteration 250 : 1.2274105548858643
Loss at iteration 300 : 0.8372907638549805
Loss at iteration 350 : 0.6581428647041321
Mean training loss eporch  283 :  0.8481383232212572
Loss at iteration 50 : 0.9298946857452393
Loss at iteration 100 : 0.9366938471794128
Loss at iteration 150 : 0.9616461992263794
Loss at iteration 200 : 0.6817625761032104
Loss at iteration 250 : 1.1038918495178223
Loss at iteration 300 : 0.9835668802261353
Loss at iteration 350 : 0.8475872278213501
Mean training loss eporch  284 :  0.8469529478322892
Loss at iteration 50 : 0.8947973251342773
Loss at iteration 100 : 1.2993472814559937
Loss at iteration 150 : 0.6708356142044067
Loss at iteration 200 : 0.6859509944915771
Loss at iteration 250 : 0.8595526814460754
Loss at iteration 300 : 0.925841212272644
Loss at iteration 350 : 0.7334258556365967
Mean training loss eporch  285 :  0.8472145578217884
Loss at iteration 50 : 0.802116870880127
Loss at iteration 100 : 0.8626226186752319
Loss at iteration 150 : 0.7885723114013672
Loss at iteration 200 : 0.6733688712120056
Loss at iteration 250 : 1.1057584285736084
Loss at iteration 300 : 0.7373695373535156
Loss at iteration 350 : 0.747961163520813
Mean training loss eporch  286 :  0.8479978666103706
Loss at iteration 50 : 0.8192314505577087
Loss at iteration 100 : 0.7442992925643921
Loss at iteration 150 : 0.7779343724250793
Loss at iteration 200 : 0.8177249431610107
Loss at iteration 250 : 0.6733881235122681
Loss at iteration 300 : 0.6740413904190063
Loss at iteration 350 : 0.8336946964263916
Mean training loss eporch  287 :  0.8479706078925461
Loss at iteration 50 : 0.8721064329147339
Loss at iteration 100 : 0.8851543068885803
Loss at iteration 150 : 0.8490824103355408
Loss at iteration 200 : 1.175304651260376
Loss at iteration 250 : 0.8946647644042969
Loss at iteration 300 : 0.9876759052276611
Loss at iteration 350 : 0.9671362638473511
Mean training loss eporch  288 :  0.8484161395244497
Loss at iteration 50 : 0.9869611859321594
Loss at iteration 100 : 0.8931760787963867
Loss at iteration 150 : 0.6895856261253357
Loss at iteration 200 : 0.9878547191619873
Loss at iteration 250 : 0.7620868682861328
Loss at iteration 300 : 1.0611001253128052
Loss at iteration 350 : 0.8316320180892944
Mean training loss eporch  289 :  0.8474440213549074
Loss at iteration 50 : 0.8581616878509521
Loss at iteration 100 : 1.1500985622406006
Loss at iteration 150 : 0.6689106225967407
Loss at iteration 200 : 0.90252685546875
Loss at iteration 250 : 0.9094083905220032
Loss at iteration 300 : 0.7490220069885254
Loss at iteration 350 : 0.8637399077415466
Mean training loss eporch  290 :  0.8477489708592651
Loss at iteration 50 : 1.0809687376022339
Loss at iteration 100 : 1.3565914630889893
Loss at iteration 150 : 0.6734331846237183
Loss at iteration 200 : 0.6090676784515381
Loss at iteration 250 : 0.6389827728271484
Loss at iteration 300 : 0.6890852451324463
Loss at iteration 350 : 0.7789022922515869
Mean training loss eporch  291 :  0.8478695321335363
Loss at iteration 50 : 0.701037585735321
Loss at iteration 100 : 0.7260317802429199
Loss at iteration 150 : 1.0954080820083618
Loss at iteration 200 : 1.0229593515396118
Loss at iteration 250 : 0.9833042621612549
Loss at iteration 300 : 1.0516574382781982
Loss at iteration 350 : 0.7531194686889648
Mean training loss eporch  292 :  0.8478986743108305
Loss at iteration 50 : 0.9071942567825317
Loss at iteration 100 : 0.7143853306770325
Loss at iteration 150 : 1.0365396738052368
Loss at iteration 200 : 0.6910442113876343
Loss at iteration 250 : 1.025089979171753
Loss at iteration 300 : 0.8280002474784851
Loss at iteration 350 : 0.9554088115692139
Mean training loss eporch  293 :  0.8473741905714469
Loss at iteration 50 : 0.7110037803649902
Loss at iteration 100 : 0.6917905807495117
Loss at iteration 150 : 0.9292424917221069
Loss at iteration 200 : 1.2235198020935059
Loss at iteration 250 : 0.920753002166748
Loss at iteration 300 : 0.8205423355102539
Loss at iteration 350 : 0.8003383874893188
Mean training loss eporch  294 :  0.8471634685993195
Loss at iteration 50 : 0.671515166759491
Loss at iteration 100 : 1.0684709548950195
Loss at iteration 150 : 0.8082219362258911
Loss at iteration 200 : 1.0456998348236084
Loss at iteration 250 : 0.7628768682479858
Loss at iteration 300 : 0.7402849197387695
Loss at iteration 350 : 0.8977565765380859
Mean training loss eporch  295 :  0.8472282290458679
Loss at iteration 50 : 0.7118129730224609
Loss at iteration 100 : 1.0150642395019531
Loss at iteration 150 : 0.9796692132949829
Loss at iteration 200 : 0.941848635673523
Loss at iteration 250 : 0.9610394239425659
Loss at iteration 300 : 0.801181435585022
Loss at iteration 350 : 0.8231187462806702
Mean training loss eporch  296 :  0.8472601924308394
Loss at iteration 50 : 1.1446009874343872
Loss at iteration 100 : 1.4224148988723755
Loss at iteration 150 : 0.8048860430717468
Loss at iteration 200 : 0.6742435097694397
Loss at iteration 250 : 0.686267614364624
Loss at iteration 300 : 1.0427676439285278
Loss at iteration 350 : 0.8775874376296997
Mean training loss eporch  297 :  0.8474044855782594
Loss at iteration 50 : 0.9354245662689209
Loss at iteration 100 : 0.6830754280090332
Loss at iteration 150 : 0.8070572018623352
Loss at iteration 200 : 0.6537939310073853
Loss at iteration 250 : 0.8465723991394043
Loss at iteration 300 : 1.0131032466888428
Loss at iteration 350 : 0.757965624332428
Mean training loss eporch  298 :  0.8470134809219018
Loss at iteration 50 : 1.1981843709945679
Loss at iteration 100 : 0.897913932800293
Loss at iteration 150 : 0.9070731401443481
Loss at iteration 200 : 0.8123201131820679
Loss at iteration 250 : 0.6624090075492859
Loss at iteration 300 : 1.1483087539672852
Loss at iteration 350 : 1.1190614700317383
Mean training loss eporch  299 :  0.848900230157943
Loss at iteration 50 : 0.5837653875350952
Loss at iteration 100 : 0.8175519704818726
Loss at iteration 150 : 0.6710886359214783
Loss at iteration 200 : 0.8307767510414124
Loss at iteration 250 : 0.5947170853614807
Loss at iteration 300 : 0.7249268293380737
Loss at iteration 350 : 1.1739734411239624
Mean training loss eporch  300 :  0.8471427466818895
Loss at iteration 50 : 0.8747304677963257
Loss at iteration 100 : 0.7946740984916687
Loss at iteration 150 : 1.1061465740203857
Loss at iteration 200 : 0.6753411293029785
Loss at iteration 250 : 0.9069921970367432
Loss at iteration 300 : 0.8214084506034851
Loss at iteration 350 : 0.6611992716789246
Mean training loss eporch  301 :  0.8470464452076211
Loss at iteration 50 : 0.883941113948822
Loss at iteration 100 : 0.8511861562728882
Loss at iteration 150 : 0.784426212310791
Loss at iteration 200 : 1.1614563465118408
Loss at iteration 250 : 0.7520496845245361
Loss at iteration 300 : 0.5431296825408936
Loss at iteration 350 : 1.1890380382537842
Mean training loss eporch  302 :  0.847227904689375
Loss at iteration 50 : 0.9089943170547485
Loss at iteration 100 : 0.9246950745582581
Loss at iteration 150 : 0.8666859865188599
Loss at iteration 200 : 0.8655540943145752
Loss at iteration 250 : 0.7115835547447205
Loss at iteration 300 : 1.0739177465438843
Loss at iteration 350 : 0.9206202030181885
Mean training loss eporch  303 :  0.8473291230737847
Loss at iteration 50 : 0.6728392839431763
Loss at iteration 100 : 0.8487483859062195
Loss at iteration 150 : 1.0662813186645508
Loss at iteration 200 : 1.048795223236084
Loss at iteration 250 : 1.1269608736038208
Loss at iteration 300 : 0.5928030610084534
Loss at iteration 350 : 0.825081467628479
Mean training loss eporch  304 :  0.8475584893945664
Loss at iteration 50 : 0.86397385597229
Loss at iteration 100 : 0.8126318454742432
Loss at iteration 150 : 0.6407653093338013
Loss at iteration 200 : 1.199810266494751
Loss at iteration 250 : 0.8559623956680298
Loss at iteration 300 : 0.7022799253463745
Loss at iteration 350 : 0.6729310750961304
Mean training loss eporch  305 :  0.8476920798026696
Loss at iteration 50 : 0.7083777785301208
Loss at iteration 100 : 0.5765721797943115
Loss at iteration 150 : 0.9122398495674133
Loss at iteration 200 : 0.7322912216186523
Loss at iteration 250 : 0.7966646552085876
Loss at iteration 300 : 0.7398802042007446
Loss at iteration 350 : 0.7136591672897339
Mean training loss eporch  306 :  0.8469648591425053
Loss at iteration 50 : 0.9343338012695312
Loss at iteration 100 : 0.9353132843971252
Loss at iteration 150 : 0.7599921226501465
Loss at iteration 200 : 0.9508694410324097
Loss at iteration 250 : 0.8967022895812988
Loss at iteration 300 : 0.8497027158737183
Loss at iteration 350 : 0.8472058773040771
Mean training loss eporch  307 :  0.8478188907343244
Loss at iteration 50 : 0.6693893074989319
Loss at iteration 100 : 0.8092040419578552
Loss at iteration 150 : 0.6897653937339783
Loss at iteration 200 : 0.9891564846038818
Loss at iteration 250 : 0.9388082027435303
Loss at iteration 300 : 0.868644654750824
Loss at iteration 350 : 0.6909031867980957
Mean training loss eporch  308 :  0.847195280449731
Loss at iteration 50 : 0.7512925863265991
Loss at iteration 100 : 0.8745643496513367
Loss at iteration 150 : 0.8136215209960938
Loss at iteration 200 : 0.9126880764961243
Loss at iteration 250 : 1.2486357688903809
Loss at iteration 300 : 0.8091608285903931
Loss at iteration 350 : 0.6681567430496216
Mean training loss eporch  309 :  0.8464203662973232
Loss at iteration 50 : 0.7629179954528809
Loss at iteration 100 : 0.86765456199646
Loss at iteration 150 : 0.591621994972229
Loss at iteration 200 : 0.6460542678833008
Loss at iteration 250 : 0.7534671425819397
Loss at iteration 300 : 0.7988505363464355
Loss at iteration 350 : 0.8919493556022644
Mean training loss eporch  310 :  0.8479454834309835
Loss at iteration 50 : 0.6736308336257935
Loss at iteration 100 : 0.657544732093811
Loss at iteration 150 : 0.6935480237007141
Loss at iteration 200 : 0.9715849161148071
Loss at iteration 250 : 0.9103846549987793
Loss at iteration 300 : 0.9378747940063477
Loss at iteration 350 : 0.8411266207695007
Mean training loss eporch  311 :  0.8474876041765567
Loss at iteration 50 : 0.8702518343925476
Loss at iteration 100 : 0.9174402952194214
Loss at iteration 150 : 0.806887149810791
Loss at iteration 200 : 0.967914342880249
Loss at iteration 250 : 0.8644344806671143
Loss at iteration 300 : 0.7861793041229248
Loss at iteration 350 : 0.7662104964256287
Mean training loss eporch  312 :  0.8472626330675902
Loss at iteration 50 : 0.640774667263031
Loss at iteration 100 : 0.9691890478134155
Loss at iteration 150 : 0.7102031111717224
Loss at iteration 200 : 0.8365127444267273
Loss at iteration 250 : 0.9637050032615662
Loss at iteration 300 : 0.9382262229919434
Loss at iteration 350 : 1.0028011798858643
Mean training loss eporch  313 :  0.8478740506544316
Loss at iteration 50 : 0.7693606615066528
Loss at iteration 100 : 0.7570294141769409
Loss at iteration 150 : 0.7664328217506409
Loss at iteration 200 : 0.8608739376068115
Loss at iteration 250 : 0.804317831993103
Loss at iteration 300 : 0.7936667203903198
Loss at iteration 350 : 0.7472379207611084
Mean training loss eporch  314 :  0.8465683336453463
Loss at iteration 50 : 0.8302463293075562
Loss at iteration 100 : 0.9162039160728455
Loss at iteration 150 : 0.7270865440368652
Loss at iteration 200 : 0.9012761116027832
Loss at iteration 250 : 0.70762038230896
Loss at iteration 300 : 0.9627273082733154
Loss at iteration 350 : 0.8805611729621887
Mean training loss eporch  315 :  0.8470505598991637
Loss at iteration 50 : 0.9051035046577454
Loss at iteration 100 : 0.7440027594566345
Loss at iteration 150 : 1.0109142065048218
Loss at iteration 200 : 0.7830456495285034
Loss at iteration 250 : 0.4521990418434143
Loss at iteration 300 : 0.8835554122924805
Loss at iteration 350 : 1.0064557790756226
Mean training loss eporch  316 :  0.8472371665888994
Loss at iteration 50 : 0.7383356094360352
Loss at iteration 100 : 0.8986027836799622
Loss at iteration 150 : 1.0229344367980957
Loss at iteration 200 : 0.595892071723938
Loss at iteration 250 : 0.8646268844604492
Loss at iteration 300 : 0.47922393679618835
Loss at iteration 350 : 0.7963407635688782
Mean training loss eporch  317 :  0.8474649059236365
Loss at iteration 50 : 0.925687849521637
Loss at iteration 100 : 0.6592612266540527
Loss at iteration 150 : 0.7178516387939453
Loss at iteration 200 : 0.606259822845459
Loss at iteration 250 : 0.960899829864502
Loss at iteration 300 : 0.6201686859130859
Loss at iteration 350 : 0.8891440629959106
Mean training loss eporch  318 :  0.8481533180468928
Loss at iteration 50 : 0.8105943202972412
Loss at iteration 100 : 0.9579014182090759
Loss at iteration 150 : 0.7624139785766602
Loss at iteration 200 : 0.8796384930610657
Loss at iteration 250 : 0.8361311554908752
Loss at iteration 300 : 0.8018840551376343
Loss at iteration 350 : 0.6875277757644653
Mean training loss eporch  319 :  0.8472111720256704
Loss at iteration 50 : 0.9026422500610352
Loss at iteration 100 : 0.8327820301055908
Loss at iteration 150 : 0.732030987739563
Loss at iteration 200 : 0.7281505465507507
Loss at iteration 250 : 0.7102155685424805
Loss at iteration 300 : 0.6888436079025269
Loss at iteration 350 : 0.8429485559463501
Mean training loss eporch  320 :  0.8475398634949689
Loss at iteration 50 : 0.7640129327774048
Loss at iteration 100 : 0.6686983108520508
Loss at iteration 150 : 0.8259050846099854
Loss at iteration 200 : 0.9416977167129517
Loss at iteration 250 : 0.7491740584373474
Loss at iteration 300 : 0.8759413957595825
Loss at iteration 350 : 0.9102365374565125
Mean training loss eporch  321 :  0.8480711510730168
Loss at iteration 50 : 0.5595446228981018
Loss at iteration 100 : 0.6828230619430542
Loss at iteration 150 : 0.8579828143119812
Loss at iteration 200 : 0.5035856366157532
Loss at iteration 250 : 0.8434682488441467
Loss at iteration 300 : 0.7764972448348999
Loss at iteration 350 : 1.1417232751846313
Mean training loss eporch  322 :  0.8467761787472579
Loss at iteration 50 : 0.9087742567062378
Loss at iteration 100 : 0.9476699233055115
Loss at iteration 150 : 1.0753223896026611
Loss at iteration 200 : 0.8948653936386108
Loss at iteration 250 : 0.8102391362190247
Loss at iteration 300 : 0.987128734588623
Loss at iteration 350 : 0.6664988994598389
Mean training loss eporch  323 :  0.8473057493015572
Loss at iteration 50 : 0.707073450088501
Loss at iteration 100 : 0.690183162689209
Loss at iteration 150 : 0.7863391041755676
Loss at iteration 200 : 0.8435967564582825
Loss at iteration 250 : 0.8204736709594727
Loss at iteration 300 : 0.7062612771987915
Loss at iteration 350 : 1.16945481300354
Mean training loss eporch  324 :  0.8468979142961048
Loss at iteration 50 : 0.5709354877471924
Loss at iteration 100 : 1.0908756256103516
Loss at iteration 150 : 0.7155479192733765
Loss at iteration 200 : 0.8310869336128235
Loss at iteration 250 : 0.655739426612854
Loss at iteration 300 : 1.109775424003601
Loss at iteration 350 : 0.8301045894622803
Mean training loss eporch  325 :  0.846954028363581
Loss at iteration 50 : 0.8799014091491699
Loss at iteration 100 : 0.775703489780426
Loss at iteration 150 : 0.7148169279098511
Loss at iteration 200 : 0.7989293336868286
Loss at iteration 250 : 1.0450414419174194
Loss at iteration 300 : 0.8563976287841797
Loss at iteration 350 : 0.8783013820648193
Mean training loss eporch  326 :  0.8481603577023461
Loss at iteration 50 : 0.5449587106704712
Loss at iteration 100 : 0.8232892751693726
Loss at iteration 150 : 0.8332313299179077
Loss at iteration 200 : 0.7428649067878723
Loss at iteration 250 : 0.555527925491333
Loss at iteration 300 : 0.801866888999939
Loss at iteration 350 : 0.803082287311554
Mean training loss eporch  327 :  0.847265222085216
Loss at iteration 50 : 1.210761547088623
Loss at iteration 100 : 0.6293998956680298
Loss at iteration 150 : 0.7807478904724121
Loss at iteration 200 : 0.8475335836410522
Loss at iteration 250 : 0.7072643041610718
Loss at iteration 300 : 1.046269178390503
Loss at iteration 350 : 0.7888020277023315
Mean training loss eporch  328 :  0.8469188660383224
Loss at iteration 50 : 1.0057992935180664
Loss at iteration 100 : 0.7725791335105896
Loss at iteration 150 : 0.9990551471710205
Loss at iteration 200 : 0.9595875144004822
Loss at iteration 250 : 0.7091661691665649
Loss at iteration 300 : 0.8167908191680908
Loss at iteration 350 : 0.8485472202301025
Mean training loss eporch  329 :  0.8471466328889604
Loss at iteration 50 : 0.8012377619743347
Loss at iteration 100 : 0.7492082118988037
Loss at iteration 150 : 0.8045542240142822
Loss at iteration 200 : 0.8581231236457825
Loss at iteration 250 : 0.8638413548469543
Loss at iteration 300 : 0.604789137840271
Loss at iteration 350 : 1.0330986976623535
Mean training loss eporch  330 :  0.8478120062401686
Loss at iteration 50 : 0.6004630327224731
Loss at iteration 100 : 1.1463767290115356
Loss at iteration 150 : 0.6424910426139832
Loss at iteration 200 : 0.8086329698562622
Loss at iteration 250 : 0.4605081081390381
Loss at iteration 300 : 0.7878422737121582
Loss at iteration 350 : 0.6549454927444458
Mean training loss eporch  331 :  0.8472013405706517
Loss at iteration 50 : 0.9860666990280151
Loss at iteration 100 : 0.8459603786468506
Loss at iteration 150 : 1.0926964282989502
Loss at iteration 200 : 0.7303048372268677
Loss at iteration 250 : 0.9093503952026367
Loss at iteration 300 : 1.1250056028366089
Loss at iteration 350 : 0.7726926207542419
Mean training loss eporch  332 :  0.8462379344556697
Loss at iteration 50 : 0.8779215812683105
Loss at iteration 100 : 0.9425086379051208
Loss at iteration 150 : 0.7843869924545288
Loss at iteration 200 : 0.715380847454071
Loss at iteration 250 : 0.7236063480377197
Loss at iteration 300 : 0.8455873727798462
Loss at iteration 350 : 0.5417383909225464
Mean training loss eporch  333 :  0.8468064886552317
Loss at iteration 50 : 0.7295333743095398
Loss at iteration 100 : 0.829684853553772
Loss at iteration 150 : 0.7829819321632385
Loss at iteration 200 : 0.6816084980964661
Loss at iteration 250 : 0.9653760194778442
Loss at iteration 300 : 0.8430109620094299
Loss at iteration 350 : 0.6510307788848877
Mean training loss eporch  334 :  0.8473743667047491
Loss at iteration 50 : 1.0894752740859985
Loss at iteration 100 : 1.0305490493774414
Loss at iteration 150 : 0.7683863639831543
Loss at iteration 200 : 0.5707663893699646
Loss at iteration 250 : 0.8093347549438477
Loss at iteration 300 : 1.0603926181793213
Loss at iteration 350 : 0.9824498295783997
Mean training loss eporch  335 :  0.8464661011147121
Loss at iteration 50 : 0.6572302579879761
Loss at iteration 100 : 0.883033037185669
Loss at iteration 150 : 1.1655635833740234
Loss at iteration 200 : 1.0745062828063965
Loss at iteration 250 : 0.9837404489517212
Loss at iteration 300 : 1.0871422290802002
Loss at iteration 350 : 0.6643519997596741
Mean training loss eporch  336 :  0.8473294036728996
Loss at iteration 50 : 0.7244284152984619
Loss at iteration 100 : 0.7436736822128296
Loss at iteration 150 : 0.6745624542236328
Loss at iteration 200 : 0.8508274555206299
Loss at iteration 250 : 0.7569519877433777
Loss at iteration 300 : 0.8575687408447266
Loss at iteration 350 : 0.7798397541046143
Mean training loss eporch  337 :  0.8476511422130797
Loss at iteration 50 : 0.9771281480789185
Loss at iteration 100 : 0.574944794178009
Loss at iteration 150 : 0.7178963422775269
Loss at iteration 200 : 1.1224415302276611
Loss at iteration 250 : 0.7457046508789062
Loss at iteration 300 : 0.9873349666595459
Loss at iteration 350 : 0.9420688152313232
Mean training loss eporch  338 :  0.8472202046523019
Loss at iteration 50 : 0.9765719175338745
Loss at iteration 100 : 1.1738399267196655
Loss at iteration 150 : 1.0890289545059204
Loss at iteration 200 : 0.9572581648826599
Loss at iteration 250 : 0.6148109436035156
Loss at iteration 300 : 1.2527087926864624
Loss at iteration 350 : 0.8055137395858765
Mean training loss eporch  339 :  0.8463374947113965
Loss at iteration 50 : 1.2135612964630127
Loss at iteration 100 : 0.9009255170822144
Loss at iteration 150 : 0.8017098307609558
Loss at iteration 200 : 0.9980640411376953
Loss at iteration 250 : 1.0526353120803833
Loss at iteration 300 : 0.8294886946678162
Loss at iteration 350 : 0.7314227819442749
Mean training loss eporch  340 :  0.8467338413946213
Loss at iteration 50 : 0.7306711673736572
Loss at iteration 100 : 0.8645908236503601
Loss at iteration 150 : 0.8880329728126526
Loss at iteration 200 : 0.6948014497756958
Loss at iteration 250 : 0.8058840036392212
Loss at iteration 300 : 0.8010513186454773
Loss at iteration 350 : 0.6384993195533752
Mean training loss eporch  341 :  0.8474131772915522
Loss at iteration 50 : 1.134506344795227
Loss at iteration 100 : 0.9332736730575562
Loss at iteration 150 : 0.638799786567688
Loss at iteration 200 : 0.5738668441772461
Loss at iteration 250 : 0.9095082879066467
Loss at iteration 300 : 0.7807838320732117
Loss at iteration 350 : 0.8599487543106079
Mean training loss eporch  342 :  0.8468325500765805
Loss at iteration 50 : 0.938428521156311
Loss at iteration 100 : 0.7501102685928345
Loss at iteration 150 : 0.5667639970779419
Loss at iteration 200 : 0.6775075793266296
Loss at iteration 250 : 0.8555703163146973
Loss at iteration 300 : 1.0375360250473022
Loss at iteration 350 : 0.8936759829521179
Mean training loss eporch  343 :  0.8472676553108074
Loss at iteration 50 : 1.0020756721496582
Loss at iteration 100 : 0.8995159268379211
Loss at iteration 150 : 1.0857398509979248
Loss at iteration 200 : 0.5394411087036133
Loss at iteration 250 : 0.9343250393867493
Loss at iteration 300 : 0.6261435151100159
Loss at iteration 350 : 0.733178973197937
Mean training loss eporch  344 :  0.8462853467969037
Loss at iteration 50 : 0.5852859020233154
Loss at iteration 100 : 1.0982942581176758
Loss at iteration 150 : 0.7786879539489746
Loss at iteration 200 : 0.8261502981185913
Loss at iteration 250 : 1.2778818607330322
Loss at iteration 300 : 0.6776756644248962
Loss at iteration 350 : 0.9583384394645691
Mean training loss eporch  345 :  0.8477367608162462
Loss at iteration 50 : 0.7047852277755737
Loss at iteration 100 : 0.9839493632316589
Loss at iteration 150 : 0.7771669030189514
Loss at iteration 200 : 0.6578934788703918
Loss at iteration 250 : 0.6477463245391846
Loss at iteration 300 : 0.8215875625610352
Loss at iteration 350 : 0.8181856274604797
Mean training loss eporch  346 :  0.8466445026258943
Loss at iteration 50 : 0.7912937998771667
Loss at iteration 100 : 0.9149624109268188
Loss at iteration 150 : 0.5976913571357727
Loss at iteration 200 : 1.0033142566680908
Loss at iteration 250 : 0.753402829170227
Loss at iteration 300 : 0.8721191883087158
Loss at iteration 350 : 1.1702640056610107
Mean training loss eporch  347 :  0.8478829250449226
Loss at iteration 50 : 1.0465320348739624
Loss at iteration 100 : 0.8831383585929871
Loss at iteration 150 : 0.870508074760437
Loss at iteration 200 : 0.5876932144165039
Loss at iteration 250 : 0.6404085159301758
Loss at iteration 300 : 1.1695648431777954
Loss at iteration 350 : 0.8422539234161377
Mean training loss eporch  348 :  0.8469176800162704
Loss at iteration 50 : 0.8173704743385315
Loss at iteration 100 : 0.8426419496536255
Loss at iteration 150 : 0.8236233592033386
Loss at iteration 200 : 0.9128775596618652
Loss at iteration 250 : 0.8808625340461731
Loss at iteration 300 : 0.6311271786689758
Loss at iteration 350 : 0.8766879439353943
Mean training loss eporch  349 :  0.8469426223525295
Loss at iteration 50 : 0.866196870803833
Loss at iteration 100 : 1.137139916419983
Loss at iteration 150 : 0.7871057391166687
Loss at iteration 200 : 1.2192490100860596
Loss at iteration 250 : 0.7957441806793213
Loss at iteration 300 : 0.7020901441574097
Loss at iteration 350 : 1.0663998126983643
Mean training loss eporch  350 :  0.8460779153007679
Loss at iteration 50 : 0.7558271884918213
Loss at iteration 100 : 0.8586755990982056
Loss at iteration 150 : 0.9058234691619873
Loss at iteration 200 : 1.355970025062561
Loss at iteration 250 : 0.6488882303237915
Loss at iteration 300 : 0.5635136365890503
Loss at iteration 350 : 1.23134446144104
Mean training loss eporch  351 :  0.8463695990660834
Loss at iteration 50 : 0.7547515630722046
Loss at iteration 100 : 0.7407256364822388
Loss at iteration 150 : 0.8199928998947144
Loss at iteration 200 : 1.0637558698654175
Loss at iteration 250 : 0.687340259552002
Loss at iteration 300 : 0.6465283632278442
Loss at iteration 350 : 0.7249858379364014
Mean training loss eporch  352 :  0.846611646905778
Loss at iteration 50 : 0.9321326017379761
Loss at iteration 100 : 0.6312445402145386
Loss at iteration 150 : 0.7746315002441406
Loss at iteration 200 : 0.940947413444519
Loss at iteration 250 : 0.6859415769577026
Loss at iteration 300 : 0.736458420753479
Loss at iteration 350 : 0.6657451391220093
Mean training loss eporch  353 :  0.845450040682283
Loss at iteration 50 : 0.9526609182357788
Loss at iteration 100 : 0.7102679014205933
Loss at iteration 150 : 0.9170751571655273
Loss at iteration 200 : 0.857513427734375
Loss at iteration 250 : 0.7040275931358337
Loss at iteration 300 : 0.9486070871353149
Loss at iteration 350 : 0.7125521898269653
Mean training loss eporch  354 :  0.8471102547393274
Loss at iteration 50 : 0.7414741516113281
Loss at iteration 100 : 0.9541988372802734
Loss at iteration 150 : 0.8768875598907471
Loss at iteration 200 : 0.8021325469017029
Loss at iteration 250 : 0.7012964487075806
Loss at iteration 300 : 0.6866773366928101
Loss at iteration 350 : 0.5876663327217102
Mean training loss eporch  355 :  0.8463137398951899
Loss at iteration 50 : 0.8829894661903381
Loss at iteration 100 : 0.9276829361915588
Loss at iteration 150 : 0.8549251556396484
Loss at iteration 200 : 0.6018913388252258
Loss at iteration 250 : 0.7904042601585388
Loss at iteration 300 : 1.087244987487793
Loss at iteration 350 : 0.9768447279930115
Mean training loss eporch  356 :  0.8462940251858777
Loss at iteration 50 : 0.6726808547973633
Loss at iteration 100 : 0.8548870086669922
Loss at iteration 150 : 0.9916052222251892
Loss at iteration 200 : 0.9090073704719543
Loss at iteration 250 : 1.339613676071167
Loss at iteration 300 : 0.9141343832015991
Loss at iteration 350 : 0.598444938659668
Mean training loss eporch  357 :  0.8460945655744543
Loss at iteration 50 : 0.9058597087860107
Loss at iteration 100 : 0.8580855131149292
Loss at iteration 150 : 0.7961441278457642
Loss at iteration 200 : 0.918929934501648
Loss at iteration 250 : 0.830172598361969
Loss at iteration 300 : 0.9671725034713745
Loss at iteration 350 : 0.9335142374038696
Mean training loss eporch  358 :  0.8462337896464363
Loss at iteration 50 : 0.7680389285087585
Loss at iteration 100 : 1.1885111331939697
Loss at iteration 150 : 0.9210584163665771
Loss at iteration 200 : 0.6537790298461914
Loss at iteration 250 : 1.0485061407089233
Loss at iteration 300 : 0.902714729309082
Loss at iteration 350 : 0.6589816808700562
Mean training loss eporch  359 :  0.8465915361724833
Loss at iteration 50 : 0.7808591723442078
Loss at iteration 100 : 0.6307294964790344
Loss at iteration 150 : 0.8008306622505188
Loss at iteration 200 : 1.2993371486663818
Loss at iteration 250 : 0.8517059087753296
Loss at iteration 300 : 0.8196535110473633
Loss at iteration 350 : 0.7602286338806152
Mean training loss eporch  360 :  0.8464925114124541
Loss at iteration 50 : 0.8364541530609131
Loss at iteration 100 : 0.8992137908935547
Loss at iteration 150 : 1.0701649188995361
Loss at iteration 200 : 0.7183495759963989
Loss at iteration 250 : 0.6539055109024048
Loss at iteration 300 : 0.6851465702056885
Loss at iteration 350 : 0.8044995069503784
Mean training loss eporch  361 :  0.8458257874168417
Loss at iteration 50 : 0.738203227519989
Loss at iteration 100 : 0.6370864510536194
Loss at iteration 150 : 0.7771409749984741
Loss at iteration 200 : 0.7950351238250732
Loss at iteration 250 : 0.9850476384162903
Loss at iteration 300 : 0.8776835203170776
Loss at iteration 350 : 1.072648286819458
Mean training loss eporch  362 :  0.8457695436540735
Loss at iteration 50 : 0.6577191352844238
Loss at iteration 100 : 0.9482001662254333
Loss at iteration 150 : 0.8866621255874634
Loss at iteration 200 : 0.7129856944084167
Loss at iteration 250 : 0.8356401324272156
Loss at iteration 300 : 1.0832533836364746
Loss at iteration 350 : 0.6678251624107361
Mean training loss eporch  363 :  0.8470991076458068
Loss at iteration 50 : 1.0524799823760986
Loss at iteration 100 : 0.7166423797607422
Loss at iteration 150 : 0.7467882633209229
Loss at iteration 200 : 0.9840916395187378
Loss at iteration 250 : 0.6453756093978882
Loss at iteration 300 : 0.9304195046424866
Loss at iteration 350 : 0.7592816352844238
Mean training loss eporch  364 :  0.8468864312562993
Loss at iteration 50 : 1.3450257778167725
Loss at iteration 100 : 0.8154299855232239
Loss at iteration 150 : 1.0570769309997559
Loss at iteration 200 : 0.5970945358276367
Loss at iteration 250 : 1.0500277280807495
Loss at iteration 300 : 0.8051790595054626
Loss at iteration 350 : 0.9524595737457275
Mean training loss eporch  365 :  0.847096355424987
Loss at iteration 50 : 0.9219399094581604
Loss at iteration 100 : 0.9802639484405518
Loss at iteration 150 : 0.835206925868988
Loss at iteration 200 : 0.962402880191803
Loss at iteration 250 : 0.8335315585136414
Loss at iteration 300 : 0.848813533782959
Loss at iteration 350 : 0.5935351848602295
Mean training loss eporch  366 :  0.8472183863952677
Loss at iteration 50 : 1.1705379486083984
Loss at iteration 100 : 1.0363478660583496
Loss at iteration 150 : 1.2520246505737305
Loss at iteration 200 : 1.0164964199066162
Loss at iteration 250 : 0.9206427335739136
Loss at iteration 300 : 0.7553589344024658
Loss at iteration 350 : 0.9304453134536743
Mean training loss eporch  367 :  0.8476410521558984
Loss at iteration 50 : 0.871173620223999
Loss at iteration 100 : 0.9574630260467529
Loss at iteration 150 : 0.9912198781967163
Loss at iteration 200 : 0.8023315072059631
Loss at iteration 250 : 0.513052225112915
Loss at iteration 300 : 0.7846208810806274
Loss at iteration 350 : 1.1435978412628174
Mean training loss eporch  368 :  0.846977640081335
Loss at iteration 50 : 0.8331055641174316
Loss at iteration 100 : 0.986970841884613
Loss at iteration 150 : 0.8913223743438721
Loss at iteration 200 : 0.7966400980949402
Loss at iteration 250 : 0.8718353509902954
Loss at iteration 300 : 0.5362225770950317
Loss at iteration 350 : 0.842544674873352
Mean training loss eporch  369 :  0.846054804072809
Loss at iteration 50 : 0.8038995862007141
Loss at iteration 100 : 0.6596996784210205
Loss at iteration 150 : 1.0142937898635864
Loss at iteration 200 : 1.0591270923614502
Loss at iteration 250 : 0.7244127988815308
Loss at iteration 300 : 0.820007860660553
Loss at iteration 350 : 0.7377620339393616
Mean training loss eporch  370 :  0.8467660829346016
Loss at iteration 50 : 0.8917251825332642
Loss at iteration 100 : 0.7899976968765259
Loss at iteration 150 : 0.7468819618225098
Loss at iteration 200 : 0.9227985143661499
Loss at iteration 250 : 0.5904725790023804
Loss at iteration 300 : 1.0122753381729126
Loss at iteration 350 : 1.022369384765625
Mean training loss eporch  371 :  0.8459397109728011
Loss at iteration 50 : 1.0822525024414062
Loss at iteration 100 : 1.2447562217712402
Loss at iteration 150 : 0.942297101020813
Loss at iteration 200 : 1.0396723747253418
Loss at iteration 250 : 0.7821478843688965
Loss at iteration 300 : 0.6165231466293335
Loss at iteration 350 : 0.7525244355201721
Mean training loss eporch  372 :  0.8456611551304973
Loss at iteration 50 : 1.036037564277649
Loss at iteration 100 : 0.7761020064353943
Loss at iteration 150 : 0.7036113142967224
Loss at iteration 200 : 0.8932588696479797
Loss at iteration 250 : 0.7836426496505737
Loss at iteration 300 : 0.6761177182197571
Loss at iteration 350 : 0.79263836145401
Mean training loss eporch  373 :  0.8464185347948124
Loss at iteration 50 : 0.8386521339416504
Loss at iteration 100 : 1.0391477346420288
Loss at iteration 150 : 0.7643444538116455
Loss at iteration 200 : 1.0088114738464355
Loss at iteration 250 : 0.8481025695800781
Loss at iteration 300 : 0.5830960273742676
Loss at iteration 350 : 0.8321985006332397
Mean training loss eporch  374 :  0.8476311569176023
Loss at iteration 50 : 0.7330423593521118
Loss at iteration 100 : 0.9985024929046631
Loss at iteration 150 : 0.9746490716934204
Loss at iteration 200 : 0.6885303258895874
Loss at iteration 250 : 0.8747154474258423
Loss at iteration 300 : 1.1005103588104248
Loss at iteration 350 : 0.6583478450775146
Mean training loss eporch  375 :  0.8462035980016466
Loss at iteration 50 : 0.7410430908203125
Loss at iteration 100 : 0.6998211145401001
Loss at iteration 150 : 0.8673977851867676
Loss at iteration 200 : 0.7878182530403137
Loss at iteration 250 : 1.0279167890548706
Loss at iteration 300 : 0.6158497929573059
Loss at iteration 350 : 0.8680880665779114
Mean training loss eporch  376 :  0.846115086917524
Loss at iteration 50 : 0.7005710601806641
Loss at iteration 100 : 1.315732717514038
Loss at iteration 150 : 0.6288749575614929
Loss at iteration 200 : 0.7875534892082214
Loss at iteration 250 : 1.1993143558502197
Loss at iteration 300 : 1.1581909656524658
Loss at iteration 350 : 0.6168698668479919
Mean training loss eporch  377 :  0.847033189875739
Loss at iteration 50 : 0.998917281627655
Loss at iteration 100 : 0.9214910268783569
Loss at iteration 150 : 1.1619853973388672
Loss at iteration 200 : 0.6923770308494568
Loss at iteration 250 : 1.288706660270691
Loss at iteration 300 : 0.6817172169685364
Loss at iteration 350 : 1.069496512413025
Mean training loss eporch  378 :  0.8462049612607906
Loss at iteration 50 : 0.5831046104431152
Loss at iteration 100 : 1.0555658340454102
Loss at iteration 150 : 0.9853886961936951
Loss at iteration 200 : 0.7497973442077637
Loss at iteration 250 : 0.9532054662704468
Loss at iteration 300 : 0.7074577212333679
Loss at iteration 350 : 0.8047580718994141
Mean training loss eporch  379 :  0.8465579243564101
Loss at iteration 50 : 0.6271622180938721
Loss at iteration 100 : 1.0108723640441895
Loss at iteration 150 : 1.0231187343597412
Loss at iteration 200 : 0.8324385285377502
Loss at iteration 250 : 0.8228827714920044
Loss at iteration 300 : 1.0442898273468018
Loss at iteration 350 : 0.7456252574920654
Mean training loss eporch  380 :  0.846632063073456
Loss at iteration 50 : 0.7342832088470459
Loss at iteration 100 : 0.6938909292221069
Loss at iteration 150 : 0.8564623594284058
Loss at iteration 200 : 0.8188796043395996
Loss at iteration 250 : 0.9694573879241943
Loss at iteration 300 : 0.7692402601242065
Loss at iteration 350 : 0.9984468221664429
Mean training loss eporch  381 :  0.8471907574348349
Loss at iteration 50 : 0.5755265951156616
Loss at iteration 100 : 0.805719256401062
Loss at iteration 150 : 0.7800008654594421
Loss at iteration 200 : 0.7213730812072754
Loss at iteration 250 : 0.5669882893562317
Loss at iteration 300 : 0.7535529136657715
Loss at iteration 350 : 0.6353060007095337
Mean training loss eporch  382 :  0.8464385665283001
Loss at iteration 50 : 0.8833713531494141
Loss at iteration 100 : 0.8858985900878906
Loss at iteration 150 : 0.7174917459487915
Loss at iteration 200 : 1.0888547897338867
Loss at iteration 250 : 0.9181670546531677
Loss at iteration 300 : 0.763309121131897
Loss at iteration 350 : 0.8752927780151367
Mean training loss eporch  383 :  0.8468346509037825
Loss at iteration 50 : 0.8732633590698242
Loss at iteration 100 : 1.2743427753448486
Loss at iteration 150 : 0.6326714754104614
Loss at iteration 200 : 0.7431201338768005
Loss at iteration 250 : 0.7184810042381287
Loss at iteration 300 : 0.7818094491958618
Loss at iteration 350 : 0.6555438041687012
Mean training loss eporch  384 :  0.8462844862351342
Loss at iteration 50 : 0.8378739356994629
Loss at iteration 100 : 1.0250767469406128
Loss at iteration 150 : 0.8458056449890137
Loss at iteration 200 : 0.9140710830688477
Loss at iteration 250 : 0.9528154730796814
Loss at iteration 300 : 0.7979989647865295
Loss at iteration 350 : 0.8360522389411926
Mean training loss eporch  385 :  0.8462615995495407
Loss at iteration 50 : 0.672095775604248
Loss at iteration 100 : 0.8826191425323486
Loss at iteration 150 : 0.984249472618103
Loss at iteration 200 : 0.8949784636497498
Loss at iteration 250 : 0.9329181909561157
Loss at iteration 300 : 0.9665241837501526
Loss at iteration 350 : 0.6738319396972656
Mean training loss eporch  386 :  0.8463071164473024
Loss at iteration 50 : 0.8063057065010071
Loss at iteration 100 : 0.706761360168457
Loss at iteration 150 : 1.0142890214920044
Loss at iteration 200 : 0.5930259227752686
Loss at iteration 250 : 1.0648421049118042
Loss at iteration 300 : 0.8996622562408447
Loss at iteration 350 : 0.7506922483444214
Mean training loss eporch  387 :  0.8461285159386024
Loss at iteration 50 : 0.5741786956787109
Loss at iteration 100 : 0.6761568784713745
Loss at iteration 150 : 0.9298167824745178
Loss at iteration 200 : 0.8382174968719482
Loss at iteration 250 : 0.8233340978622437
Loss at iteration 300 : 0.7707264423370361
Loss at iteration 350 : 1.0185812711715698
Mean training loss eporch  388 :  0.8461150884943665
Loss at iteration 50 : 0.9932444095611572
Loss at iteration 100 : 0.9058994650840759
Loss at iteration 150 : 0.8393386602401733
Loss at iteration 200 : 1.0644692182540894
Loss at iteration 250 : 0.965851366519928
Loss at iteration 300 : 1.1793302297592163
Loss at iteration 350 : 0.7886790633201599
Mean training loss eporch  389 :  0.8465943397983672
Loss at iteration 50 : 0.8137010335922241
Loss at iteration 100 : 0.6399837732315063
Loss at iteration 150 : 0.7263185977935791
Loss at iteration 200 : 1.0484588146209717
Loss at iteration 250 : 1.1115760803222656
Loss at iteration 300 : 0.4783109724521637
Loss at iteration 350 : 0.8673578500747681
Mean training loss eporch  390 :  0.8452415929111854
Loss at iteration 50 : 0.8577718138694763
Loss at iteration 100 : 0.6825128793716431
Loss at iteration 150 : 0.9464528560638428
Loss at iteration 200 : 0.7694828510284424
Loss at iteration 250 : 1.0199018716812134
Loss at iteration 300 : 0.7944002747535706
Loss at iteration 350 : 0.5933531522750854
Mean training loss eporch  391 :  0.8460548032843878
Loss at iteration 50 : 0.6308841705322266
Loss at iteration 100 : 0.7074865698814392
Loss at iteration 150 : 0.5670153498649597
Loss at iteration 200 : 0.974955141544342
Loss at iteration 250 : 1.1604204177856445
Loss at iteration 300 : 0.651934027671814
Loss at iteration 350 : 1.0097525119781494
Mean training loss eporch  392 :  0.8461186238539913
Loss at iteration 50 : 0.9338557124137878
Loss at iteration 100 : 0.9668477773666382
Loss at iteration 150 : 1.0723164081573486
Loss at iteration 200 : 0.7693672180175781
Loss at iteration 250 : 0.8643010854721069
Loss at iteration 300 : 0.9107685089111328
Loss at iteration 350 : 0.705188512802124
Mean training loss eporch  393 :  0.8455351673106037
Loss at iteration 50 : 0.8839396238327026
Loss at iteration 100 : 0.6813541650772095
Loss at iteration 150 : 1.002807378768921
Loss at iteration 200 : 0.6340824365615845
Loss at iteration 250 : 0.7190678119659424
Loss at iteration 300 : 0.7192730903625488
Loss at iteration 350 : 1.134176254272461
Mean training loss eporch  394 :  0.8462079281687106
Loss at iteration 50 : 0.7791473865509033
Loss at iteration 100 : 0.5622290968894958
Loss at iteration 150 : 0.7873044013977051
Loss at iteration 200 : 1.005371332168579
Loss at iteration 250 : 0.8013688325881958
Loss at iteration 300 : 0.7393732070922852
Loss at iteration 350 : 0.6591202616691589
Mean training loss eporch  395 :  0.8460196628772393
Loss at iteration 50 : 0.6343588829040527
Loss at iteration 100 : 1.0803338289260864
Loss at iteration 150 : 0.7326539754867554
Loss at iteration 200 : 0.937408983707428
Loss at iteration 250 : 0.7239049673080444
Loss at iteration 300 : 0.8487756252288818
Loss at iteration 350 : 0.9143621921539307
Mean training loss eporch  396 :  0.8469681079110141
Loss at iteration 50 : 0.7838280200958252
Loss at iteration 100 : 1.0168075561523438
Loss at iteration 150 : 0.7829762101173401
Loss at iteration 200 : 1.0312023162841797
Loss at iteration 250 : 0.8522831201553345
Loss at iteration 300 : 0.8067493438720703
Loss at iteration 350 : 1.2566757202148438
Mean training loss eporch  397 :  0.8467808838874574
Loss at iteration 50 : 0.7712031006813049
Loss at iteration 100 : 0.7441160678863525
Loss at iteration 150 : 0.7954193353652954
Loss at iteration 200 : 0.7958365678787231
Loss at iteration 250 : 0.6591290235519409
Loss at iteration 300 : 0.9155502319335938
Loss at iteration 350 : 0.6437345147132874
Mean training loss eporch  398 :  0.846090392618583
Loss at iteration 50 : 0.7925204038619995
Loss at iteration 100 : 0.7666509747505188
Loss at iteration 150 : 0.9834167957305908
Loss at iteration 200 : 1.2593368291854858
Loss at iteration 250 : 1.0051186084747314
Loss at iteration 300 : 0.9715447425842285
Loss at iteration 350 : 0.9431251287460327
Mean training loss eporch  399 :  0.8458308657956501
Loss at iteration 50 : 0.5380553603172302
Loss at iteration 100 : 0.88797527551651
Loss at iteration 150 : 0.8617817759513855
Loss at iteration 200 : 0.9083623886108398
Loss at iteration 250 : 1.1376556158065796
Loss at iteration 300 : 0.94573974609375
Loss at iteration 350 : 0.7228679656982422
Mean training loss eporch  400 :  0.8452364172411975
Loss at iteration 50 : 0.8242114782333374
Loss at iteration 100 : 0.9342904090881348
Loss at iteration 150 : 0.715786337852478
Loss at iteration 200 : 0.8411003351211548
Loss at iteration 250 : 0.9556664228439331
Loss at iteration 300 : 0.6253670454025269
Loss at iteration 350 : 0.9654519557952881
Mean training loss eporch  401 :  0.8460524872970329
Loss at iteration 50 : 0.8929359316825867
Loss at iteration 100 : 0.8777138590812683
Loss at iteration 150 : 0.7269554138183594
Loss at iteration 200 : 0.6924614906311035
Loss at iteration 250 : 0.9634509682655334
Loss at iteration 300 : 0.8012164235115051
Loss at iteration 350 : 1.010467290878296
Mean training loss eporch  402 :  0.8464428724119903
Loss at iteration 50 : 0.6769399642944336
Loss at iteration 100 : 1.013280987739563
Loss at iteration 150 : 0.7164824604988098
Loss at iteration 200 : 0.7231532335281372
Loss at iteration 250 : 0.7550455331802368
Loss at iteration 300 : 0.6915549039840698
Loss at iteration 350 : 0.6421003341674805
Mean training loss eporch  403 :  0.8469686804625093
Loss at iteration 50 : 0.5750666260719299
Loss at iteration 100 : 0.6844795346260071
Loss at iteration 150 : 0.7306245565414429
Loss at iteration 200 : 0.6233203411102295
Loss at iteration 250 : 0.7057141065597534
Loss at iteration 300 : 0.6626455783843994
Loss at iteration 350 : 1.3534796237945557
Mean training loss eporch  404 :  0.8465666826124545
Loss at iteration 50 : 0.8575434684753418
Loss at iteration 100 : 0.9734293222427368
Loss at iteration 150 : 0.6668373346328735
Loss at iteration 200 : 0.7164286375045776
Loss at iteration 250 : 0.8411233425140381
Loss at iteration 300 : 0.8271211981773376
Loss at iteration 350 : 0.8005006909370422
Mean training loss eporch  405 :  0.8458233307751398
Loss at iteration 50 : 0.7081620693206787
Loss at iteration 100 : 1.1808230876922607
Loss at iteration 150 : 0.8147789239883423
Loss at iteration 200 : 0.6136475205421448
Loss at iteration 250 : 0.7774848937988281
Loss at iteration 300 : 0.7121248245239258
Loss at iteration 350 : 0.7086557149887085
Mean training loss eporch  406 :  0.8459951620568674
Loss at iteration 50 : 0.869162380695343
Loss at iteration 100 : 0.7262160778045654
Loss at iteration 150 : 0.854127824306488
Loss at iteration 200 : 0.7195050716400146
Loss at iteration 250 : 0.9335118532180786
Loss at iteration 300 : 0.894446611404419
Loss at iteration 350 : 0.6724140644073486
Mean training loss eporch  407 :  0.8461748558692831
Loss at iteration 50 : 0.8967188000679016
Loss at iteration 100 : 0.8946235775947571
Loss at iteration 150 : 1.017476201057434
Loss at iteration 200 : 0.8263827562332153
Loss at iteration 250 : 0.9264990091323853
Loss at iteration 300 : 0.7527076601982117
Loss at iteration 350 : 0.8366256356239319
Mean training loss eporch  408 :  0.8459162598564511
Loss at iteration 50 : 0.8681133985519409
Loss at iteration 100 : 1.094005823135376
Loss at iteration 150 : 0.7813577055931091
Loss at iteration 200 : 0.5764882564544678
Loss at iteration 250 : 1.0690187215805054
Loss at iteration 300 : 0.6858049631118774
Loss at iteration 350 : 0.8141912221908569
Mean training loss eporch  409 :  0.8455860351443921
Loss at iteration 50 : 1.1967411041259766
Loss at iteration 100 : 0.7962453365325928
Loss at iteration 150 : 0.8785190582275391
Loss at iteration 200 : 0.5134132504463196
Loss at iteration 250 : 0.7705767750740051
Loss at iteration 300 : 0.7427918314933777
Loss at iteration 350 : 0.7423585653305054
Mean training loss eporch  410 :  0.8446637598610429
Loss at iteration 50 : 0.6137707233428955
Loss at iteration 100 : 0.7825075387954712
Loss at iteration 150 : 0.863532543182373
Loss at iteration 200 : 0.7435990571975708
Loss at iteration 250 : 0.9717957377433777
Loss at iteration 300 : 1.0287268161773682
Loss at iteration 350 : 0.7438222169876099
Mean training loss eporch  411 :  0.8462768978385068
Loss at iteration 50 : 0.7860097885131836
Loss at iteration 100 : 0.8955745100975037
Loss at iteration 150 : 0.7224377393722534
Loss at iteration 200 : 0.9457098245620728
Loss at iteration 250 : 0.7744221687316895
Loss at iteration 300 : 0.8253270387649536
Loss at iteration 350 : 0.8477257490158081
Mean training loss eporch  412 :  0.8460084007530616
Loss at iteration 50 : 0.700741171836853
Loss at iteration 100 : 0.7880610227584839
Loss at iteration 150 : 0.8550510406494141
Loss at iteration 200 : 0.9926300644874573
Loss at iteration 250 : 1.1401511430740356
Loss at iteration 300 : 0.7149823307991028
Loss at iteration 350 : 0.6481356620788574
Mean training loss eporch  413 :  0.8463249788397834
Loss at iteration 50 : 0.7250925302505493
Loss at iteration 100 : 0.6461052894592285
Loss at iteration 150 : 0.5430037379264832
Loss at iteration 200 : 1.2714133262634277
Loss at iteration 250 : 1.079554557800293
Loss at iteration 300 : 0.802137017250061
Loss at iteration 350 : 0.6142773032188416
Mean training loss eporch  414 :  0.847016916388557
Loss at iteration 50 : 0.7650942206382751
Loss at iteration 100 : 0.6458700895309448
Loss at iteration 150 : 0.7058873176574707
Loss at iteration 200 : 0.9714965224266052
Loss at iteration 250 : 0.7683749198913574
Loss at iteration 300 : 1.1066558361053467
Loss at iteration 350 : 0.827355682849884
Mean training loss eporch  415 :  0.8448424755580841
Loss at iteration 50 : 0.8128848671913147
Loss at iteration 100 : 0.734722375869751
Loss at iteration 150 : 0.9132879376411438
Loss at iteration 200 : 0.9618337750434875
Loss at iteration 250 : 0.777214527130127
Loss at iteration 300 : 0.6131318807601929
Loss at iteration 350 : 0.43398433923721313
Mean training loss eporch  416 :  0.8458077327284232
Loss at iteration 50 : 0.7640179991722107
Loss at iteration 100 : 0.8039544820785522
Loss at iteration 150 : 0.7405091524124146
Loss at iteration 200 : 0.986497163772583
Loss at iteration 250 : 0.9276530742645264
Loss at iteration 300 : 0.703050971031189
Loss at iteration 350 : 0.9006653428077698
Mean training loss eporch  417 :  0.8460357707171213
Loss at iteration 50 : 0.5608712434768677
Loss at iteration 100 : 0.6988052129745483
Loss at iteration 150 : 0.7675220966339111
Loss at iteration 200 : 0.6371619701385498
Loss at iteration 250 : 0.9981911182403564
Loss at iteration 300 : 0.9882351756095886
Loss at iteration 350 : 0.8554227352142334
Mean training loss eporch  418 :  0.8464688455301618
Loss at iteration 50 : 0.9154099225997925
Loss at iteration 100 : 0.9626622200012207
Loss at iteration 150 : 1.0652546882629395
Loss at iteration 200 : 1.0112502574920654
Loss at iteration 250 : 1.137390375137329
Loss at iteration 300 : 0.9157969951629639
Loss at iteration 350 : 0.7602208852767944
Mean training loss eporch  419 :  0.8456613112379003
Loss at iteration 50 : 1.1357684135437012
Loss at iteration 100 : 0.6537898778915405
Loss at iteration 150 : 0.7003077268600464
Loss at iteration 200 : 0.6765533685684204
Loss at iteration 250 : 1.0898128747940063
Loss at iteration 300 : 0.835529088973999
Loss at iteration 350 : 0.6730432510375977
Mean training loss eporch  420 :  0.8458016945256127
Loss at iteration 50 : 0.8124091625213623
Loss at iteration 100 : 0.785251259803772
Loss at iteration 150 : 0.7250910997390747
Loss at iteration 200 : 0.8696868419647217
Loss at iteration 250 : 1.0503265857696533
Loss at iteration 300 : 0.8347377777099609
Loss at iteration 350 : 0.8704921007156372
Mean training loss eporch  421 :  0.8465538834610944
Loss at iteration 50 : 0.9152464866638184
Loss at iteration 100 : 1.1127188205718994
Loss at iteration 150 : 0.7343260645866394
Loss at iteration 200 : 0.7033801674842834
Loss at iteration 250 : 0.8583236932754517
Loss at iteration 300 : 1.1437870264053345
Loss at iteration 350 : 0.774917483329773
Mean training loss eporch  422 :  0.8451283450322177
Loss at iteration 50 : 0.9242328405380249
Loss at iteration 100 : 0.793857991695404
Loss at iteration 150 : 0.843379557132721
Loss at iteration 200 : 0.6121242046356201
Loss at iteration 250 : 0.890580952167511
Loss at iteration 300 : 0.7790137529373169
Loss at iteration 350 : 0.8072322607040405
Mean training loss eporch  423 :  0.8456997520551479
Loss at iteration 50 : 0.9492331743240356
Loss at iteration 100 : 0.7039228677749634
Loss at iteration 150 : 0.8978734016418457
Loss at iteration 200 : 0.7118666172027588
Loss at iteration 250 : 0.9483420252799988
Loss at iteration 300 : 1.0229241847991943
Loss at iteration 350 : 0.8967682123184204
Mean training loss eporch  424 :  0.8454819528198747
Loss at iteration 50 : 0.922587513923645
Loss at iteration 100 : 0.6821962594985962
Loss at iteration 150 : 0.8235414028167725
Loss at iteration 200 : 0.9248374104499817
Loss at iteration 250 : 0.8161520957946777
Loss at iteration 300 : 0.9012735486030579
Loss at iteration 350 : 0.8990120887756348
Mean training loss eporch  425 :  0.8458485218582961
Loss at iteration 50 : 0.7239240407943726
Loss at iteration 100 : 0.5056250095367432
Loss at iteration 150 : 0.7473264336585999
Loss at iteration 200 : 0.8333723545074463
Loss at iteration 250 : 0.8080374598503113
Loss at iteration 300 : 0.6425641775131226
Loss at iteration 350 : 0.7862032651901245
Mean training loss eporch  426 :  0.8460185864457378
Loss at iteration 50 : 0.6562336683273315
Loss at iteration 100 : 0.7593671679496765
Loss at iteration 150 : 0.8165269494056702
Loss at iteration 200 : 0.6205466985702515
Loss at iteration 250 : 0.8449286222457886
Loss at iteration 300 : 1.2959444522857666
Loss at iteration 350 : 0.6821590065956116
Mean training loss eporch  427 :  0.8461264201572963
Loss at iteration 50 : 0.5989419221878052
Loss at iteration 100 : 1.2736793756484985
Loss at iteration 150 : 1.1591789722442627
Loss at iteration 200 : 1.0766205787658691
Loss at iteration 250 : 0.681219756603241
Loss at iteration 300 : 0.9638376235961914
Loss at iteration 350 : 0.7433826923370361
Mean training loss eporch  428 :  0.8463057563418434
Loss at iteration 50 : 0.9623686075210571
Loss at iteration 100 : 0.8563668727874756
Loss at iteration 150 : 0.8106549978256226
Loss at iteration 200 : 0.8888697624206543
Loss at iteration 250 : 0.7868853807449341
Loss at iteration 300 : 1.0016906261444092
Loss at iteration 350 : 0.7749702334403992
Mean training loss eporch  429 :  0.8461181131147203
Loss at iteration 50 : 0.9924117922782898
Loss at iteration 100 : 0.9308749437332153
Loss at iteration 150 : 0.7452050447463989
Loss at iteration 200 : 1.1434811353683472
Loss at iteration 250 : 0.7870922088623047
Loss at iteration 300 : 0.6289666891098022
Loss at iteration 350 : 0.7148107290267944
Mean training loss eporch  430 :  0.845036551592842
Loss at iteration 50 : 0.8302478194236755
Loss at iteration 100 : 0.7655624151229858
Loss at iteration 150 : 1.123215675354004
Loss at iteration 200 : 0.7400014400482178
Loss at iteration 250 : 0.8831417560577393
Loss at iteration 300 : 0.7972000241279602
Loss at iteration 350 : 0.9720242619514465
Mean training loss eporch  431 :  0.8472670162165606
Loss at iteration 50 : 0.7490097284317017
Loss at iteration 100 : 1.0304851531982422
Loss at iteration 150 : 0.7560675144195557
Loss at iteration 200 : 0.7881717681884766
Loss at iteration 250 : 0.7337561845779419
Loss at iteration 300 : 0.7240351438522339
Loss at iteration 350 : 0.8123120069503784
Mean training loss eporch  432 :  0.8448755399732993
Loss at iteration 50 : 0.9784321784973145
Loss at iteration 100 : 1.3280895948410034
Loss at iteration 150 : 0.6261361837387085
Loss at iteration 200 : 0.8089495897293091
Loss at iteration 250 : 1.3391354084014893
Loss at iteration 300 : 0.7049050331115723
Loss at iteration 350 : 0.9936460256576538
Mean training loss eporch  433 :  0.8452082359128528
Loss at iteration 50 : 0.906259298324585
Loss at iteration 100 : 0.8540528416633606
Loss at iteration 150 : 0.7476500272750854
Loss at iteration 200 : 0.6815115213394165
Loss at iteration 250 : 0.7137068510055542
Loss at iteration 300 : 0.7802693843841553
Loss at iteration 350 : 0.7322022914886475
Mean training loss eporch  434 :  0.8452787694161531
Loss at iteration 50 : 0.60578453540802
Loss at iteration 100 : 0.8450185060501099
Loss at iteration 150 : 1.2575113773345947
Loss at iteration 200 : 0.7285116314888
Loss at iteration 250 : 0.8674105405807495
Loss at iteration 300 : 0.9021674394607544
Loss at iteration 350 : 1.1529804468154907
Mean training loss eporch  435 :  0.8458783263882632
Loss at iteration 50 : 0.84348464012146
Loss at iteration 100 : 0.8539531230926514
Loss at iteration 150 : 0.9119884967803955
Loss at iteration 200 : 0.8193806409835815
Loss at iteration 250 : 0.8758258819580078
Loss at iteration 300 : 0.8465883731842041
Loss at iteration 350 : 1.0251578092575073
Mean training loss eporch  436 :  0.8448317217290717
Loss at iteration 50 : 0.598814845085144
Loss at iteration 100 : 0.9287747740745544
Loss at iteration 150 : 1.4518502950668335
Loss at iteration 200 : 0.7327432632446289
Loss at iteration 250 : 0.832465648651123
Loss at iteration 300 : 1.1760947704315186
Loss at iteration 350 : 0.9636085033416748
Mean training loss eporch  437 :  0.8451342723041615
Loss at iteration 50 : 0.8290742039680481
Loss at iteration 100 : 0.8496271967887878
Loss at iteration 150 : 0.6514854431152344
Loss at iteration 200 : 1.048469066619873
Loss at iteration 250 : 0.6631922125816345
Loss at iteration 300 : 0.5631524324417114
Loss at iteration 350 : 0.7789550423622131
Mean training loss eporch  438 :  0.845410598018182
Loss at iteration 50 : 0.7898174524307251
Loss at iteration 100 : 0.9792625308036804
Loss at iteration 150 : 0.9608958959579468
Loss at iteration 200 : 0.6553487777709961
Loss at iteration 250 : 0.8883079886436462
Loss at iteration 300 : 0.5697164535522461
Loss at iteration 350 : 0.7872819900512695
Mean training loss eporch  439 :  0.8453309465022314
Loss at iteration 50 : 0.7103374004364014
Loss at iteration 100 : 0.8682210445404053
Loss at iteration 150 : 0.8525601029396057
Loss at iteration 200 : 0.9165414571762085
Loss at iteration 250 : 0.8385807871818542
Loss at iteration 300 : 0.8066743612289429
Loss at iteration 350 : 0.6380376815795898
Mean training loss eporch  440 :  0.8448752792423995
Loss at iteration 50 : 0.7963707447052002
Loss at iteration 100 : 0.8288527727127075
Loss at iteration 150 : 0.9189020395278931
Loss at iteration 200 : 0.7545206546783447
Loss at iteration 250 : 1.130492925643921
Loss at iteration 300 : 1.0631721019744873
Loss at iteration 350 : 0.8478356599807739
Mean training loss eporch  441 :  0.8466714380910156
Loss at iteration 50 : 0.7282083630561829
Loss at iteration 100 : 0.6923101544380188
Loss at iteration 150 : 0.8594639897346497
Loss at iteration 200 : 0.8991916179656982
Loss at iteration 250 : 0.8585851192474365
Loss at iteration 300 : 0.7960067391395569
Loss at iteration 350 : 0.9172506332397461
Mean training loss eporch  442 :  0.844866358965793
Loss at iteration 50 : 1.1718071699142456
Loss at iteration 100 : 0.885667085647583
Loss at iteration 150 : 0.6673541069030762
Loss at iteration 200 : 0.5907797813415527
Loss at iteration 250 : 0.9978089332580566
Loss at iteration 300 : 0.9816138744354248
Loss at iteration 350 : 0.7504860758781433
Mean training loss eporch  443 :  0.8449118392808097
Loss at iteration 50 : 0.8302181363105774
Loss at iteration 100 : 1.077582597732544
Loss at iteration 150 : 0.7569137215614319
Loss at iteration 200 : 1.053928256034851
Loss at iteration 250 : 0.9852698445320129
Loss at iteration 300 : 1.1464585065841675
Loss at iteration 350 : 0.688237726688385
Mean training loss eporch  444 :  0.8456718421802318
Loss at iteration 50 : 0.5141435265541077
Loss at iteration 100 : 0.6282001733779907
Loss at iteration 150 : 0.9583532810211182
Loss at iteration 200 : 0.8422035574913025
Loss at iteration 250 : 0.9406353235244751
Loss at iteration 300 : 0.7733778357505798
Loss at iteration 350 : 0.8117559552192688
Mean training loss eporch  445 :  0.8454255020965344
Loss at iteration 50 : 0.9604849219322205
Loss at iteration 100 : 0.7366787195205688
Loss at iteration 150 : 0.8806312084197998
Loss at iteration 200 : 0.7499260902404785
Loss at iteration 250 : 0.8287447690963745
Loss at iteration 300 : 0.7646463513374329
Loss at iteration 350 : 0.7227749824523926
Mean training loss eporch  446 :  0.8452897754611162
Loss at iteration 50 : 1.0767438411712646
Loss at iteration 100 : 0.9036872982978821
Loss at iteration 150 : 0.8781194686889648
Loss at iteration 200 : 0.6801843643188477
Loss at iteration 250 : 0.7494387626647949
Loss at iteration 300 : 0.7130130529403687
Loss at iteration 350 : 1.1767573356628418
Mean training loss eporch  447 :  0.8452095808806243
Loss at iteration 50 : 0.5811468362808228
Loss at iteration 100 : 0.7650020122528076
Loss at iteration 150 : 0.6763361692428589
Loss at iteration 200 : 0.8144392371177673
Loss at iteration 250 : 0.6731177568435669
Loss at iteration 300 : 0.7413719892501831
Loss at iteration 350 : 1.070199728012085
Mean training loss eporch  448 :  0.8453400541865637
Loss at iteration 50 : 1.047026515007019
Loss at iteration 100 : 0.7969481348991394
Loss at iteration 150 : 1.0151591300964355
Loss at iteration 200 : 1.352765440940857
Loss at iteration 250 : 0.7368496656417847
Loss at iteration 300 : 0.6250084638595581
Loss at iteration 350 : 0.8584882020950317
Mean training loss eporch  449 :  0.8453841244102155
Loss at iteration 50 : 0.9348858594894409
Loss at iteration 100 : 0.7514055967330933
Loss at iteration 150 : 0.7294054627418518
Loss at iteration 200 : 0.6198395490646362
Loss at iteration 250 : 1.0538370609283447
Loss at iteration 300 : 0.7247721552848816
Loss at iteration 350 : 1.0567059516906738
Mean training loss eporch  450 :  0.8455971506222215
Loss at iteration 50 : 0.8558821678161621
Loss at iteration 100 : 0.7549603581428528
Loss at iteration 150 : 0.6598138213157654
Loss at iteration 200 : 0.8631840348243713
Loss at iteration 250 : 0.9856131672859192
Loss at iteration 300 : 0.8410309553146362
Loss at iteration 350 : 0.9646457433700562
Mean training loss eporch  451 :  0.8448396322746126
Loss at iteration 50 : 0.8923150300979614
Loss at iteration 100 : 1.2659435272216797
Loss at iteration 150 : 0.7185046672821045
Loss at iteration 200 : 0.9113337993621826
Loss at iteration 250 : 1.4546573162078857
Loss at iteration 300 : 0.9758303165435791
Loss at iteration 350 : 0.7791413068771362
Mean training loss eporch  452 :  0.8446712238448006
Loss at iteration 50 : 0.8406546115875244
Loss at iteration 100 : 0.776702880859375
Loss at iteration 150 : 0.832222580909729
Loss at iteration 200 : 0.8743306398391724
Loss at iteration 250 : 0.5868746042251587
Loss at iteration 300 : 0.7200862169265747
Loss at iteration 350 : 0.919205904006958
Mean training loss eporch  453 :  0.845814680138593
Loss at iteration 50 : 1.0252931118011475
Loss at iteration 100 : 0.9568167924880981
Loss at iteration 150 : 0.7054864168167114
Loss at iteration 200 : 0.711712121963501
Loss at iteration 250 : 0.8848503828048706
Loss at iteration 300 : 0.8458235263824463
Loss at iteration 350 : 0.5713430643081665
Mean training loss eporch  454 :  0.844468836983045
Loss at iteration 50 : 0.5205389261245728
Loss at iteration 100 : 0.6628267168998718
Loss at iteration 150 : 0.6997429132461548
Loss at iteration 200 : 0.8007971048355103
Loss at iteration 250 : 1.116868019104004
Loss at iteration 300 : 0.6955863833427429
Loss at iteration 350 : 0.7824708223342896
Mean training loss eporch  455 :  0.8452444934340381
Loss at iteration 50 : 0.9377951622009277
Loss at iteration 100 : 1.0751910209655762
Loss at iteration 150 : 1.411031723022461
Loss at iteration 200 : 0.8367984890937805
Loss at iteration 250 : 1.1961753368377686
Loss at iteration 300 : 1.0195355415344238
Loss at iteration 350 : 0.7120449542999268
Mean training loss eporch  456 :  0.8457920092438894
Loss at iteration 50 : 0.9461551308631897
Loss at iteration 100 : 0.7478201389312744
Loss at iteration 150 : 0.8289503455162048
Loss at iteration 200 : 0.8651596903800964
Loss at iteration 250 : 0.7935769557952881
Loss at iteration 300 : 0.7564184665679932
Loss at iteration 350 : 0.572033166885376
Mean training loss eporch  457 :  0.8455916316736312
Loss at iteration 50 : 0.8585969805717468
Loss at iteration 100 : 0.8848540782928467
Loss at iteration 150 : 0.8181354999542236
Loss at iteration 200 : 0.9986505508422852
Loss at iteration 250 : 0.743632435798645
Loss at iteration 300 : 0.9007291793823242
Loss at iteration 350 : 0.6218958497047424
Mean training loss eporch  458 :  0.844695007990277
Loss at iteration 50 : 1.1748390197753906
Loss at iteration 100 : 1.2077674865722656
Loss at iteration 150 : 0.9791880249977112
Loss at iteration 200 : 0.5902343392372131
Loss at iteration 250 : 0.689070463180542
Loss at iteration 300 : 0.7097955942153931
Loss at iteration 350 : 1.1173113584518433
Mean training loss eporch  459 :  0.8446247235492423
Loss at iteration 50 : 0.8005427718162537
Loss at iteration 100 : 0.8928898572921753
Loss at iteration 150 : 0.6778647899627686
Loss at iteration 200 : 0.9639310240745544
Loss at iteration 250 : 0.879393458366394
Loss at iteration 300 : 0.8623913526535034
Loss at iteration 350 : 0.7832012176513672
Mean training loss eporch  460 :  0.8450450177388217
Loss at iteration 50 : 1.024853229522705
Loss at iteration 100 : 0.7275511026382446
Loss at iteration 150 : 0.7039682865142822
Loss at iteration 200 : 0.6853829622268677
Loss at iteration 250 : 0.7225915193557739
Loss at iteration 300 : 0.7430918216705322
Loss at iteration 350 : 0.6752070188522339
Mean training loss eporch  461 :  0.8458464822914235
Loss at iteration 50 : 0.9042862057685852
Loss at iteration 100 : 0.7184818983078003
Loss at iteration 150 : 1.0004403591156006
Loss at iteration 200 : 1.0261170864105225
Loss at iteration 250 : 1.1794109344482422
Loss at iteration 300 : 0.682949423789978
Loss at iteration 350 : 0.9111247658729553
Mean training loss eporch  462 :  0.8449642305809354
Loss at iteration 50 : 0.7525041103363037
Loss at iteration 100 : 0.7742500305175781
Loss at iteration 150 : 0.5624901056289673
Loss at iteration 200 : 1.101425290107727
Loss at iteration 250 : 0.68772292137146
Loss at iteration 300 : 0.8274012207984924
Loss at iteration 350 : 0.81817227602005
Mean training loss eporch  463 :  0.8451904760939735
Loss at iteration 50 : 0.9788699150085449
Loss at iteration 100 : 0.9825517535209656
Loss at iteration 150 : 0.5224292278289795
Loss at iteration 200 : 0.8227828145027161
Loss at iteration 250 : 0.7712932825088501
Loss at iteration 300 : 0.603618860244751
Loss at iteration 350 : 0.5952039957046509
Mean training loss eporch  464 :  0.8446096337188489
Loss at iteration 50 : 0.677396297454834
Loss at iteration 100 : 0.9462410807609558
Loss at iteration 150 : 0.8307026028633118
Loss at iteration 200 : 0.7408608794212341
Loss at iteration 250 : 0.6561244130134583
Loss at iteration 300 : 0.8648273944854736
Loss at iteration 350 : 0.7247751951217651
Mean training loss eporch  465 :  0.8451258599285095
Loss at iteration 50 : 0.6494845151901245
Loss at iteration 100 : 0.7922202348709106
Loss at iteration 150 : 0.8484689593315125
Loss at iteration 200 : 0.8654046058654785
Loss at iteration 250 : 1.1441316604614258
Loss at iteration 300 : 0.867354154586792
Loss at iteration 350 : 0.9436008334159851
Mean training loss eporch  466 :  0.8446538482235852
Loss at iteration 50 : 1.1464719772338867
Loss at iteration 100 : 0.9543476700782776
Loss at iteration 150 : 0.7313567399978638
Loss at iteration 200 : 0.7460918426513672
Loss at iteration 250 : 0.8711289763450623
Loss at iteration 300 : 0.9698763489723206
Loss at iteration 350 : 1.0816380977630615
Mean training loss eporch  467 :  0.8446176592950467
Loss at iteration 50 : 1.085859775543213
Loss at iteration 100 : 0.8693618178367615
Loss at iteration 150 : 0.583465576171875
Loss at iteration 200 : 1.0139403343200684
Loss at iteration 250 : 0.7260441184043884
Loss at iteration 300 : 0.8110058307647705
Loss at iteration 350 : 0.7786884903907776
Mean training loss eporch  468 :  0.8448246903520412
Loss at iteration 50 : 0.6797926425933838
Loss at iteration 100 : 0.9972806572914124
Loss at iteration 150 : 1.0310927629470825
Loss at iteration 200 : 0.972957193851471
Loss at iteration 250 : 1.1348220109939575
Loss at iteration 300 : 0.8008116483688354
Loss at iteration 350 : 0.7773144245147705
Mean training loss eporch  469 :  0.8444619035279309
Loss at iteration 50 : 0.587558388710022
Loss at iteration 100 : 0.8432048559188843
Loss at iteration 150 : 1.1653668880462646
Loss at iteration 200 : 1.0856729745864868
Loss at iteration 250 : 0.7646489143371582
Loss at iteration 300 : 0.7501708269119263
Loss at iteration 350 : 0.5190235376358032
Mean training loss eporch  470 :  0.8449136742523738
Loss at iteration 50 : 0.9934561848640442
Loss at iteration 100 : 0.5590630769729614
Loss at iteration 150 : 0.7875163555145264
Loss at iteration 200 : 0.8133783936500549
Loss at iteration 250 : 0.8166841268539429
Loss at iteration 300 : 0.5697352886199951
Loss at iteration 350 : 0.8941867351531982
Mean training loss eporch  471 :  0.8455672201025423
Loss at iteration 50 : 0.7241236567497253
Loss at iteration 100 : 0.6232632994651794
Loss at iteration 150 : 1.0903582572937012
Loss at iteration 200 : 0.9268804788589478
Loss at iteration 250 : 0.6872246265411377
Loss at iteration 300 : 0.7511605024337769
Loss at iteration 350 : 0.9172240495681763
Mean training loss eporch  472 :  0.8439350706875008
Loss at iteration 50 : 1.0637495517730713
Loss at iteration 100 : 0.797728419303894
Loss at iteration 150 : 0.8422844409942627
Loss at iteration 200 : 0.6301130652427673
Loss at iteration 250 : 0.4815896153450012
Loss at iteration 300 : 0.8867457509040833
Loss at iteration 350 : 0.6600672006607056
Mean training loss eporch  473 :  0.8453260248615628
Loss at iteration 50 : 0.8286247849464417
Loss at iteration 100 : 0.9345682263374329
Loss at iteration 150 : 0.8245002031326294
Loss at iteration 200 : 1.3600099086761475
Loss at iteration 250 : 0.8516897559165955
Loss at iteration 300 : 0.5189255475997925
Loss at iteration 350 : 0.878482460975647
Mean training loss eporch  474 :  0.8453099785185365
Loss at iteration 50 : 0.7545247673988342
Loss at iteration 100 : 0.695452094078064
Loss at iteration 150 : 0.7962780594825745
Loss at iteration 200 : 0.5930564403533936
Loss at iteration 250 : 0.9925374388694763
Loss at iteration 300 : 0.8615456819534302
Loss at iteration 350 : 0.7646064758300781
Mean training loss eporch  475 :  0.8455848391093905
Loss at iteration 50 : 0.7848597764968872
Loss at iteration 100 : 0.6700586080551147
Loss at iteration 150 : 0.6904991865158081
Loss at iteration 200 : 0.5506048202514648
Loss at iteration 250 : 0.6811456680297852
Loss at iteration 300 : 0.8532876968383789
Loss at iteration 350 : 0.6432632207870483
Mean training loss eporch  476 :  0.844803272416352
Loss at iteration 50 : 0.8968673944473267
Loss at iteration 100 : 0.8618209362030029
Loss at iteration 150 : 0.6677048206329346
Loss at iteration 200 : 1.0443131923675537
Loss at iteration 250 : 0.8184007406234741
Loss at iteration 300 : 0.7019631266593933
Loss at iteration 350 : 0.9231567978858948
Mean training loss eporch  477 :  0.8466441431058147
Loss at iteration 50 : 0.6867949962615967
Loss at iteration 100 : 0.8989635705947876
Loss at iteration 150 : 0.7759785652160645
Loss at iteration 200 : 0.9547870755195618
Loss at iteration 250 : 0.7703472375869751
Loss at iteration 300 : 0.7524943947792053
Loss at iteration 350 : 0.8175495862960815
Mean training loss eporch  478 :  0.8452503852270268
Loss at iteration 50 : 0.8639359474182129
Loss at iteration 100 : 0.6363039016723633
Loss at iteration 150 : 0.9020472168922424
Loss at iteration 200 : 0.638728141784668
Loss at iteration 250 : 1.17580246925354
Loss at iteration 300 : 1.1244046688079834
Loss at iteration 350 : 0.855841875076294
Mean training loss eporch  479 :  0.8446805714457123
Loss at iteration 50 : 0.9900116920471191
Loss at iteration 100 : 0.8300216197967529
Loss at iteration 150 : 0.7993056774139404
Loss at iteration 200 : 0.917389452457428
Loss at iteration 250 : 1.1578254699707031
Loss at iteration 300 : 0.6974050998687744
Loss at iteration 350 : 1.229034185409546
Mean training loss eporch  480 :  0.8458415940009728
Loss at iteration 50 : 1.3824446201324463
Loss at iteration 100 : 0.7437621355056763
Loss at iteration 150 : 1.0877163410186768
Loss at iteration 200 : 0.8422504663467407
Loss at iteration 250 : 0.7746121883392334
Loss at iteration 300 : 0.7631692886352539
Loss at iteration 350 : 0.8841202259063721
Mean training loss eporch  481 :  0.8442388996876106
Loss at iteration 50 : 1.161195158958435
Loss at iteration 100 : 0.5909472703933716
Loss at iteration 150 : 0.603909432888031
Loss at iteration 200 : 0.953882098197937
Loss at iteration 250 : 0.7701533436775208
Loss at iteration 300 : 0.780545711517334
Loss at iteration 350 : 0.6759158968925476
Mean training loss eporch  482 :  0.8449524036317906
Loss at iteration 50 : 0.5002307891845703
Loss at iteration 100 : 0.7446339726448059
Loss at iteration 150 : 0.6607606410980225
Loss at iteration 200 : 0.6769652366638184
Loss at iteration 250 : 0.6182874441146851
Loss at iteration 300 : 0.6463515758514404
Loss at iteration 350 : 1.0288084745407104
Mean training loss eporch  483 :  0.8447967554841723
Loss at iteration 50 : 1.068098783493042
Loss at iteration 100 : 0.8618520498275757
Loss at iteration 150 : 0.9122974872589111
Loss at iteration 200 : 0.8484823107719421
Loss at iteration 250 : 0.815330982208252
Loss at iteration 300 : 0.7647979259490967
Loss at iteration 350 : 0.504878044128418
Mean training loss eporch  484 :  0.8453997242703009
Loss at iteration 50 : 0.6387872695922852
Loss at iteration 100 : 0.589341938495636
Loss at iteration 150 : 0.7844564318656921
Loss at iteration 200 : 0.7346441149711609
Loss at iteration 250 : 0.6861702799797058
Loss at iteration 300 : 0.6354333758354187
Loss at iteration 350 : 1.0630841255187988
Mean training loss eporch  485 :  0.8446976437612816
Loss at iteration 50 : 0.7077698707580566
Loss at iteration 100 : 0.8929805755615234
Loss at iteration 150 : 0.9802985787391663
Loss at iteration 200 : 0.7144131064414978
Loss at iteration 250 : 0.8066024780273438
Loss at iteration 300 : 0.8382250070571899
Loss at iteration 350 : 1.0330291986465454
Mean training loss eporch  486 :  0.8454596829162073
Loss at iteration 50 : 0.7169368863105774
Loss at iteration 100 : 0.9440286755561829
Loss at iteration 150 : 0.647313117980957
Loss at iteration 200 : 1.1269700527191162
Loss at iteration 250 : 0.913514256477356
Loss at iteration 300 : 0.9006384015083313
Loss at iteration 350 : 0.6652297973632812
Mean training loss eporch  487 :  0.8448275663549938
Loss at iteration 50 : 0.7855046987533569
Loss at iteration 100 : 0.9911856055259705
Loss at iteration 150 : 0.7846899032592773
Loss at iteration 200 : 0.9461802244186401
Loss at iteration 250 : 0.7847580909729004
Loss at iteration 300 : 0.9129709601402283
Loss at iteration 350 : 0.7707476615905762
Mean training loss eporch  488 :  0.8455414623810501
Loss at iteration 50 : 0.7763935327529907
Loss at iteration 100 : 0.7894769906997681
Loss at iteration 150 : 0.7511085271835327
Loss at iteration 200 : 0.7388395667076111
Loss at iteration 250 : 0.9823076725006104
Loss at iteration 300 : 0.6785434484481812
Loss at iteration 350 : 0.7889748215675354
Mean training loss eporch  489 :  0.844422758414001
Loss at iteration 50 : 1.1957533359527588
Loss at iteration 100 : 0.9226794242858887
Loss at iteration 150 : 0.6653305888175964
Loss at iteration 200 : 0.9890467524528503
Loss at iteration 250 : 0.6538339257240295
Loss at iteration 300 : 0.902884304523468
Loss at iteration 350 : 0.8197651505470276
Mean training loss eporch  490 :  0.844137673655515
Loss at iteration 50 : 0.9562826752662659
Loss at iteration 100 : 0.6355382204055786
Loss at iteration 150 : 0.8446464538574219
Loss at iteration 200 : 0.6487187743186951
Loss at iteration 250 : 0.9904547929763794
Loss at iteration 300 : 1.176771879196167
Loss at iteration 350 : 1.1899477243423462
Mean training loss eporch  491 :  0.8446817737092417
Loss at iteration 50 : 1.1568272113800049
Loss at iteration 100 : 0.7994222640991211
Loss at iteration 150 : 0.8950237035751343
Loss at iteration 200 : 1.080005407333374
Loss at iteration 250 : 1.1869206428527832
Loss at iteration 300 : 0.4481669068336487
Loss at iteration 350 : 0.8504505753517151
Mean training loss eporch  492 :  0.8449533904986407
Loss at iteration 50 : 0.9132763743400574
Loss at iteration 100 : 0.6585009098052979
Loss at iteration 150 : 0.8337762355804443
Loss at iteration 200 : 0.7799669504165649
Loss at iteration 250 : 1.0721274614334106
Loss at iteration 300 : 0.7979322671890259
Loss at iteration 350 : 0.7825812101364136
Mean training loss eporch  493 :  0.8447215419913096
Loss at iteration 50 : 1.1229653358459473
Loss at iteration 100 : 0.7323210835456848
Loss at iteration 150 : 1.1850908994674683
Loss at iteration 200 : 0.6737880706787109
Loss at iteration 250 : 0.8017768859863281
Loss at iteration 300 : 0.5942033529281616
Loss at iteration 350 : 0.797382116317749
Mean training loss eporch  494 :  0.844835772637337
Loss at iteration 50 : 1.2325866222381592
Loss at iteration 100 : 0.7584415674209595
Loss at iteration 150 : 1.085693120956421
Loss at iteration 200 : 0.8231242895126343
Loss at iteration 250 : 0.81654953956604
Loss at iteration 300 : 0.684280276298523
Loss at iteration 350 : 1.2007323503494263
Mean training loss eporch  495 :  0.8448796834422168
Loss at iteration 50 : 0.7241275310516357
Loss at iteration 100 : 0.7956088781356812
Loss at iteration 150 : 0.6641514301300049
Loss at iteration 200 : 0.6826653480529785
Loss at iteration 250 : 0.8607078790664673
Loss at iteration 300 : 1.182195782661438
Loss at iteration 350 : 0.7017498016357422
Mean training loss eporch  496 :  0.8450383955524081
Loss at iteration 50 : 0.7534869909286499
Loss at iteration 100 : 0.9018558263778687
Loss at iteration 150 : 0.7543190717697144
Loss at iteration 200 : 0.8031438589096069
Loss at iteration 250 : 1.0588053464889526
Loss at iteration 300 : 0.815420389175415
Loss at iteration 350 : 0.7701007127761841
Mean training loss eporch  497 :  0.8445988219408762
Loss at iteration 50 : 0.6793214082717896
Loss at iteration 100 : 0.8103797435760498
Loss at iteration 150 : 0.8788048624992371
Loss at iteration 200 : 0.870408296585083
Loss at iteration 250 : 0.8471207618713379
Loss at iteration 300 : 0.7540766000747681
Loss at iteration 350 : 0.9662420749664307
Mean training loss eporch  498 :  0.8447126706756612
Loss at iteration 50 : 0.9132158756256104
Loss at iteration 100 : 0.7634083032608032
Loss at iteration 150 : 0.8135651350021362
Loss at iteration 200 : 1.0278568267822266
Loss at iteration 250 : 0.7044403553009033
Loss at iteration 300 : 0.9878234267234802
Loss at iteration 350 : 0.7572696208953857
Mean training loss eporch  499 :  0.8445388285255937
Loss at iteration 50 : 1.2622311115264893
Loss at iteration 100 : 0.9321163892745972
Loss at iteration 150 : 0.9299396872520447
Loss at iteration 200 : 1.3207569122314453
Loss at iteration 250 : 0.7497286796569824
Loss at iteration 300 : 1.009070873260498
Loss at iteration 350 : 0.8067196607589722
Mean training loss eporch  500 :  0.8457224589807016
Loss at iteration 50 : 0.6564332246780396
Loss at iteration 100 : 0.7767823934555054
Loss at iteration 150 : 0.9208705425262451
Loss at iteration 200 : 0.8282566070556641
Loss at iteration 250 : 0.8545821309089661
Loss at iteration 300 : 0.6413172483444214
Loss at iteration 350 : 0.9049121141433716
Mean training loss eporch  501 :  0.8444067952494142
Loss at iteration 50 : 0.7984133362770081
Loss at iteration 100 : 1.1627006530761719
Loss at iteration 150 : 0.9853096008300781
Loss at iteration 200 : 0.816857099533081
Loss at iteration 250 : 0.735339879989624
Loss at iteration 300 : 1.093479037284851
Loss at iteration 350 : 0.7687859535217285
Mean training loss eporch  502 :  0.8452711199957227
Loss at iteration 50 : 1.5632882118225098
Loss at iteration 100 : 0.9083147048950195
Loss at iteration 150 : 0.9197317361831665
Loss at iteration 200 : 0.7632514834403992
Loss at iteration 250 : 0.7778699994087219
Loss at iteration 300 : 0.9684231281280518
Loss at iteration 350 : 0.9532855153083801
Mean training loss eporch  503 :  0.8447460476998929
Loss at iteration 50 : 0.8973094820976257
Loss at iteration 100 : 0.6850160956382751
Loss at iteration 150 : 0.6265759468078613
Loss at iteration 200 : 0.8245153427124023
Loss at iteration 250 : 0.6913106441497803
Loss at iteration 300 : 0.6292858123779297
Loss at iteration 350 : 0.5866115689277649
Mean training loss eporch  504 :  0.8439706885625445
Loss at iteration 50 : 0.8405241370201111
Loss at iteration 100 : 0.738054633140564
Loss at iteration 150 : 1.276110053062439
Loss at iteration 200 : 0.840011715888977
Loss at iteration 250 : 1.101388692855835
Loss at iteration 300 : 0.9368473291397095
Loss at iteration 350 : 0.7642260789871216
Mean training loss eporch  505 :  0.8450782724789211
Loss at iteration 50 : 0.9753415584564209
Loss at iteration 100 : 0.8994534015655518
Loss at iteration 150 : 1.0774234533309937
Loss at iteration 200 : 0.9745944738388062
Loss at iteration 250 : 1.0178422927856445
Loss at iteration 300 : 0.521553635597229
Loss at iteration 350 : 0.7348604202270508
Mean training loss eporch  506 :  0.8451490034028967
Loss at iteration 50 : 0.947297215461731
Loss at iteration 100 : 0.6495298147201538
Loss at iteration 150 : 1.0102829933166504
Loss at iteration 200 : 0.7309263944625854
Loss at iteration 250 : 0.7504814863204956
Loss at iteration 300 : 0.6638327836990356
Loss at iteration 350 : 1.1208488941192627
Mean training loss eporch  507 :  0.8454323763412143
Loss at iteration 50 : 0.8972488641738892
Loss at iteration 100 : 1.1570080518722534
Loss at iteration 150 : 1.0528264045715332
Loss at iteration 200 : 1.1569241285324097
Loss at iteration 250 : 0.8139948844909668
Loss at iteration 300 : 0.563511848449707
Loss at iteration 350 : 0.9293808937072754
Mean training loss eporch  508 :  0.8436958999545486
Loss at iteration 50 : 0.8552998304367065
Loss at iteration 100 : 1.0928794145584106
Loss at iteration 150 : 0.6935521364212036
Loss at iteration 200 : 1.1561620235443115
Loss at iteration 250 : 0.675514817237854
Loss at iteration 300 : 0.692213237285614
Loss at iteration 350 : 0.975890576839447
Mean training loss eporch  509 :  0.8438337488622262
Loss at iteration 50 : 0.9246285557746887
Loss at iteration 100 : 0.8270547389984131
Loss at iteration 150 : 0.8339047431945801
Loss at iteration 200 : 0.8402776718139648
Loss at iteration 250 : 0.7156420946121216
Loss at iteration 300 : 1.0909936428070068
Loss at iteration 350 : 1.0932196378707886
Mean training loss eporch  510 :  0.843913229606139
Loss at iteration 50 : 0.9999983310699463
Loss at iteration 100 : 0.6256367564201355
Loss at iteration 150 : 1.2204039096832275
Loss at iteration 200 : 0.7012887001037598
Loss at iteration 250 : 0.7027238607406616
Loss at iteration 300 : 0.6729156970977783
Loss at iteration 350 : 0.8068383932113647
Mean training loss eporch  511 :  0.8445980544128115
Loss at iteration 50 : 0.820975124835968
Loss at iteration 100 : 0.7883424758911133
Loss at iteration 150 : 0.8362421989440918
Loss at iteration 200 : 0.6489668488502502
Loss at iteration 250 : 1.045105218887329
Loss at iteration 300 : 0.7025673985481262
Loss at iteration 350 : 0.9454208612442017
Mean training loss eporch  512 :  0.844966079349871
Loss at iteration 50 : 0.931829571723938
Loss at iteration 100 : 0.9971215724945068
Loss at iteration 150 : 0.8059417009353638
Loss at iteration 200 : 0.8634865283966064
Loss at iteration 250 : 0.6992928981781006
Loss at iteration 300 : 0.8562264442443848
Loss at iteration 350 : 0.6190186738967896
Mean training loss eporch  513 :  0.8448514939931334
Loss at iteration 50 : 0.9079474210739136
Loss at iteration 100 : 0.9270744919776917
Loss at iteration 150 : 0.6629058122634888
Loss at iteration 200 : 1.2540464401245117
Loss at iteration 250 : 0.8013116121292114
Loss at iteration 300 : 0.715157151222229
Loss at iteration 350 : 0.7708531618118286
Mean training loss eporch  514 :  0.8446792613261591
Loss at iteration 50 : 0.8237018585205078
Loss at iteration 100 : 0.8342710733413696
Loss at iteration 150 : 0.8013020157814026
Loss at iteration 200 : 1.1225804090499878
Loss at iteration 250 : 0.6329165697097778
Loss at iteration 300 : 0.9307770729064941
Loss at iteration 350 : 1.2296359539031982
Mean training loss eporch  515 :  0.8444583040696604
Loss at iteration 50 : 0.7391901016235352
Loss at iteration 100 : 0.7349986433982849
Loss at iteration 150 : 0.6082049608230591
Loss at iteration 200 : 0.7951306104660034
Loss at iteration 250 : 0.6732096672058105
Loss at iteration 300 : 0.8019786477088928
Loss at iteration 350 : 0.7753836512565613
Mean training loss eporch  516 :  0.8442627981541648
Loss at iteration 50 : 0.6917717456817627
Loss at iteration 100 : 0.7103480100631714
Loss at iteration 150 : 0.7576130628585815
Loss at iteration 200 : 1.1410223245620728
Loss at iteration 250 : 0.784686803817749
Loss at iteration 300 : 0.6079322695732117
Loss at iteration 350 : 0.5810518860816956
Mean training loss eporch  517 :  0.8439157273245868
Loss at iteration 50 : 0.6882818937301636
Loss at iteration 100 : 0.79323810338974
Loss at iteration 150 : 0.7619534730911255
Loss at iteration 200 : 0.5521969795227051
Loss at iteration 250 : 1.0635974407196045
Loss at iteration 300 : 0.6778558492660522
Loss at iteration 350 : 0.6923717260360718
Mean training loss eporch  518 :  0.8454554788965397
Loss at iteration 50 : 0.8886514902114868
Loss at iteration 100 : 1.0451468229293823
Loss at iteration 150 : 0.8077355027198792
Loss at iteration 200 : 1.1571389436721802
Loss at iteration 250 : 1.0968563556671143
Loss at iteration 300 : 0.8875523209571838
Loss at iteration 350 : 0.8160510659217834
Mean training loss eporch  519 :  0.8445510812222011
Loss at iteration 50 : 0.9359797239303589
Loss at iteration 100 : 0.9432519674301147
Loss at iteration 150 : 0.7860106229782104
Loss at iteration 200 : 1.1041709184646606
Loss at iteration 250 : 0.7524502277374268
Loss at iteration 300 : 1.1381925344467163
Loss at iteration 350 : 0.9889358878135681
Mean training loss eporch  520 :  0.844321807067861
Loss at iteration 50 : 0.9132033586502075
Loss at iteration 100 : 0.7174681425094604
Loss at iteration 150 : 0.5982864499092102
Loss at iteration 200 : 0.9330242872238159
Loss at iteration 250 : 0.5998584628105164
Loss at iteration 300 : 0.73684161901474
Loss at iteration 350 : 0.9335957169532776
Mean training loss eporch  521 :  0.8444244084219453
Loss at iteration 50 : 0.7047165632247925
Loss at iteration 100 : 0.6601152420043945
Loss at iteration 150 : 0.8058153986930847
Loss at iteration 200 : 0.4460773766040802
Loss at iteration 250 : 0.8283636569976807
Loss at iteration 300 : 0.8562480211257935
Loss at iteration 350 : 0.615378201007843
Mean training loss eporch  522 :  0.8434241569389112
Loss at iteration 50 : 0.9195075035095215
Loss at iteration 100 : 0.876943051815033
Loss at iteration 150 : 1.0058034658432007
Loss at iteration 200 : 1.347794532775879
Loss at iteration 250 : 0.989586591720581
Loss at iteration 300 : 0.782464861869812
Loss at iteration 350 : 0.709426999092102
Mean training loss eporch  523 :  0.844184263042672
Loss at iteration 50 : 0.8188081383705139
Loss at iteration 100 : 1.1499814987182617
Loss at iteration 150 : 0.939998209476471
Loss at iteration 200 : 0.7641411423683167
Loss at iteration 250 : 1.1044245958328247
Loss at iteration 300 : 0.632082462310791
Loss at iteration 350 : 0.685066819190979
Mean training loss eporch  524 :  0.8449247648160925
Loss at iteration 50 : 0.6770403385162354
Loss at iteration 100 : 0.9598059058189392
Loss at iteration 150 : 0.7138060331344604
Loss at iteration 200 : 0.6207730770111084
Loss at iteration 250 : 1.0705797672271729
Loss at iteration 300 : 1.1484044790267944
Loss at iteration 350 : 1.1221096515655518
Mean training loss eporch  525 :  0.8443056169168028
Loss at iteration 50 : 0.8905909061431885
Loss at iteration 100 : 0.9960103631019592
Loss at iteration 150 : 0.9597870707511902
Loss at iteration 200 : 0.960284948348999
Loss at iteration 250 : 0.8522953987121582
Loss at iteration 300 : 0.7144007086753845
Loss at iteration 350 : 0.8491166830062866
Mean training loss eporch  526 :  0.8434356071015514
Loss at iteration 50 : 0.814966082572937
Loss at iteration 100 : 0.9898400902748108
Loss at iteration 150 : 0.6389119625091553
Loss at iteration 200 : 1.0169875621795654
Loss at iteration 250 : 0.9429130554199219
Loss at iteration 300 : 0.8400225043296814
Loss at iteration 350 : 0.9238243103027344
Mean training loss eporch  527 :  0.846155876835818
Loss at iteration 50 : 0.9675012230873108
Loss at iteration 100 : 1.008207082748413
Loss at iteration 150 : 1.1727607250213623
Loss at iteration 200 : 0.5845550894737244
Loss at iteration 250 : 1.013035774230957
Loss at iteration 300 : 0.8161116242408752
Loss at iteration 350 : 0.9002867341041565
Mean training loss eporch  528 :  0.8451978296199173
Loss at iteration 50 : 0.8050503730773926
Loss at iteration 100 : 1.1836273670196533
Loss at iteration 150 : 0.8444080352783203
Loss at iteration 200 : 0.9118674993515015
Loss at iteration 250 : 0.8452327847480774
Loss at iteration 300 : 0.7870869040489197
Loss at iteration 350 : 0.820306658744812
Mean training loss eporch  529 :  0.8440200110907277
Loss at iteration 50 : 0.7049419283866882
Loss at iteration 100 : 0.5534720420837402
Loss at iteration 150 : 0.8694489002227783
Loss at iteration 200 : 0.7949551939964294
Loss at iteration 250 : 0.9689062833786011
Loss at iteration 300 : 0.7980061173439026
Loss at iteration 350 : 0.9455949068069458
Mean training loss eporch  530 :  0.8437445261491039
Loss at iteration 50 : 0.8802231550216675
Loss at iteration 100 : 1.04337477684021
Loss at iteration 150 : 0.8197579383850098
Loss at iteration 200 : 0.9193406701087952
Loss at iteration 250 : 0.6767944097518921
Loss at iteration 300 : 0.8224887251853943
Loss at iteration 350 : 0.6241738200187683
Mean training loss eporch  531 :  0.84402161868161
Loss at iteration 50 : 0.7539645433425903
Loss at iteration 100 : 0.891226053237915
Loss at iteration 150 : 0.6004408597946167
Loss at iteration 200 : 0.7302918434143066
Loss at iteration 250 : 0.5286836624145508
Loss at iteration 300 : 1.1478192806243896
Loss at iteration 350 : 0.5465273857116699
Mean training loss eporch  532 :  0.8439158952583081
Loss at iteration 50 : 0.9611448049545288
Loss at iteration 100 : 0.9945424795150757
Loss at iteration 150 : 0.7906122207641602
Loss at iteration 200 : 0.8263478875160217
Loss at iteration 250 : 1.1088354587554932
Loss at iteration 300 : 1.027479648590088
Loss at iteration 350 : 0.6731661558151245
Mean training loss eporch  533 :  0.844861149945587
Loss at iteration 50 : 0.8181204795837402
Loss at iteration 100 : 0.940812349319458
Loss at iteration 150 : 0.6294937133789062
Loss at iteration 200 : 0.6016613245010376
Loss at iteration 250 : 0.8138168454170227
Loss at iteration 300 : 0.8632729053497314
Loss at iteration 350 : 1.5825284719467163
Mean training loss eporch  534 :  0.8440247266380875
Loss at iteration 50 : 0.768153190612793
Loss at iteration 100 : 1.106041431427002
Loss at iteration 150 : 0.8860028982162476
Loss at iteration 200 : 1.0021724700927734
Loss at iteration 250 : 1.0237081050872803
Loss at iteration 300 : 0.9843007922172546
Loss at iteration 350 : 0.912593424320221
Mean training loss eporch  535 :  0.8437678539563739
Loss at iteration 50 : 0.6549718976020813
Loss at iteration 100 : 1.1776270866394043
Loss at iteration 150 : 0.817664384841919
Loss at iteration 200 : 1.0519219636917114
Loss at iteration 250 : 0.9600765705108643
Loss at iteration 300 : 0.9038519859313965
Loss at iteration 350 : 0.9585143327713013
Mean training loss eporch  536 :  0.8430137470285729
Loss at iteration 50 : 0.9967892169952393
Loss at iteration 100 : 0.8343505859375
Loss at iteration 150 : 0.8218536376953125
Loss at iteration 200 : 0.821765124797821
Loss at iteration 250 : 1.0064345598220825
Loss at iteration 300 : 0.8679238557815552
Loss at iteration 350 : 1.227879524230957
Mean training loss eporch  537 :  0.8441537825991867
Loss at iteration 50 : 0.9210107326507568
Loss at iteration 100 : 0.6921513676643372
Loss at iteration 150 : 0.8903658390045166
Loss at iteration 200 : 0.8755772113800049
Loss at iteration 250 : 0.7571804523468018
Loss at iteration 300 : 0.8493798971176147
Loss at iteration 350 : 1.1531755924224854
Mean training loss eporch  538 :  0.8443818210609375
Loss at iteration 50 : 1.0490220785140991
Loss at iteration 100 : 0.7272177934646606
Loss at iteration 150 : 0.7180647850036621
Loss at iteration 200 : 0.755598247051239
Loss at iteration 250 : 1.0475060939788818
Loss at iteration 300 : 0.923451840877533
Loss at iteration 350 : 0.8527278900146484
Mean training loss eporch  539 :  0.8449025273953796
Loss at iteration 50 : 0.8154230713844299
Loss at iteration 100 : 0.6747896671295166
Loss at iteration 150 : 1.03006112575531
Loss at iteration 200 : 1.054924488067627
Loss at iteration 250 : 0.7965857982635498
Loss at iteration 300 : 0.9160273671150208
Loss at iteration 350 : 1.054429054260254
Mean training loss eporch  540 :  0.8435508070326356
Loss at iteration 50 : 0.806446373462677
Loss at iteration 100 : 0.7472878694534302
Loss at iteration 150 : 1.1203906536102295
Loss at iteration 200 : 1.1142854690551758
Loss at iteration 250 : 0.7954791784286499
Loss at iteration 300 : 0.8183475136756897
Loss at iteration 350 : 0.5666434168815613
Mean training loss eporch  541 :  0.8443647361306287
Loss at iteration 50 : 0.7519340515136719
Loss at iteration 100 : 0.6875351667404175
Loss at iteration 150 : 0.7463616132736206
Loss at iteration 200 : 0.9537305235862732
Loss at iteration 250 : 0.5157609581947327
Loss at iteration 300 : 0.7939115166664124
Loss at iteration 350 : 0.7057923078536987
Mean training loss eporch  542 :  0.8442522819553103
Loss at iteration 50 : 0.7317490577697754
Loss at iteration 100 : 0.7554609775543213
Loss at iteration 150 : 0.7362241148948669
Loss at iteration 200 : 1.2040624618530273
Loss at iteration 250 : 0.6859478950500488
Loss at iteration 300 : 0.6842058300971985
Loss at iteration 350 : 0.915333092212677
Mean training loss eporch  543 :  0.844208794138419
Loss at iteration 50 : 1.312182903289795
Loss at iteration 100 : 0.8170656561851501
Loss at iteration 150 : 0.7365469336509705
Loss at iteration 200 : 0.8329898118972778
Loss at iteration 250 : 0.5551469326019287
Loss at iteration 300 : 1.0361692905426025
Loss at iteration 350 : 1.1051305532455444
Mean training loss eporch  544 :  0.8438886391422736
Loss at iteration 50 : 1.0511740446090698
Loss at iteration 100 : 0.8960813879966736
Loss at iteration 150 : 0.7381893992424011
Loss at iteration 200 : 0.6690129041671753
Loss at iteration 250 : 0.8965416550636292
Loss at iteration 300 : 0.6993221044540405
Loss at iteration 350 : 0.6984137892723083
Mean training loss eporch  545 :  0.844169652178174
Loss at iteration 50 : 1.128731369972229
Loss at iteration 100 : 0.7933664917945862
Loss at iteration 150 : 0.5764739513397217
Loss at iteration 200 : 1.2362689971923828
Loss at iteration 250 : 0.7607032656669617
Loss at iteration 300 : 0.7747997641563416
Loss at iteration 350 : 0.8058537244796753
Mean training loss eporch  546 :  0.8444742614787722
Loss at iteration 50 : 0.9235875010490417
Loss at iteration 100 : 0.738254189491272
Loss at iteration 150 : 0.8419758081436157
Loss at iteration 200 : 0.7763737440109253
Loss at iteration 250 : 0.9132493138313293
Loss at iteration 300 : 0.93223637342453
Loss at iteration 350 : 0.8236948251724243
Mean training loss eporch  547 :  0.8435063750024826
Loss at iteration 50 : 0.6794158816337585
Loss at iteration 100 : 1.112301230430603
Loss at iteration 150 : 0.7903933525085449
Loss at iteration 200 : 0.7906205654144287
Loss at iteration 250 : 0.8222922086715698
Loss at iteration 300 : 0.97295743227005
Loss at iteration 350 : 0.8197447657585144
Mean training loss eporch  548 :  0.8442264095185295
Loss at iteration 50 : 0.947599470615387
Loss at iteration 100 : 1.0806819200515747
Loss at iteration 150 : 1.082718849182129
Loss at iteration 200 : 1.015928030014038
Loss at iteration 250 : 0.8284744024276733
Loss at iteration 300 : 0.7992842197418213
Loss at iteration 350 : 0.9633307456970215
Mean training loss eporch  549 :  0.8437910097301322
Loss at iteration 50 : 0.7210105657577515
Loss at iteration 100 : 0.5905367136001587
Loss at iteration 150 : 0.9553999900817871
Loss at iteration 200 : 0.8794215321540833
Loss at iteration 250 : 0.8076532483100891
Loss at iteration 300 : 0.7968404293060303
Loss at iteration 350 : 0.7974807024002075
Mean training loss eporch  550 :  0.8442148950995592
Loss at iteration 50 : 0.8640562295913696
Loss at iteration 100 : 1.086014986038208
Loss at iteration 150 : 0.8280240297317505
Loss at iteration 200 : 1.091400384902954
Loss at iteration 250 : 0.8631633520126343
Loss at iteration 300 : 1.1470043659210205
Loss at iteration 350 : 0.8267145156860352
Mean training loss eporch  551 :  0.8439431321368647
Loss at iteration 50 : 0.88973468542099
Loss at iteration 100 : 0.7303926944732666
Loss at iteration 150 : 1.3401201963424683
Loss at iteration 200 : 0.7589573860168457
Loss at iteration 250 : 0.7820068597793579
Loss at iteration 300 : 1.0993688106536865
Loss at iteration 350 : 0.6194883584976196
Mean training loss eporch  552 :  0.8432494356203332
Loss at iteration 50 : 0.8202095627784729
Loss at iteration 100 : 0.9681777954101562
Loss at iteration 150 : 0.6052098274230957
Loss at iteration 200 : 0.6866540312767029
Loss at iteration 250 : 0.5940236449241638
Loss at iteration 300 : 0.8104296922683716
Loss at iteration 350 : 0.9694288372993469
Mean training loss eporch  553 :  0.843459699756254
Loss at iteration 50 : 0.7930980920791626
Loss at iteration 100 : 1.2162225246429443
Loss at iteration 150 : 0.8203043341636658
Loss at iteration 200 : 0.6426430940628052
Loss at iteration 250 : 0.7348685264587402
Loss at iteration 300 : 0.7509751319885254
Loss at iteration 350 : 0.8924334049224854
Mean training loss eporch  554 :  0.8444151428956834
Loss at iteration 50 : 0.687060534954071
Loss at iteration 100 : 0.898246169090271
Loss at iteration 150 : 1.0732393264770508
Loss at iteration 200 : 0.7009797096252441
Loss at iteration 250 : 0.7376166582107544
Loss at iteration 300 : 0.8530286550521851
Loss at iteration 350 : 0.7757718563079834
Mean training loss eporch  555 :  0.8435628082228717
Loss at iteration 50 : 0.7262364625930786
Loss at iteration 100 : 0.9420455098152161
Loss at iteration 150 : 0.7802200317382812
Loss at iteration 200 : 1.0173040628433228
Loss at iteration 250 : 0.9631575345993042
Loss at iteration 300 : 0.686559796333313
Loss at iteration 350 : 1.2668447494506836
Mean training loss eporch  556 :  0.8440619984631816
Loss at iteration 50 : 0.9378729462623596
Loss at iteration 100 : 0.6683894395828247
Loss at iteration 150 : 0.6726111769676208
Loss at iteration 200 : 0.91119784116745
Loss at iteration 250 : 0.8764266967773438
Loss at iteration 300 : 0.6447550058364868
Loss at iteration 350 : 0.6513280272483826
Mean training loss eporch  557 :  0.8441004437744302
Loss at iteration 50 : 0.8401872515678406
Loss at iteration 100 : 0.6815629005432129
Loss at iteration 150 : 0.8624597787857056
Loss at iteration 200 : 0.9200779795646667
Loss at iteration 250 : 0.9381375908851624
Loss at iteration 300 : 0.8614774942398071
Loss at iteration 350 : 0.7179667353630066
Mean training loss eporch  558 :  0.8435600392086796
Loss at iteration 50 : 0.6364739537239075
Loss at iteration 100 : 0.8940824270248413
Loss at iteration 150 : 0.769538402557373
Loss at iteration 200 : 0.7904934883117676
Loss at iteration 250 : 0.8158014416694641
Loss at iteration 300 : 0.9266356229782104
Loss at iteration 350 : 0.7297112345695496
Mean training loss eporch  559 :  0.8435031272589214
Loss at iteration 50 : 1.1464475393295288
Loss at iteration 100 : 1.0657165050506592
Loss at iteration 150 : 1.0657539367675781
Loss at iteration 200 : 0.9042302370071411
Loss at iteration 250 : 1.056203007698059
Loss at iteration 300 : 0.9236318469047546
Loss at iteration 350 : 0.9395414590835571
Mean training loss eporch  560 :  0.8434842039668371
Loss at iteration 50 : 0.9634441137313843
Loss at iteration 100 : 0.8547176122665405
Loss at iteration 150 : 0.9777073860168457
Loss at iteration 200 : 0.7803844213485718
Loss at iteration 250 : 0.6993354558944702
Loss at iteration 300 : 1.0215355157852173
Loss at iteration 350 : 0.8184565305709839
Mean training loss eporch  561 :  0.8438564650123082
Loss at iteration 50 : 0.7554870843887329
Loss at iteration 100 : 0.8061569929122925
Loss at iteration 150 : 0.8924866318702698
Loss at iteration 200 : 1.02217698097229
Loss at iteration 250 : 0.9736716747283936
Loss at iteration 300 : 0.7528457641601562
Loss at iteration 350 : 0.6986450552940369
Mean training loss eporch  562 :  0.8448925228819014
Loss at iteration 50 : 0.9124988317489624
Loss at iteration 100 : 0.7867237329483032
Loss at iteration 150 : 0.7738668918609619
Loss at iteration 200 : 0.9713047742843628
Loss at iteration 250 : 0.8779550790786743
Loss at iteration 300 : 0.7853617668151855
Loss at iteration 350 : 1.3354867696762085
Mean training loss eporch  563 :  0.8434920148559348
Loss at iteration 50 : 1.0598089694976807
Loss at iteration 100 : 0.5474976301193237
Loss at iteration 150 : 0.7370806932449341
Loss at iteration 200 : 0.5818981528282166
Loss at iteration 250 : 0.9897445440292358
Loss at iteration 300 : 0.9532508254051208
Loss at iteration 350 : 0.6070877313613892
Mean training loss eporch  564 :  0.8435872389525964
Loss at iteration 50 : 0.7974868416786194
Loss at iteration 100 : 1.1630821228027344
Loss at iteration 150 : 0.8815526962280273
Loss at iteration 200 : 1.0323271751403809
Loss at iteration 250 : 0.8995141983032227
Loss at iteration 300 : 0.8464258909225464
Loss at iteration 350 : 0.8265445232391357
Mean training loss eporch  565 :  0.8432619310718364
Loss at iteration 50 : 0.6865272521972656
Loss at iteration 100 : 0.5848233699798584
Loss at iteration 150 : 0.8386937975883484
Loss at iteration 200 : 0.7272026538848877
Loss at iteration 250 : 0.8547435998916626
Loss at iteration 300 : 0.8691291213035583
Loss at iteration 350 : 0.8430341482162476
Mean training loss eporch  566 :  0.8431591007602278
Loss at iteration 50 : 0.8175861239433289
Loss at iteration 100 : 0.9232323169708252
Loss at iteration 150 : 1.0462090969085693
Loss at iteration 200 : 1.162211537361145
Loss at iteration 250 : 0.8651068210601807
Loss at iteration 300 : 0.9435334205627441
Loss at iteration 350 : 1.019386887550354
Mean training loss eporch  567 :  0.8426554755716728
Loss at iteration 50 : 0.8891030550003052
Loss at iteration 100 : 0.6388119459152222
Loss at iteration 150 : 0.8840045928955078
Loss at iteration 200 : 0.6909477710723877
Loss at iteration 250 : 0.7424006462097168
Loss at iteration 300 : 0.7137464284896851
Loss at iteration 350 : 0.6593767404556274
Mean training loss eporch  568 :  0.8441146821098984
Loss at iteration 50 : 1.131766676902771
Loss at iteration 100 : 0.8706741333007812
Loss at iteration 150 : 0.7767776250839233
Loss at iteration 200 : 0.6030457019805908
Loss at iteration 250 : 1.074420690536499
Loss at iteration 300 : 0.778320848941803
Loss at iteration 350 : 0.9405656456947327
Mean training loss eporch  569 :  0.8437791037811804
Loss at iteration 50 : 0.7808079123497009
Loss at iteration 100 : 1.4784210920333862
Loss at iteration 150 : 1.0392251014709473
Loss at iteration 200 : 0.9277941584587097
Loss at iteration 250 : 0.7050944566726685
Loss at iteration 300 : 0.6966543793678284
Loss at iteration 350 : 0.763137936592102
Mean training loss eporch  570 :  0.8437189283982787
Loss at iteration 50 : 0.7374109029769897
Loss at iteration 100 : 0.6484072208404541
Loss at iteration 150 : 0.7113617658615112
Loss at iteration 200 : 0.47652721405029297
Loss at iteration 250 : 0.9230774641036987
Loss at iteration 300 : 0.9123117327690125
Loss at iteration 350 : 0.5817735195159912
Mean training loss eporch  571 :  0.8434522781107161
Loss at iteration 50 : 0.7756441235542297
Loss at iteration 100 : 0.715040922164917
Loss at iteration 150 : 0.7866469621658325
Loss at iteration 200 : 0.7157819271087646
Loss at iteration 250 : 0.6331995725631714
Loss at iteration 300 : 0.887546181678772
Loss at iteration 350 : 0.7847402095794678
Mean training loss eporch  572 :  0.8428986719045689
Loss at iteration 50 : 0.6752462387084961
Loss at iteration 100 : 0.665090799331665
Loss at iteration 150 : 0.9178659915924072
Loss at iteration 200 : 1.1086300611495972
Loss at iteration 250 : 0.7184565663337708
Loss at iteration 300 : 0.9153851270675659
Loss at iteration 350 : 1.0125350952148438
Mean training loss eporch  573 :  0.8432497466525073
Loss at iteration 50 : 1.036534070968628
Loss at iteration 100 : 0.8184608221054077
Loss at iteration 150 : 0.8876214027404785
Loss at iteration 200 : 1.1316758394241333
Loss at iteration 250 : 0.8329735994338989
Loss at iteration 300 : 0.7766092419624329
Loss at iteration 350 : 0.792992353439331
Mean training loss eporch  574 :  0.8433658252790491
Loss at iteration 50 : 0.8945325613021851
Loss at iteration 100 : 0.7158917188644409
Loss at iteration 150 : 0.8844947814941406
Loss at iteration 200 : 0.6647236347198486
Loss at iteration 250 : 0.8988092541694641
Loss at iteration 300 : 0.9182899594306946
Loss at iteration 350 : 1.0135537385940552
Mean training loss eporch  575 :  0.8431833652907579
Loss at iteration 50 : 0.8598510026931763
Loss at iteration 100 : 1.0642672777175903
Loss at iteration 150 : 1.0554349422454834
Loss at iteration 200 : 0.6971743106842041
Loss at iteration 250 : 0.8397661447525024
Loss at iteration 300 : 0.7645588517189026
Loss at iteration 350 : 0.9348242878913879
Mean training loss eporch  576 :  0.8432558104790077
Loss at iteration 50 : 0.7496329545974731
Loss at iteration 100 : 0.7327232360839844
Loss at iteration 150 : 1.1039775609970093
Loss at iteration 200 : 0.6389566659927368
Loss at iteration 250 : 0.9828670620918274
Loss at iteration 300 : 0.8241196870803833
Loss at iteration 350 : 1.1246707439422607
Mean training loss eporch  577 :  0.8436853366869467
Loss at iteration 50 : 0.7533313035964966
Loss at iteration 100 : 0.7955201268196106
Loss at iteration 150 : 0.7114146947860718
Loss at iteration 200 : 0.8054176568984985
Loss at iteration 250 : 0.8502593040466309
Loss at iteration 300 : 0.8561846017837524
Loss at iteration 350 : 0.9488412141799927
Mean training loss eporch  578 :  0.8430929248610501
Loss at iteration 50 : 0.6132984161376953
Loss at iteration 100 : 1.0329867601394653
Loss at iteration 150 : 0.8763009309768677
Loss at iteration 200 : 0.9077879190444946
Loss at iteration 250 : 0.7045988440513611
Loss at iteration 300 : 0.751295268535614
Loss at iteration 350 : 0.7502349019050598
Mean training loss eporch  579 :  0.8436719082966053
Loss at iteration 50 : 0.8418185710906982
Loss at iteration 100 : 1.0002139806747437
Loss at iteration 150 : 0.7629058361053467
Loss at iteration 200 : 0.7686969041824341
Loss at iteration 250 : 0.8026617169380188
Loss at iteration 300 : 1.0451290607452393
Loss at iteration 350 : 0.5701291561126709
Mean training loss eporch  580 :  0.8440300431201067
Loss at iteration 50 : 0.9912517070770264
Loss at iteration 100 : 0.78106689453125
Loss at iteration 150 : 0.8443325757980347
Loss at iteration 200 : 1.193542718887329
Loss at iteration 250 : 1.1435480117797852
Loss at iteration 300 : 1.0989577770233154
Loss at iteration 350 : 0.7895950078964233
Mean training loss eporch  581 :  0.8428889689622102
Loss at iteration 50 : 0.8509328365325928
Loss at iteration 100 : 0.6991498470306396
Loss at iteration 150 : 0.8326305150985718
Loss at iteration 200 : 0.8583681583404541
Loss at iteration 250 : 1.136301875114441
Loss at iteration 300 : 0.7499613761901855
Loss at iteration 350 : 0.741409182548523
Mean training loss eporch  582 :  0.8433032408750877
Loss at iteration 50 : 0.5202549695968628
Loss at iteration 100 : 1.0671424865722656
Loss at iteration 150 : 0.8264090418815613
Loss at iteration 200 : 0.5677156448364258
Loss at iteration 250 : 0.6560337543487549
Loss at iteration 300 : 0.9732198715209961
Loss at iteration 350 : 0.7856906056404114
Mean training loss eporch  583 :  0.8429782873108274
Loss at iteration 50 : 0.8293910026550293
Loss at iteration 100 : 1.0924592018127441
Loss at iteration 150 : 0.9681503772735596
Loss at iteration 200 : 0.7549499273300171
Loss at iteration 250 : 0.7505751848220825
Loss at iteration 300 : 0.575889527797699
Loss at iteration 350 : 0.9967718124389648
Mean training loss eporch  584 :  0.8429117921010527
Loss at iteration 50 : 0.9435111284255981
Loss at iteration 100 : 0.8024685382843018
Loss at iteration 150 : 1.3000285625457764
Loss at iteration 200 : 0.6446703672409058
Loss at iteration 250 : 0.786442220211029
Loss at iteration 300 : 0.80837082862854
Loss at iteration 350 : 0.8800028562545776
Mean training loss eporch  585 :  0.8433235142596816
Loss at iteration 50 : 0.7090674638748169
Loss at iteration 100 : 0.7384690046310425
Loss at iteration 150 : 0.7488211393356323
Loss at iteration 200 : 0.6898486614227295
Loss at iteration 250 : 0.7662339210510254
Loss at iteration 300 : 1.0375072956085205
Loss at iteration 350 : 0.7478101253509521
Mean training loss eporch  586 :  0.8433230214964145
Loss at iteration 50 : 1.0020986795425415
Loss at iteration 100 : 0.839893102645874
Loss at iteration 150 : 1.0690997838974
Loss at iteration 200 : 0.6504749655723572
Loss at iteration 250 : 0.7955688238143921
Loss at iteration 300 : 1.3219704627990723
Loss at iteration 350 : 0.9552761912345886
Mean training loss eporch  587 :  0.8436450759569804
Loss at iteration 50 : 0.9947404861450195
Loss at iteration 100 : 0.9030365347862244
Loss at iteration 150 : 0.7445818185806274
Loss at iteration 200 : 0.9394711256027222
Loss at iteration 250 : 0.8547515869140625
Loss at iteration 300 : 1.0435631275177002
Loss at iteration 350 : 0.761881947517395
Mean training loss eporch  588 :  0.8431991106145597
Loss at iteration 50 : 0.7734268307685852
Loss at iteration 100 : 0.7438186407089233
Loss at iteration 150 : 0.5880728960037231
Loss at iteration 200 : 0.8927750587463379
Loss at iteration 250 : 0.9391950964927673
Loss at iteration 300 : 1.1347050666809082
Loss at iteration 350 : 0.7759959101676941
Mean training loss eporch  589 :  0.8431354614477309
Loss at iteration 50 : 0.7873274087905884
Loss at iteration 100 : 0.5953706502914429
Loss at iteration 150 : 1.265566110610962
Loss at iteration 200 : 0.8691971898078918
Loss at iteration 250 : 0.6700464487075806
Loss at iteration 300 : 0.7940452694892883
Loss at iteration 350 : 0.6836839318275452
Mean training loss eporch  590 :  0.8427101200219815
Loss at iteration 50 : 0.8585047721862793
Loss at iteration 100 : 1.2166627645492554
Loss at iteration 150 : 0.9490408301353455
Loss at iteration 200 : 0.795838475227356
Loss at iteration 250 : 0.6528182625770569
Loss at iteration 300 : 0.7097569108009338
Loss at iteration 350 : 0.6451468467712402
Mean training loss eporch  591 :  0.8424782553520153
Loss at iteration 50 : 0.6952639818191528
Loss at iteration 100 : 0.7887046337127686
Loss at iteration 150 : 0.7961680293083191
Loss at iteration 200 : 0.8774811029434204
Loss at iteration 250 : 0.8420500755310059
Loss at iteration 300 : 0.744970440864563
Loss at iteration 350 : 1.0137059688568115
Mean training loss eporch  592 :  0.8432540138247152
Loss at iteration 50 : 1.388993740081787
Loss at iteration 100 : 0.810055136680603
Loss at iteration 150 : 0.9488667845726013
Loss at iteration 200 : 0.6568587422370911
Loss at iteration 250 : 0.5612431764602661
Loss at iteration 300 : 1.0443981885910034
Loss at iteration 350 : 0.5319793224334717
Mean training loss eporch  593 :  0.8424293408318172
Loss at iteration 50 : 0.725742757320404
Loss at iteration 100 : 0.8220528364181519
Loss at iteration 150 : 0.8419550657272339
Loss at iteration 200 : 1.0644173622131348
Loss at iteration 250 : 1.0571621656417847
Loss at iteration 300 : 0.7573641538619995
Loss at iteration 350 : 0.9790282845497131
Mean training loss eporch  594 :  0.843033457243884
Loss at iteration 50 : 0.7734503746032715
Loss at iteration 100 : 0.49458372592926025
Loss at iteration 150 : 0.8772035837173462
Loss at iteration 200 : 1.0157030820846558
Loss at iteration 250 : 0.8497607707977295
Loss at iteration 300 : 0.9895997643470764
Loss at iteration 350 : 0.6729830503463745
Mean training loss eporch  595 :  0.843069683701273
Loss at iteration 50 : 0.5305324792861938
Loss at iteration 100 : 0.7902100682258606
Loss at iteration 150 : 1.0116451978683472
Loss at iteration 200 : 1.261409878730774
Loss at iteration 250 : 0.7408461570739746
Loss at iteration 300 : 0.8887361288070679
Loss at iteration 350 : 0.8348863124847412
Mean training loss eporch  596 :  0.842909728093122
Loss at iteration 50 : 1.1236976385116577
Loss at iteration 100 : 1.0371241569519043
Loss at iteration 150 : 0.9075625538825989
Loss at iteration 200 : 0.6194400787353516
Loss at iteration 250 : 0.9031600952148438
Loss at iteration 300 : 0.6541849374771118
Loss at iteration 350 : 0.699386715888977
Mean training loss eporch  597 :  0.8426676074821482
Loss at iteration 50 : 0.921523928642273
Loss at iteration 100 : 0.8270436525344849
Loss at iteration 150 : 0.9043275117874146
Loss at iteration 200 : 0.9332123398780823
Loss at iteration 250 : 0.7815675735473633
Loss at iteration 300 : 0.5744239091873169
Loss at iteration 350 : 0.6472367644309998
Mean training loss eporch  598 :  0.843669140386203
Loss at iteration 50 : 0.8663440942764282
Loss at iteration 100 : 0.8565448522567749
Loss at iteration 150 : 0.8187887668609619
Loss at iteration 200 : 0.5519975423812866
Loss at iteration 250 : 0.8185563087463379
Loss at iteration 300 : 0.8474994897842407
Loss at iteration 350 : 0.7041073441505432
Mean training loss eporch  599 :  0.8427276915658719
Loss at iteration 50 : 0.628933846950531
Loss at iteration 100 : 0.6905272006988525
Loss at iteration 150 : 0.7994557023048401
Loss at iteration 200 : 0.7153841257095337
Loss at iteration 250 : 0.7709755301475525
Loss at iteration 300 : 0.9550018310546875
Loss at iteration 350 : 0.7855534553527832
Mean training loss eporch  600 :  0.8430949063212784
Loss at iteration 50 : 0.8225302696228027
Loss at iteration 100 : 0.6716043949127197
Loss at iteration 150 : 0.8662872314453125
Loss at iteration 200 : 0.9231072664260864
Loss at iteration 250 : 1.0819164514541626
Loss at iteration 300 : 0.8646277189254761
Loss at iteration 350 : 0.663529634475708
Mean training loss eporch  601 :  0.8427456967414372
Loss at iteration 50 : 0.8897407650947571
Loss at iteration 100 : 0.8853299617767334
Loss at iteration 150 : 0.9585031270980835
Loss at iteration 200 : 0.6627768278121948
Loss at iteration 250 : 0.683853805065155
Loss at iteration 300 : 0.8386856317520142
Loss at iteration 350 : 1.243300437927246
Mean training loss eporch  602 :  0.8422968448312195
Loss at iteration 50 : 0.6645045280456543
Loss at iteration 100 : 0.8435376286506653
Loss at iteration 150 : 0.7551685571670532
Loss at iteration 200 : 0.6412315368652344
Loss at iteration 250 : 0.8075722455978394
Loss at iteration 300 : 0.8648170232772827
Loss at iteration 350 : 0.8349213600158691
Mean training loss eporch  603 :  0.8431554654287914
Loss at iteration 50 : 0.9027152061462402
Loss at iteration 100 : 0.8846660852432251
Loss at iteration 150 : 1.0077264308929443
Loss at iteration 200 : 0.5444610714912415
Loss at iteration 250 : 0.7588250637054443
Loss at iteration 300 : 0.6433160305023193
Loss at iteration 350 : 0.6628618240356445
Mean training loss eporch  604 :  0.8426294624017029
Loss at iteration 50 : 0.9952126741409302
Loss at iteration 100 : 0.9767802953720093
Loss at iteration 150 : 0.7308272123336792
Loss at iteration 200 : 0.5394921898841858
Loss at iteration 250 : 0.9585965871810913
Loss at iteration 300 : 1.119210958480835
Loss at iteration 350 : 0.7453367114067078
Mean training loss eporch  605 :  0.843331665510223
Loss at iteration 50 : 0.6429864168167114
Loss at iteration 100 : 0.9108187556266785
Loss at iteration 150 : 0.6876751780509949
Loss at iteration 200 : 0.7096728086471558
Loss at iteration 250 : 0.6734309792518616
Loss at iteration 300 : 0.5079273581504822
Loss at iteration 350 : 0.8351976871490479
Mean training loss eporch  606 :  0.8420724484024855
Loss at iteration 50 : 1.210553765296936
Loss at iteration 100 : 0.757746696472168
Loss at iteration 150 : 0.8607215881347656
Loss at iteration 200 : 0.6545426249504089
Loss at iteration 250 : 0.8949465751647949
Loss at iteration 300 : 0.8879191875457764
Loss at iteration 350 : 0.7489964962005615
Mean training loss eporch  607 :  0.84317742524639
Loss at iteration 50 : 0.9611138105392456
Loss at iteration 100 : 0.9384503960609436
Loss at iteration 150 : 0.8567464351654053
Loss at iteration 200 : 0.9279187917709351
Loss at iteration 250 : 0.6948329210281372
Loss at iteration 300 : 0.6955829858779907
Loss at iteration 350 : 0.9674867391586304
Mean training loss eporch  608 :  0.8429662893531183
Loss at iteration 50 : 0.771630048751831
Loss at iteration 100 : 0.8542861938476562
Loss at iteration 150 : 0.7314355969429016
Loss at iteration 200 : 0.854574978351593
Loss at iteration 250 : 1.4568629264831543
Loss at iteration 300 : 0.6617169380187988
Loss at iteration 350 : 1.1142609119415283
Mean training loss eporch  609 :  0.843109326151313
Loss at iteration 50 : 0.6877621412277222
Loss at iteration 100 : 0.8584153056144714
Loss at iteration 150 : 0.6588882207870483
Loss at iteration 200 : 0.6941782832145691
Loss at iteration 250 : 0.6799996495246887
Loss at iteration 300 : 0.9217751026153564
Loss at iteration 350 : 0.9291977882385254
Mean training loss eporch  610 :  0.8429293897416856
Loss at iteration 50 : 0.7158886194229126
Loss at iteration 100 : 0.7595028877258301
Loss at iteration 150 : 0.845116138458252
Loss at iteration 200 : 1.1724669933319092
Loss at iteration 250 : 0.8156768083572388
Loss at iteration 300 : 0.9302726984024048
Loss at iteration 350 : 0.6962328553199768
Mean training loss eporch  611 :  0.8426897416985224
Loss at iteration 50 : 1.1033849716186523
Loss at iteration 100 : 0.7590721845626831
Loss at iteration 150 : 1.297663927078247
Loss at iteration 200 : 0.7993711233139038
Loss at iteration 250 : 0.7792035341262817
Loss at iteration 300 : 1.102134346961975
Loss at iteration 350 : 0.9153121709823608
Mean training loss eporch  612 :  0.8431476092843152
Loss at iteration 50 : 0.9019042253494263
Loss at iteration 100 : 0.7150080800056458
Loss at iteration 150 : 0.8141615390777588
Loss at iteration 200 : 0.8633109331130981
Loss at iteration 250 : 1.0714164972305298
Loss at iteration 300 : 1.0946532487869263
Loss at iteration 350 : 0.6802404522895813
Mean training loss eporch  613 :  0.8432971598610045
Loss at iteration 50 : 1.2038710117340088
Loss at iteration 100 : 1.0228184461593628
Loss at iteration 150 : 0.7785417437553406
Loss at iteration 200 : 1.1065174341201782
Loss at iteration 250 : 0.9733806848526001
Loss at iteration 300 : 0.8561328053474426
Loss at iteration 350 : 1.173409342765808
Mean training loss eporch  614 :  0.8423917903786614
Loss at iteration 50 : 0.6828375458717346
Loss at iteration 100 : 0.7105027437210083
Loss at iteration 150 : 0.8675605654716492
Loss at iteration 200 : 0.7295592427253723
Loss at iteration 250 : 0.7590001821517944
Loss at iteration 300 : 0.7093836665153503
Loss at iteration 350 : 0.9358025789260864
Mean training loss eporch  615 :  0.843574233313717
Loss at iteration 50 : 0.6748474836349487
Loss at iteration 100 : 0.612809419631958
Loss at iteration 150 : 0.6332345008850098
Loss at iteration 200 : 1.0023853778839111
Loss at iteration 250 : 0.6823676824569702
Loss at iteration 300 : 0.8858194351196289
Loss at iteration 350 : 0.6247161030769348
Mean training loss eporch  616 :  0.842788789165083
Loss at iteration 50 : 0.5533981323242188
Loss at iteration 100 : 1.0505824089050293
Loss at iteration 150 : 0.8548208475112915
Loss at iteration 200 : 0.9988688826560974
Loss at iteration 250 : 0.6283869743347168
Loss at iteration 300 : 1.1652789115905762
Loss at iteration 350 : 0.6657640337944031
Mean training loss eporch  617 :  0.842816614127033
Loss at iteration 50 : 0.9936537742614746
Loss at iteration 100 : 0.9730700850486755
Loss at iteration 150 : 0.8350815773010254
Loss at iteration 200 : 0.7792949676513672
Loss at iteration 250 : 0.6281764507293701
Loss at iteration 300 : 0.7709988355636597
Loss at iteration 350 : 0.878929853439331
Mean training loss eporch  618 :  0.8432427557214858
Loss at iteration 50 : 0.712650716304779
Loss at iteration 100 : 0.7458829879760742
Loss at iteration 150 : 0.8406784534454346
Loss at iteration 200 : 0.8185877203941345
Loss at iteration 250 : 0.5270951986312866
Loss at iteration 300 : 1.0492029190063477
Loss at iteration 350 : 0.6960657835006714
Mean training loss eporch  619 :  0.8431354508040443
Loss at iteration 50 : 0.9098116755485535
Loss at iteration 100 : 0.6790866255760193
Loss at iteration 150 : 0.6245765686035156
Loss at iteration 200 : 0.7473132610321045
Loss at iteration 250 : 0.8516786098480225
Loss at iteration 300 : 0.6393465399742126
Loss at iteration 350 : 0.7228052616119385
Mean training loss eporch  620 :  0.8425589698963064
Loss at iteration 50 : 1.0649852752685547
Loss at iteration 100 : 0.902773380279541
Loss at iteration 150 : 1.044451117515564
Loss at iteration 200 : 0.969063401222229
Loss at iteration 250 : 0.8227660655975342
Loss at iteration 300 : 0.7637927532196045
Loss at iteration 350 : 0.6798555850982666
Mean training loss eporch  621 :  0.8429330707227112
Loss at iteration 50 : 0.5685944557189941
Loss at iteration 100 : 0.8663040995597839
Loss at iteration 150 : 0.7329431772232056
Loss at iteration 200 : 0.8913666009902954
Loss at iteration 250 : 0.6633751392364502
Loss at iteration 300 : 0.6566272974014282
Loss at iteration 350 : 0.8816636800765991
Mean training loss eporch  622 :  0.8435015881818438
Loss at iteration 50 : 0.7965470552444458
Loss at iteration 100 : 0.7293649315834045
Loss at iteration 150 : 0.9723529815673828
Loss at iteration 200 : 0.9854928255081177
Loss at iteration 250 : 0.9634538888931274
Loss at iteration 300 : 0.7322841882705688
Loss at iteration 350 : 0.9048285484313965
Mean training loss eporch  623 :  0.8434003731876454
Loss at iteration 50 : 0.7900723218917847
Loss at iteration 100 : 0.6703698635101318
Loss at iteration 150 : 0.8979514241218567
Loss at iteration 200 : 0.707098126411438
Loss at iteration 250 : 0.6074960231781006
Loss at iteration 300 : 1.3090099096298218
Loss at iteration 350 : 0.8621941208839417
Mean training loss eporch  624 :  0.8418169228172807
Loss at iteration 50 : 0.9488322734832764
Loss at iteration 100 : 0.7177177667617798
Loss at iteration 150 : 1.0357050895690918
Loss at iteration 200 : 1.0870118141174316
Loss at iteration 250 : 0.7733920812606812
Loss at iteration 300 : 0.5958616733551025
Loss at iteration 350 : 0.6706613302230835
Mean training loss eporch  625 :  0.8421182734941048
Loss at iteration 50 : 1.1167151927947998
Loss at iteration 100 : 0.9269475936889648
Loss at iteration 150 : 0.5971450805664062
Loss at iteration 200 : 0.7135286331176758
Loss at iteration 250 : 0.8301825523376465
Loss at iteration 300 : 0.5888756513595581
Loss at iteration 350 : 0.716780424118042
Mean training loss eporch  626 :  0.8426618655680349
Loss at iteration 50 : 0.7015811800956726
Loss at iteration 100 : 0.7909463047981262
Loss at iteration 150 : 0.9635410308837891
Loss at iteration 200 : 0.7418479919433594
Loss at iteration 250 : 0.7768187522888184
Loss at iteration 300 : 0.9243237376213074
Loss at iteration 350 : 0.6878871917724609
Mean training loss eporch  627 :  0.8427928071173411
Loss at iteration 50 : 0.6811689734458923
Loss at iteration 100 : 0.7421245574951172
Loss at iteration 150 : 0.7814474105834961
Loss at iteration 200 : 1.0253852605819702
Loss at iteration 250 : 0.7297775745391846
Loss at iteration 300 : 0.9535669684410095
Loss at iteration 350 : 0.5579090118408203
Mean training loss eporch  628 :  0.8431310287859074
Loss at iteration 50 : 0.8546135425567627
Loss at iteration 100 : 0.9360523223876953
Loss at iteration 150 : 0.8634052276611328
Loss at iteration 200 : 1.223992109298706
Loss at iteration 250 : 0.8768283724784851
Loss at iteration 300 : 0.6756907105445862
Loss at iteration 350 : 1.1988873481750488
Mean training loss eporch  629 :  0.8425376087269455
Loss at iteration 50 : 0.6002063751220703
Loss at iteration 100 : 0.7056978940963745
Loss at iteration 150 : 0.8137226104736328
Loss at iteration 200 : 0.8330223560333252
Loss at iteration 250 : 0.7645291090011597
Loss at iteration 300 : 0.8690311312675476
Loss at iteration 350 : 0.6588871479034424
Mean training loss eporch  630 :  0.8420172501651068
Loss at iteration 50 : 0.8105950355529785
Loss at iteration 100 : 0.765746533870697
Loss at iteration 150 : 1.0527207851409912
Loss at iteration 200 : 0.7741445302963257
Loss at iteration 250 : 0.9554332494735718
Loss at iteration 300 : 0.9718911647796631
Loss at iteration 350 : 0.6636630892753601
Mean training loss eporch  631 :  0.8429694145760208
Loss at iteration 50 : 0.6492325663566589
Loss at iteration 100 : 0.8161402940750122
Loss at iteration 150 : 0.853661060333252
Loss at iteration 200 : 0.7507350444793701
Loss at iteration 250 : 0.6812307834625244
Loss at iteration 300 : 0.8564126491546631
Loss at iteration 350 : 0.8507710695266724
Mean training loss eporch  632 :  0.8422512672250233
Loss at iteration 50 : 0.9762556552886963
Loss at iteration 100 : 0.6945247054100037
Loss at iteration 150 : 0.8390383720397949
Loss at iteration 200 : 0.8661692142486572
Loss at iteration 250 : 0.9403669834136963
Loss at iteration 300 : 0.7014970779418945
Loss at iteration 350 : 0.839087963104248
Mean training loss eporch  633 :  0.8421261766284862
Loss at iteration 50 : 1.108780860900879
Loss at iteration 100 : 1.0371309518814087
Loss at iteration 150 : 0.6284552812576294
Loss at iteration 200 : 1.1751519441604614
Loss at iteration 250 : 1.0488425493240356
Loss at iteration 300 : 0.9407786726951599
Loss at iteration 350 : 0.8735917806625366
Mean training loss eporch  634 :  0.8420152523845592
Loss at iteration 50 : 0.6161415576934814
Loss at iteration 100 : 0.9107969999313354
Loss at iteration 150 : 0.6871533393859863
Loss at iteration 200 : 1.1804169416427612
Loss at iteration 250 : 1.2178810834884644
Loss at iteration 300 : 1.1235568523406982
Loss at iteration 350 : 0.9058728218078613
Mean training loss eporch  635 :  0.8428858049489834
Loss at iteration 50 : 0.9682959914207458
Loss at iteration 100 : 0.6859180927276611
Loss at iteration 150 : 0.6966800689697266
Loss at iteration 200 : 0.9607015252113342
Loss at iteration 250 : 0.616892397403717
Loss at iteration 300 : 0.7854683995246887
Loss at iteration 350 : 0.8004997372627258
Mean training loss eporch  636 :  0.8427672178814651
Loss at iteration 50 : 0.7689706683158875
Loss at iteration 100 : 0.625608503818512
Loss at iteration 150 : 0.6398964524269104
Loss at iteration 200 : 0.6312148571014404
Loss at iteration 250 : 0.7275827527046204
Loss at iteration 300 : 0.6232197880744934
Loss at iteration 350 : 0.8557465672492981
Mean training loss eporch  637 :  0.8416930281769031
Loss at iteration 50 : 0.701518177986145
Loss at iteration 100 : 1.0367100238800049
Loss at iteration 150 : 0.7158831357955933
Loss at iteration 200 : 1.0187679529190063
Loss at iteration 250 : 0.7718725204467773
Loss at iteration 300 : 1.1881080865859985
Loss at iteration 350 : 1.0260705947875977
Mean training loss eporch  638 :  0.8420624680146969
Loss at iteration 50 : 1.39799964427948
Loss at iteration 100 : 0.7431000471115112
Loss at iteration 150 : 0.7429546117782593
Loss at iteration 200 : 0.6544408798217773
Loss at iteration 250 : 0.6715075373649597
Loss at iteration 300 : 0.8391613960266113
Loss at iteration 350 : 0.6830995082855225
Mean training loss eporch  639 :  0.8430572774202104
Loss at iteration 50 : 0.8181318640708923
Loss at iteration 100 : 0.9306638240814209
Loss at iteration 150 : 0.8116999268531799
Loss at iteration 200 : 0.8019968271255493
Loss at iteration 250 : 0.7479680776596069
Loss at iteration 300 : 0.6667190194129944
Loss at iteration 350 : 0.8156681060791016
Mean training loss eporch  640 :  0.8417274035000927
Loss at iteration 50 : 0.7939115762710571
Loss at iteration 100 : 0.842488706111908
Loss at iteration 150 : 0.87035071849823
Loss at iteration 200 : 1.0062748193740845
Loss at iteration 250 : 0.7599982023239136
Loss at iteration 300 : 1.0816158056259155
Loss at iteration 350 : 0.7452762126922607
Mean training loss eporch  641 :  0.8436762534436726
Loss at iteration 50 : 0.6406184434890747
Loss at iteration 100 : 0.6679192781448364
Loss at iteration 150 : 0.8157223463058472
Loss at iteration 200 : 0.7027779817581177
Loss at iteration 250 : 0.6841492652893066
Loss at iteration 300 : 0.6687431335449219
Loss at iteration 350 : 0.5609709620475769
Mean training loss eporch  642 :  0.842354333353421
Loss at iteration 50 : 0.8423895835876465
Loss at iteration 100 : 0.7774172425270081
Loss at iteration 150 : 0.7428008317947388
Loss at iteration 200 : 1.004830002784729
Loss at iteration 250 : 0.7219705581665039
Loss at iteration 300 : 1.1364632844924927
Loss at iteration 350 : 0.7210425138473511
Mean training loss eporch  643 :  0.8435239653896403
Loss at iteration 50 : 0.6888866424560547
Loss at iteration 100 : 0.8678168058395386
Loss at iteration 150 : 1.1238244771957397
Loss at iteration 200 : 0.7843549847602844
Loss at iteration 250 : 0.5364835262298584
Loss at iteration 300 : 0.9015489220619202
Loss at iteration 350 : 0.7305607199668884
Mean training loss eporch  644 :  0.8427055463904426
Loss at iteration 50 : 0.7909748554229736
Loss at iteration 100 : 0.9104105830192566
Loss at iteration 150 : 1.2253444194793701
Loss at iteration 200 : 0.8422330617904663
Loss at iteration 250 : 0.6575225591659546
Loss at iteration 300 : 0.6024874448776245
Loss at iteration 350 : 0.8583453893661499
Mean training loss eporch  645 :  0.8428807847556614
Loss at iteration 50 : 0.9534131288528442
Loss at iteration 100 : 0.8993933200836182
Loss at iteration 150 : 1.2177467346191406
Loss at iteration 200 : 0.7564647197723389
Loss at iteration 250 : 1.0563809871673584
Loss at iteration 300 : 0.721168041229248
Loss at iteration 350 : 0.7182930707931519
Mean training loss eporch  646 :  0.8419323891558975
Loss at iteration 50 : 0.9936968088150024
Loss at iteration 100 : 0.7844451665878296
Loss at iteration 150 : 0.8039195537567139
Loss at iteration 200 : 0.9262918829917908
Loss at iteration 250 : 0.48443055152893066
Loss at iteration 300 : 0.7299469709396362
Loss at iteration 350 : 0.9355826377868652
Mean training loss eporch  647 :  0.8425616234067886
Loss at iteration 50 : 0.5881614089012146
Loss at iteration 100 : 0.9020062685012817
Loss at iteration 150 : 0.8875265121459961
Loss at iteration 200 : 0.7902049422264099
Loss at iteration 250 : 0.7378276586532593
Loss at iteration 300 : 0.8227717876434326
Loss at iteration 350 : 0.674643874168396
Mean training loss eporch  648 :  0.8426053526382598
Loss at iteration 50 : 0.6849620342254639
Loss at iteration 100 : 1.1053252220153809
Loss at iteration 150 : 0.8551832437515259
Loss at iteration 200 : 0.8126476407051086
Loss at iteration 250 : 0.9556527137756348
Loss at iteration 300 : 0.7040773630142212
Loss at iteration 350 : 0.910064160823822
Mean training loss eporch  649 :  0.8418905439357909
Loss at iteration 50 : 0.6221507787704468
Loss at iteration 100 : 0.9395907521247864
Loss at iteration 150 : 0.9816392064094543
Loss at iteration 200 : 0.7832227945327759
Loss at iteration 250 : 0.7259238362312317
Loss at iteration 300 : 0.9983094930648804
Loss at iteration 350 : 1.0588700771331787
Mean training loss eporch  650 :  0.8421596878420108
Loss at iteration 50 : 0.9040312170982361
Loss at iteration 100 : 0.8760292530059814
Loss at iteration 150 : 0.8142619132995605
Loss at iteration 200 : 0.6634433269500732
Loss at iteration 250 : 0.9330286383628845
Loss at iteration 300 : 0.6295195817947388
Loss at iteration 350 : 0.8783060908317566
Mean training loss eporch  651 :  0.8428024749749552
Loss at iteration 50 : 1.2070990800857544
Loss at iteration 100 : 1.1153651475906372
Loss at iteration 150 : 1.0217496156692505
Loss at iteration 200 : 0.7469913959503174
Loss at iteration 250 : 0.7948848605155945
Loss at iteration 300 : 0.7866863012313843
Loss at iteration 350 : 0.7319426536560059
Mean training loss eporch  652 :  0.8425922261344062
Loss at iteration 50 : 0.5313839912414551
Loss at iteration 100 : 0.9321746230125427
Loss at iteration 150 : 1.1881980895996094
Loss at iteration 200 : 0.5595138669013977
Loss at iteration 250 : 0.6226058006286621
Loss at iteration 300 : 0.8709754943847656
Loss at iteration 350 : 0.8188571333885193
Mean training loss eporch  653 :  0.8428795577357056
Loss at iteration 50 : 0.7374600172042847
Loss at iteration 100 : 1.0540939569473267
Loss at iteration 150 : 0.861324667930603
Loss at iteration 200 : 0.8602421283721924
Loss at iteration 250 : 1.4410176277160645
Loss at iteration 300 : 0.8802237510681152
Loss at iteration 350 : 0.9591455459594727
Mean training loss eporch  654 :  0.841905807613065
Loss at iteration 50 : 0.6909635066986084
Loss at iteration 100 : 0.8033456802368164
Loss at iteration 150 : 1.050992488861084
Loss at iteration 200 : 1.1654999256134033
Loss at iteration 250 : 1.0320026874542236
Loss at iteration 300 : 0.8975690007209778
Loss at iteration 350 : 0.7629756927490234
Mean training loss eporch  655 :  0.8418843356705217
Loss at iteration 50 : 0.8203696012496948
Loss at iteration 100 : 0.7333897948265076
Loss at iteration 150 : 0.7111192345619202
Loss at iteration 200 : 0.8087078332901001
Loss at iteration 250 : 0.8287944197654724
Loss at iteration 300 : 0.8078444004058838
Loss at iteration 350 : 0.7086609601974487
Mean training loss eporch  656 :  0.8425995400027623
Loss at iteration 50 : 0.9082125425338745
Loss at iteration 100 : 0.8278881907463074
Loss at iteration 150 : 0.633452832698822
Loss at iteration 200 : 0.8392302989959717
Loss at iteration 250 : 0.684821605682373
Loss at iteration 300 : 0.8893558979034424
Loss at iteration 350 : 0.6893677711486816
Mean training loss eporch  657 :  0.8424880395806025
Loss at iteration 50 : 1.2155237197875977
Loss at iteration 100 : 0.6733598709106445
Loss at iteration 150 : 0.9224973917007446
Loss at iteration 200 : 0.46109986305236816
Loss at iteration 250 : 0.6118597388267517
Loss at iteration 300 : 0.886665940284729
Loss at iteration 350 : 1.0934550762176514
Mean training loss eporch  658 :  0.8425088755037419
Loss at iteration 50 : 1.039831280708313
Loss at iteration 100 : 0.9936788082122803
Loss at iteration 150 : 0.7110803127288818
Loss at iteration 200 : 0.9563981890678406
Loss at iteration 250 : 0.7307329177856445
Loss at iteration 300 : 0.8100418448448181
Loss at iteration 350 : 0.7449240684509277
Mean training loss eporch  659 :  0.8421071684234357
Loss at iteration 50 : 0.840455174446106
Loss at iteration 100 : 0.7206341028213501
Loss at iteration 150 : 0.7996693253517151
Loss at iteration 200 : 0.9083456993103027
Loss at iteration 250 : 0.8827202916145325
Loss at iteration 300 : 0.7828223705291748
Loss at iteration 350 : 1.1917214393615723
Mean training loss eporch  660 :  0.8422092754374105
Loss at iteration 50 : 0.5535395741462708
Loss at iteration 100 : 1.1465493440628052
Loss at iteration 150 : 0.8692649602890015
Loss at iteration 200 : 0.6921239495277405
Loss at iteration 250 : 0.5777844190597534
Loss at iteration 300 : 0.9721364974975586
Loss at iteration 350 : 1.2613811492919922
Mean training loss eporch  661 :  0.8421907644107859
Loss at iteration 50 : 0.6180942058563232
Loss at iteration 100 : 0.6039977073669434
Loss at iteration 150 : 0.8693907856941223
Loss at iteration 200 : 0.9147554636001587
Loss at iteration 250 : 1.102928638458252
Loss at iteration 300 : 0.917199432849884
Loss at iteration 350 : 1.0991162061691284
Mean training loss eporch  662 :  0.8422513939243145
Loss at iteration 50 : 0.7501692771911621
Loss at iteration 100 : 1.008460283279419
Loss at iteration 150 : 0.7128075361251831
Loss at iteration 200 : 0.7356592416763306
Loss at iteration 250 : 1.0161241292953491
Loss at iteration 300 : 0.8379976153373718
Loss at iteration 350 : 0.7353534698486328
Mean training loss eporch  663 :  0.842083362202165
Loss at iteration 50 : 0.7589151859283447
Loss at iteration 100 : 1.117472529411316
Loss at iteration 150 : 0.6797538995742798
Loss at iteration 200 : 1.277181625366211
Loss at iteration 250 : 0.9872670769691467
Loss at iteration 300 : 0.6678785681724548
Loss at iteration 350 : 0.5237537026405334
Mean training loss eporch  664 :  0.84235882861589
Loss at iteration 50 : 0.764735758304596
Loss at iteration 100 : 0.9908123016357422
Loss at iteration 150 : 0.5718033909797668
Loss at iteration 200 : 1.1285346746444702
Loss at iteration 250 : 1.0164010524749756
Loss at iteration 300 : 0.8080911636352539
Loss at iteration 350 : 1.0314514636993408
Mean training loss eporch  665 :  0.8419249258028767
Loss at iteration 50 : 0.990450382232666
Loss at iteration 100 : 0.9718338251113892
Loss at iteration 150 : 0.830346941947937
Loss at iteration 200 : 0.868744969367981
Loss at iteration 250 : 1.007844090461731
Loss at iteration 300 : 0.585700511932373
Loss at iteration 350 : 0.9500449895858765
Mean training loss eporch  666 :  0.8423185348510742
Loss at iteration 50 : 0.935370922088623
Loss at iteration 100 : 0.8022245764732361
Loss at iteration 150 : 0.8454396724700928
Loss at iteration 200 : 1.078894019126892
Loss at iteration 250 : 0.9062259793281555
Loss at iteration 300 : 0.8969341516494751
Loss at iteration 350 : 1.1767441034317017
Mean training loss eporch  667 :  0.8429372884609081
Loss at iteration 50 : 0.9221607446670532
Loss at iteration 100 : 0.647141695022583
Loss at iteration 150 : 0.8727177381515503
Loss at iteration 200 : 1.1899895668029785
Loss at iteration 250 : 0.7498586177825928
Loss at iteration 300 : 1.3065805435180664
Loss at iteration 350 : 0.8807520866394043
Mean training loss eporch  668 :  0.8423257046748721
Loss at iteration 50 : 0.9078004360198975
Loss at iteration 100 : 0.7114576101303101
Loss at iteration 150 : 0.8169472217559814
Loss at iteration 200 : 0.6301041841506958
Loss at iteration 250 : 0.6043302416801453
Loss at iteration 300 : 0.5709652304649353
Loss at iteration 350 : 0.7296254634857178
Mean training loss eporch  669 :  0.8420911298857795
Loss at iteration 50 : 0.7620375752449036
Loss at iteration 100 : 0.9938070774078369
Loss at iteration 150 : 0.6837221384048462
Loss at iteration 200 : 0.7048898339271545
Loss at iteration 250 : 1.246244192123413
Loss at iteration 300 : 1.1253561973571777
Loss at iteration 350 : 0.6631742715835571
Mean training loss eporch  670 :  0.8424654391707567
Loss at iteration 50 : 0.993226170539856
Loss at iteration 100 : 0.9647008180618286
Loss at iteration 150 : 0.7114298343658447
Loss at iteration 200 : 1.1082326173782349
Loss at iteration 250 : 1.0046961307525635
Loss at iteration 300 : 0.7983198165893555
Loss at iteration 350 : 0.9851781129837036
Mean training loss eporch  671 :  0.8426336397727331
Loss at iteration 50 : 0.8524715900421143
Loss at iteration 100 : 0.9126731157302856
Loss at iteration 150 : 0.6626313924789429
Loss at iteration 200 : 0.6497384309768677
Loss at iteration 250 : 0.8920440077781677
Loss at iteration 300 : 0.7786338329315186
Loss at iteration 350 : 0.6626183390617371
Mean training loss eporch  672 :  0.8421369198138121
Loss at iteration 50 : 0.7847591638565063
Loss at iteration 100 : 0.7513631582260132
Loss at iteration 150 : 0.7407189607620239
Loss at iteration 200 : 0.8213502168655396
Loss at iteration 250 : 0.9396626353263855
Loss at iteration 300 : 0.8906338214874268
Loss at iteration 350 : 0.8029752373695374
Mean training loss eporch  673 :  0.8428333638206361
Loss at iteration 50 : 0.7795538902282715
Loss at iteration 100 : 0.8189076781272888
Loss at iteration 150 : 0.8384676575660706
Loss at iteration 200 : 0.7795220613479614
Loss at iteration 250 : 0.847503662109375
Loss at iteration 300 : 0.86747145652771
Loss at iteration 350 : 1.132495403289795
Mean training loss eporch  674 :  0.8431814331856985
Loss at iteration 50 : 0.8462412357330322
Loss at iteration 100 : 0.9328367710113525
Loss at iteration 150 : 0.5695711374282837
Loss at iteration 200 : 0.7978509664535522
Loss at iteration 250 : 0.8244231939315796
Loss at iteration 300 : 0.887776255607605
Loss at iteration 350 : 1.073144793510437
Mean training loss eporch  675 :  0.8431283486267876
Loss at iteration 50 : 0.7603782415390015
Loss at iteration 100 : 0.8917999267578125
Loss at iteration 150 : 0.8219078779220581
Loss at iteration 200 : 0.7669429183006287
Loss at iteration 250 : 0.8488089442253113
Loss at iteration 300 : 0.48689931631088257
Loss at iteration 350 : 0.7638713121414185
Mean training loss eporch  676 :  0.8419947481502301
Loss at iteration 50 : 0.7598028779029846
Loss at iteration 100 : 0.9084796905517578
Loss at iteration 150 : 0.8247857093811035
Loss at iteration 200 : 0.6571379899978638
Loss at iteration 250 : 0.6078081130981445
Loss at iteration 300 : 1.252052664756775
Loss at iteration 350 : 0.7008615732192993
Mean training loss eporch  677 :  0.843945195987111
Loss at iteration 50 : 1.1064624786376953
Loss at iteration 100 : 0.8752937316894531
Loss at iteration 150 : 0.8008351922035217
Loss at iteration 200 : 0.9188424348831177
Loss at iteration 250 : 0.651060938835144
Loss at iteration 300 : 0.8421704769134521
Loss at iteration 350 : 0.9395014643669128
Mean training loss eporch  678 :  0.8425807508999709
Loss at iteration 50 : 0.7633625268936157
Loss at iteration 100 : 0.5792108178138733
Loss at iteration 150 : 0.7940957546234131
Loss at iteration 200 : 1.0933367013931274
Loss at iteration 250 : 0.796576738357544
Loss at iteration 300 : 0.6211693286895752
Loss at iteration 350 : 0.6645053029060364
Mean training loss eporch  679 :  0.8425693910904032
Loss at iteration 50 : 0.6192895174026489
Loss at iteration 100 : 0.8845679759979248
Loss at iteration 150 : 0.6869046688079834
Loss at iteration 200 : 0.6953721046447754
Loss at iteration 250 : 0.6624888181686401
Loss at iteration 300 : 0.7841309309005737
Loss at iteration 350 : 0.6828416585922241
Mean training loss eporch  680 :  0.8430003239994958
Loss at iteration 50 : 0.9937103390693665
Loss at iteration 100 : 0.7621951103210449
Loss at iteration 150 : 0.8795492649078369
Loss at iteration 200 : 0.8152821660041809
Loss at iteration 250 : 0.7907304167747498
Loss at iteration 300 : 0.7866045236587524
Loss at iteration 350 : 0.9468111991882324
Mean training loss eporch  681 :  0.8419446360970301
Loss at iteration 50 : 0.8081940412521362
Loss at iteration 100 : 0.8764568567276001
Loss at iteration 150 : 0.8031914830207825
Loss at iteration 200 : 0.9286757707595825
Loss at iteration 250 : 0.7379387021064758
Loss at iteration 300 : 0.7377545833587646
Loss at iteration 350 : 0.92946857213974
Mean training loss eporch  682 :  0.8425556402357798
Loss at iteration 50 : 0.9485108852386475
Loss at iteration 100 : 0.9245866537094116
Loss at iteration 150 : 0.9854282736778259
Loss at iteration 200 : 0.7817062139511108
Loss at iteration 250 : 0.858639121055603
Loss at iteration 300 : 0.8484963178634644
Loss at iteration 350 : 0.771016538143158
Mean training loss eporch  683 :  0.8417184397814765
Loss at iteration 50 : 0.6922141313552856
Loss at iteration 100 : 0.8644344210624695
Loss at iteration 150 : 0.7981037497520447
Loss at iteration 200 : 0.7398165464401245
Loss at iteration 250 : 1.2110979557037354
Loss at iteration 300 : 0.763347327709198
Loss at iteration 350 : 0.6996932029724121
Mean training loss eporch  684 :  0.8426004490524373
Loss at iteration 50 : 0.625627338886261
Loss at iteration 100 : 0.9876612424850464
Loss at iteration 150 : 1.1688413619995117
Loss at iteration 200 : 0.8415428400039673
Loss at iteration 250 : 0.8861788511276245
Loss at iteration 300 : 0.8713279962539673
Loss at iteration 350 : 0.6425363421440125
Mean training loss eporch  685 :  0.8435226215256585
Loss at iteration 50 : 0.7030022740364075
Loss at iteration 100 : 0.9551129341125488
Loss at iteration 150 : 0.6668311357498169
Loss at iteration 200 : 0.7124531865119934
Loss at iteration 250 : 1.4574916362762451
Loss at iteration 300 : 0.9573012590408325
Loss at iteration 350 : 0.885553240776062
Mean training loss eporch  686 :  0.8426655787954885
Loss at iteration 50 : 0.7200047969818115
Loss at iteration 100 : 1.0942662954330444
Loss at iteration 150 : 0.8094481825828552
Loss at iteration 200 : 0.8402197957038879
Loss at iteration 250 : 0.7664673328399658
Loss at iteration 300 : 0.7906187772750854
Loss at iteration 350 : 0.9911597371101379
Mean training loss eporch  687 :  0.8420952083887877
Loss at iteration 50 : 0.7666918635368347
Loss at iteration 100 : 0.5637742877006531
Loss at iteration 150 : 0.7579596042633057
Loss at iteration 200 : 0.6577619314193726
Loss at iteration 250 : 0.7377923727035522
Loss at iteration 300 : 0.9494774341583252
Loss at iteration 350 : 0.8994753360748291
Mean training loss eporch  688 :  0.8429283917580963
Loss at iteration 50 : 0.6688556671142578
Loss at iteration 100 : 1.0722025632858276
Loss at iteration 150 : 0.8268128633499146
Loss at iteration 200 : 0.7779824733734131
Loss at iteration 250 : 0.6562927961349487
Loss at iteration 300 : 0.7598003149032593
Loss at iteration 350 : 0.7822781205177307
Mean training loss eporch  689 :  0.8420724963384961
Loss at iteration 50 : 0.7354671955108643
Loss at iteration 100 : 0.6935722827911377
Loss at iteration 150 : 0.6493068337440491
Loss at iteration 200 : 0.8519147634506226
Loss at iteration 250 : 0.8193269371986389
Loss at iteration 300 : 0.8882104754447937
Loss at iteration 350 : 0.709800124168396
Mean training loss eporch  690 :  0.8423981397713303
Loss at iteration 50 : 0.9151635766029358
Loss at iteration 100 : 1.0268006324768066
Loss at iteration 150 : 0.7606213092803955
Loss at iteration 200 : 0.6202387809753418
Loss at iteration 250 : 0.9100593328475952
Loss at iteration 300 : 0.7331594824790955
Loss at iteration 350 : 0.8082656264305115
Mean training loss eporch  691 :  0.8422160697361779
Loss at iteration 50 : 0.680168628692627
Loss at iteration 100 : 0.9077726602554321
Loss at iteration 150 : 0.6415603160858154
Loss at iteration 200 : 0.9811009168624878
Loss at iteration 250 : 0.96822190284729
Loss at iteration 300 : 0.9510884284973145
Loss at iteration 350 : 1.1851431131362915
Mean training loss eporch  692 :  0.8421908706899673
Loss at iteration 50 : 0.8472526669502258
Loss at iteration 100 : 0.6617923974990845
Loss at iteration 150 : 0.9116607904434204
Loss at iteration 200 : 0.7056598663330078
Loss at iteration 250 : 0.9463282823562622
Loss at iteration 300 : 1.1514137983322144
Loss at iteration 350 : 0.8601526021957397
Mean training loss eporch  693 :  0.8426169216948212
Loss at iteration 50 : 0.7072188854217529
Loss at iteration 100 : 0.8214219808578491
Loss at iteration 150 : 0.9445062875747681
Loss at iteration 200 : 0.846170961856842
Loss at iteration 250 : 1.2957404851913452
Loss at iteration 300 : 0.684527575969696
Loss at iteration 350 : 1.0448259115219116
Mean training loss eporch  694 :  0.842016799345849
Loss at iteration 50 : 1.2576245069503784
Loss at iteration 100 : 0.6023874282836914
Loss at iteration 150 : 0.8876984119415283
Loss at iteration 200 : 0.6775742769241333
Loss at iteration 250 : 0.6784776449203491
Loss at iteration 300 : 0.5751848220825195
Loss at iteration 350 : 0.8263356685638428
Mean training loss eporch  695 :  0.8425412763048101
Loss at iteration 50 : 0.5697625279426575
Loss at iteration 100 : 1.026930570602417
Loss at iteration 150 : 0.5952526330947876
Loss at iteration 200 : 1.0025179386138916
Loss at iteration 250 : 0.7352993488311768
Loss at iteration 300 : 0.8164653778076172
Loss at iteration 350 : 0.6873526573181152
Mean training loss eporch  696 :  0.8424863949339226
Loss at iteration 50 : 0.7959725856781006
Loss at iteration 100 : 0.6775241494178772
Loss at iteration 150 : 0.839706301689148
Loss at iteration 200 : 0.7467259764671326
Loss at iteration 250 : 0.5770207643508911
Loss at iteration 300 : 0.9091030955314636
Loss at iteration 350 : 0.9694179892539978
Mean training loss eporch  697 :  0.842558076536214
Loss at iteration 50 : 0.6523699760437012
Loss at iteration 100 : 0.9515688419342041
Loss at iteration 150 : 0.6044049263000488
Loss at iteration 200 : 1.4716471433639526
Loss at iteration 250 : 0.7309790849685669
Loss at iteration 300 : 0.8455286026000977
Loss at iteration 350 : 0.6600962281227112
Mean training loss eporch  698 :  0.8421133859920754
Loss at iteration 50 : 0.6220962405204773
Loss at iteration 100 : 0.6152303814888
Loss at iteration 150 : 1.121196985244751
Loss at iteration 200 : 0.8204879760742188
Loss at iteration 250 : 1.3029528856277466
Loss at iteration 300 : 0.6610028147697449
Loss at iteration 350 : 0.8050234317779541
Mean training loss eporch  699 :  0.8421024110897508
Loss at iteration 50 : 1.087170124053955
Loss at iteration 100 : 0.6988662481307983
Loss at iteration 150 : 0.9017753005027771
Loss at iteration 200 : 0.5969629883766174
Loss at iteration 250 : 0.6933324337005615
Loss at iteration 300 : 1.0342172384262085
Loss at iteration 350 : 0.9060990810394287
Mean training loss eporch  700 :  0.8425096416126483
Loss at iteration 50 : 0.6961846947669983
Loss at iteration 100 : 0.8566589951515198
Loss at iteration 150 : 1.0760695934295654
Loss at iteration 200 : 0.7554421424865723
Loss at iteration 250 : 0.9956976771354675
Loss at iteration 300 : 0.662691593170166
Loss at iteration 350 : 0.7387545108795166
Mean training loss eporch  701 :  0.8424829043566234
Loss at iteration 50 : 0.909095823764801
Loss at iteration 100 : 0.7131516933441162
Loss at iteration 150 : 0.5357800722122192
Loss at iteration 200 : 1.051071047782898
Loss at iteration 250 : 0.8331339359283447
Loss at iteration 300 : 0.8000357747077942
Loss at iteration 350 : 1.1075196266174316
Mean training loss eporch  702 :  0.8417518143616025
Loss at iteration 50 : 0.9854428768157959
Loss at iteration 100 : 0.7984035015106201
Loss at iteration 150 : 0.5514962077140808
Loss at iteration 200 : 0.8776997327804565
Loss at iteration 250 : 0.823833167552948
Loss at iteration 300 : 0.5704752206802368
Loss at iteration 350 : 0.8200781345367432
Mean training loss eporch  703 :  0.8418684712951146
Loss at iteration 50 : 1.0885220766067505
Loss at iteration 100 : 0.8484023213386536
Loss at iteration 150 : 0.7816683053970337
Loss at iteration 200 : 0.7859145998954773
Loss at iteration 250 : 0.7713321447372437
Loss at iteration 300 : 0.6262956857681274
Loss at iteration 350 : 1.0109002590179443
Mean training loss eporch  704 :  0.8424019334965913
Loss at iteration 50 : 0.8733405470848083
Loss at iteration 100 : 0.6350560188293457
Loss at iteration 150 : 0.6403698921203613
Loss at iteration 200 : 0.8009512424468994
Loss at iteration 250 : 0.8919572830200195
Loss at iteration 300 : 0.9620389938354492
Loss at iteration 350 : 0.8690718412399292
Mean training loss eporch  705 :  0.8423640535622047
Loss at iteration 50 : 1.0746924877166748
Loss at iteration 100 : 1.0096862316131592
Loss at iteration 150 : 0.6771081686019897
Loss at iteration 200 : 0.5677958130836487
Loss at iteration 250 : 0.8182963132858276
Loss at iteration 300 : 0.9666100740432739
Loss at iteration 350 : 0.771992564201355
Mean training loss eporch  706 :  0.8416706485250008
Loss at iteration 50 : 0.7843101024627686
Loss at iteration 100 : 1.4304723739624023
Loss at iteration 150 : 0.9274827241897583
Loss at iteration 200 : 0.6902236938476562
Loss at iteration 250 : 0.6825453042984009
Loss at iteration 300 : 0.8678012490272522
Loss at iteration 350 : 0.7454724907875061
Mean training loss eporch  707 :  0.842290865838843
Loss at iteration 50 : 0.6261206865310669
Loss at iteration 100 : 1.0160233974456787
Loss at iteration 150 : 1.008851170539856
Loss at iteration 200 : 1.0818142890930176
Loss at iteration 250 : 1.0451866388320923
Loss at iteration 300 : 0.6316041946411133
Loss at iteration 350 : 0.9080965518951416
Mean training loss eporch  708 :  0.8422205900704419
Loss at iteration 50 : 0.6995189189910889
Loss at iteration 100 : 0.7388070821762085
Loss at iteration 150 : 0.6011157631874084
Loss at iteration 200 : 0.8858078718185425
Loss at iteration 250 : 0.9052612781524658
Loss at iteration 300 : 0.8053483963012695
Loss at iteration 350 : 0.7876710891723633
Mean training loss eporch  709 :  0.8422537010813517
Loss at iteration 50 : 1.30853271484375
Loss at iteration 100 : 0.7434639930725098
Loss at iteration 150 : 0.8990349769592285
Loss at iteration 200 : 0.9772193431854248
Loss at iteration 250 : 0.6330870389938354
Loss at iteration 300 : 0.7021448612213135
Loss at iteration 350 : 0.7569180727005005
Mean training loss eporch  710 :  0.8421019400869098
Loss at iteration 50 : 0.5782628059387207
Loss at iteration 100 : 0.7997807264328003
Loss at iteration 150 : 0.8348241448402405
Loss at iteration 200 : 0.8112357258796692
Loss at iteration 250 : 0.9441320896148682
Loss at iteration 300 : 0.8993045091629028
Loss at iteration 350 : 0.6412914991378784
Mean training loss eporch  711 :  0.842746247847875
Loss at iteration 50 : 0.492073655128479
Loss at iteration 100 : 0.8444985151290894
Loss at iteration 150 : 0.5739742517471313
Loss at iteration 200 : 0.8312587738037109
Loss at iteration 250 : 0.6799346804618835
Loss at iteration 300 : 0.8306719660758972
Loss at iteration 350 : 1.004390001296997
Mean training loss eporch  712 :  0.841637591993998
Loss at iteration 50 : 0.6673496961593628
Loss at iteration 100 : 0.5209367275238037
Loss at iteration 150 : 0.8970237374305725
Loss at iteration 200 : 0.9445493817329407
Loss at iteration 250 : 0.9276826977729797
Loss at iteration 300 : 0.8019313216209412
Loss at iteration 350 : 0.849190354347229
Mean training loss eporch  713 :  0.8414839939780967
Loss at iteration 50 : 0.744868278503418
Loss at iteration 100 : 0.8316255807876587
Loss at iteration 150 : 1.0369614362716675
Loss at iteration 200 : 0.9925912618637085
Loss at iteration 250 : 0.825410008430481
Loss at iteration 300 : 0.7032665014266968
Loss at iteration 350 : 0.9159970283508301
Mean training loss eporch  714 :  0.8415867759594842
Loss at iteration 50 : 1.2093369960784912
Loss at iteration 100 : 0.8845506310462952
Loss at iteration 150 : 0.7556284666061401
Loss at iteration 200 : 0.9922052621841431
Loss at iteration 250 : 0.6554765105247498
Loss at iteration 300 : 1.1023638248443604
Loss at iteration 350 : 0.9818126559257507
Mean training loss eporch  715 :  0.84256992098831
Loss at iteration 50 : 0.6946990489959717
Loss at iteration 100 : 0.7280351519584656
Loss at iteration 150 : 1.0151433944702148
Loss at iteration 200 : 0.7040554881095886
Loss at iteration 250 : 0.6357903480529785
Loss at iteration 300 : 0.6016948819160461
Loss at iteration 350 : 0.5801463723182678
Mean training loss eporch  716 :  0.8431869330544951
Loss at iteration 50 : 0.59209805727005
Loss at iteration 100 : 1.1276721954345703
Loss at iteration 150 : 0.6818206310272217
Loss at iteration 200 : 0.9507410526275635
Loss at iteration 250 : 0.9692788124084473
Loss at iteration 300 : 0.8722972273826599
Loss at iteration 350 : 0.6324238777160645
Mean training loss eporch  717 :  0.8420279290941026
Loss at iteration 50 : 0.754716157913208
Loss at iteration 100 : 0.7239581346511841
Loss at iteration 150 : 0.8638962507247925
Loss at iteration 200 : 0.7711127996444702
Loss at iteration 250 : 0.7089059948921204
Loss at iteration 300 : 0.5334734916687012
Loss at iteration 350 : 0.8951786756515503
Mean training loss eporch  718 :  0.8422266518470471
Loss at iteration 50 : 0.682160496711731
Loss at iteration 100 : 0.5772310495376587
Loss at iteration 150 : 0.6781429648399353
Loss at iteration 200 : 0.8496099710464478
Loss at iteration 250 : 1.034325122833252
Loss at iteration 300 : 0.7116056084632874
Loss at iteration 350 : 0.7146161794662476
Mean training loss eporch  719 :  0.8425318385873523
Loss at iteration 50 : 0.7207363843917847
Loss at iteration 100 : 1.1646314859390259
Loss at iteration 150 : 0.5745962858200073
Loss at iteration 200 : 0.7508493065834045
Loss at iteration 250 : 0.7868843674659729
Loss at iteration 300 : 1.0417885780334473
Loss at iteration 350 : 0.568821370601654
Mean training loss eporch  720 :  0.8418022887731986
Loss at iteration 50 : 0.6927668452262878
Loss at iteration 100 : 0.8341725468635559
Loss at iteration 150 : 0.7474532723426819
Loss at iteration 200 : 0.9265146851539612
Loss at iteration 250 : 0.6720763444900513
Loss at iteration 300 : 0.8864110708236694
Loss at iteration 350 : 1.0346473455429077
Mean training loss eporch  721 :  0.8421924039327279
Loss at iteration 50 : 0.8424569368362427
Loss at iteration 100 : 0.9730556011199951
Loss at iteration 150 : 0.9235861301422119
Loss at iteration 200 : 0.7483300566673279
Loss at iteration 250 : 0.6628844738006592
Loss at iteration 300 : 0.8908808827400208
Loss at iteration 350 : 0.8674407005310059
Mean training loss eporch  722 :  0.8422639764175213
Loss at iteration 50 : 0.869877815246582
Loss at iteration 100 : 1.0205222368240356
Loss at iteration 150 : 0.6970585584640503
Loss at iteration 200 : 0.5984169840812683
Loss at iteration 250 : 1.0257837772369385
Loss at iteration 300 : 0.7548880577087402
Loss at iteration 350 : 0.8436015844345093
Mean training loss eporch  723 :  0.842602661520085
Loss at iteration 50 : 0.9814162254333496
Loss at iteration 100 : 0.6015873551368713
Loss at iteration 150 : 0.5452827215194702
Loss at iteration 200 : 0.6981885433197021
Loss at iteration 250 : 0.8594339489936829
Loss at iteration 300 : 0.8013708591461182
Loss at iteration 350 : 0.8119040131568909
Mean training loss eporch  724 :  0.8425967764286768
Loss at iteration 50 : 0.6469038128852844
Loss at iteration 100 : 0.9745877981185913
Loss at iteration 150 : 0.9243407249450684
Loss at iteration 200 : 0.8922041058540344
Loss at iteration 250 : 0.6623136401176453
Loss at iteration 300 : 0.9787338972091675
Loss at iteration 350 : 0.5851554274559021
Mean training loss eporch  725 :  0.8424179869354087
Loss at iteration 50 : 1.2433948516845703
Loss at iteration 100 : 0.7679186463356018
Loss at iteration 150 : 0.6796554923057556
Loss at iteration 200 : 0.8941305875778198
Loss at iteration 250 : 0.9759277701377869
Loss at iteration 300 : 0.9936288595199585
Loss at iteration 350 : 0.868804931640625
Mean training loss eporch  726 :  0.8420356158068572
Loss at iteration 50 : 0.6660120487213135
Loss at iteration 100 : 0.6569041013717651
Loss at iteration 150 : 0.7027826309204102
Loss at iteration 200 : 0.6258980631828308
Loss at iteration 250 : 0.9218961000442505
Loss at iteration 300 : 0.6584908962249756
Loss at iteration 350 : 0.9664083123207092
Mean training loss eporch  727 :  0.8419008418996498
Loss at iteration 50 : 0.9907240271568298
Loss at iteration 100 : 0.5506150126457214
Loss at iteration 150 : 0.6812322735786438
Loss at iteration 200 : 1.0258007049560547
Loss at iteration 250 : 0.8132778406143188
Loss at iteration 300 : 0.6072225570678711
Loss at iteration 350 : 0.8685281872749329
Mean training loss eporch  728 :  0.8420831516148553
Loss at iteration 50 : 0.6097723245620728
Loss at iteration 100 : 0.7835314273834229
Loss at iteration 150 : 0.6436260938644409
Loss at iteration 200 : 1.019565463066101
Loss at iteration 250 : 1.144029974937439
Loss at iteration 300 : 0.7957777976989746
Loss at iteration 350 : 0.7839277386665344
Mean training loss eporch  729 :  0.8425301961482518
Loss at iteration 50 : 0.9957845211029053
Loss at iteration 100 : 1.0548748970031738
Loss at iteration 150 : 0.6768261790275574
Loss at iteration 200 : 0.6846817135810852
Loss at iteration 250 : 1.086087703704834
Loss at iteration 300 : 0.9117389917373657
Loss at iteration 350 : 0.8552063703536987
Mean training loss eporch  730 :  0.8415976173032529
Loss at iteration 50 : 0.5278112292289734
Loss at iteration 100 : 0.5580446720123291
Loss at iteration 150 : 0.718285322189331
Loss at iteration 200 : 0.7099728584289551
Loss at iteration 250 : 0.7685930728912354
Loss at iteration 300 : 0.8668603897094727
Loss at iteration 350 : 0.8412616848945618
Mean training loss eporch  731 :  0.8416146157437532
Loss at iteration 50 : 0.6295552253723145
Loss at iteration 100 : 0.6137696504592896
Loss at iteration 150 : 0.8722009062767029
Loss at iteration 200 : 0.8829877376556396
Loss at iteration 250 : 0.9184763431549072
Loss at iteration 300 : 0.7145013213157654
Loss at iteration 350 : 0.8785429000854492
Mean training loss eporch  732 :  0.8415486623370458
Loss at iteration 50 : 0.47372305393218994
Loss at iteration 100 : 1.1278936862945557
Loss at iteration 150 : 0.7943220138549805
Loss at iteration 200 : 0.7715862989425659
Loss at iteration 250 : 0.801003098487854
Loss at iteration 300 : 0.6938205361366272
Loss at iteration 350 : 0.9511860609054565
Mean training loss eporch  733 :  0.8420084997144326
Loss at iteration 50 : 1.4627641439437866
Loss at iteration 100 : 0.7021437287330627
Loss at iteration 150 : 1.0485239028930664
Loss at iteration 200 : 0.8117856979370117
Loss at iteration 250 : 0.6554678678512573
Loss at iteration 300 : 0.9781465530395508
Loss at iteration 350 : 0.8627725839614868
Mean training loss eporch  734 :  0.8420214008086573
Loss at iteration 50 : 1.2006216049194336
Loss at iteration 100 : 0.7289900183677673
Loss at iteration 150 : 0.7621632814407349
Loss at iteration 200 : 0.7084046006202698
Loss at iteration 250 : 0.5878145694732666
Loss at iteration 300 : 0.668580174446106
Loss at iteration 350 : 1.1733894348144531
Mean training loss eporch  735 :  0.8424231790045582
Loss at iteration 50 : 0.7003844976425171
Loss at iteration 100 : 0.8825066685676575
Loss at iteration 150 : 0.8760280609130859
Loss at iteration 200 : 1.0303406715393066
Loss at iteration 250 : 0.7203670144081116
Loss at iteration 300 : 0.6638677716255188
Loss at iteration 350 : 0.857316255569458
Mean training loss eporch  736 :  0.8422022944404965
Loss at iteration 50 : 0.7835862040519714
Loss at iteration 100 : 0.6165090799331665
Loss at iteration 150 : 0.8796650171279907
Loss at iteration 200 : 1.2255640029907227
Loss at iteration 250 : 0.8137302398681641
Loss at iteration 300 : 0.7835702896118164
Loss at iteration 350 : 0.679597020149231
Mean training loss eporch  737 :  0.8419774575996651
Loss at iteration 50 : 0.8460773825645447
Loss at iteration 100 : 0.861009955406189
Loss at iteration 150 : 0.8110251426696777
Loss at iteration 200 : 0.6931403875350952
Loss at iteration 250 : 0.8372119665145874
Loss at iteration 300 : 0.6656542420387268
Loss at iteration 350 : 0.5729881525039673
Mean training loss eporch  738 :  0.8423036991288422
Loss at iteration 50 : 0.6912409067153931
Loss at iteration 100 : 0.9342134594917297
Loss at iteration 150 : 0.6871944069862366
Loss at iteration 200 : 0.9428722858428955
Loss at iteration 250 : 0.7196024656295776
Loss at iteration 300 : 1.1327518224716187
Loss at iteration 350 : 0.9831476211547852
Mean training loss eporch  739 :  0.8414909849879603
Loss at iteration 50 : 0.732363224029541
Loss at iteration 100 : 0.68300461769104
Loss at iteration 150 : 0.8835129737854004
Loss at iteration 200 : 0.888685941696167
Loss at iteration 250 : 0.9120657444000244
Loss at iteration 300 : 0.6233065128326416
Loss at iteration 350 : 0.45305174589157104
Mean training loss eporch  740 :  0.8419079346946938
Loss at iteration 50 : 0.9392011165618896
Loss at iteration 100 : 0.9565901756286621
Loss at iteration 150 : 0.87321937084198
Loss at iteration 200 : 1.036628007888794
Loss at iteration 250 : 0.9963252544403076
Loss at iteration 300 : 0.7585880160331726
Loss at iteration 350 : 1.05519437789917
Mean training loss eporch  741 :  0.8418529290686209
Loss at iteration 50 : 0.8708560466766357
Loss at iteration 100 : 0.8101226091384888
Loss at iteration 150 : 0.8267050981521606
Loss at iteration 200 : 0.6512853503227234
Loss at iteration 250 : 0.592418909072876
Loss at iteration 300 : 0.8004104495048523
Loss at iteration 350 : 1.0870730876922607
Mean training loss eporch  742 :  0.8421277963610553
Loss at iteration 50 : 0.7944479584693909
Loss at iteration 100 : 0.6616914868354797
Loss at iteration 150 : 0.9729589223861694
Loss at iteration 200 : 1.0211641788482666
Loss at iteration 250 : 0.8029240369796753
Loss at iteration 300 : 0.723137617111206
Loss at iteration 350 : 0.6651934385299683
Mean training loss eporch  743 :  0.8415676595830412
Loss at iteration 50 : 0.9504664540290833
Loss at iteration 100 : 1.0042507648468018
Loss at iteration 150 : 0.8849612474441528
Loss at iteration 200 : 1.4055495262145996
Loss at iteration 250 : 0.7629888653755188
Loss at iteration 300 : 0.5867494344711304
Loss at iteration 350 : 0.6388860940933228
Mean training loss eporch  744 :  0.8422954750281794
Loss at iteration 50 : 0.5929737091064453
Loss at iteration 100 : 0.7523465156555176
Loss at iteration 150 : 1.1395118236541748
Loss at iteration 200 : 1.1064379215240479
Loss at iteration 250 : 0.6689429879188538
Loss at iteration 300 : 1.181333303451538
Loss at iteration 350 : 0.9158278703689575
Mean training loss eporch  745 :  0.8421161217348916
Loss at iteration 50 : 0.9783482551574707
Loss at iteration 100 : 0.7992515563964844
Loss at iteration 150 : 1.2123098373413086
Loss at iteration 200 : 0.876198410987854
Loss at iteration 250 : 0.9849053621292114
Loss at iteration 300 : 0.9201598763465881
Loss at iteration 350 : 0.9030994176864624
Mean training loss eporch  746 :  0.8422017825974358
Loss at iteration 50 : 0.7781932353973389
Loss at iteration 100 : 0.8421064019203186
Loss at iteration 150 : 0.7607731223106384
Loss at iteration 200 : 0.7008262872695923
Loss at iteration 250 : 0.6567027568817139
Loss at iteration 300 : 0.9389688372612
Loss at iteration 350 : 0.6203430891036987
Mean training loss eporch  747 :  0.8424533186135469
Loss at iteration 50 : 0.5106222629547119
Loss at iteration 100 : 1.0034542083740234
Loss at iteration 150 : 0.7181702852249146
Loss at iteration 200 : 0.8239360451698303
Loss at iteration 250 : 0.6753568649291992
Loss at iteration 300 : 0.7852031588554382
Loss at iteration 350 : 0.6534315347671509
Mean training loss eporch  748 :  0.8417246535656944
Loss at iteration 50 : 0.6541102528572083
Loss at iteration 100 : 0.8340988159179688
Loss at iteration 150 : 0.8275961875915527
Loss at iteration 200 : 0.7392008304595947
Loss at iteration 250 : 0.8907462954521179
Loss at iteration 300 : 0.7152158617973328
Loss at iteration 350 : 0.8099938631057739
Mean training loss eporch  749 :  0.8430128377423716
Loss at iteration 50 : 0.8983473181724548
Loss at iteration 100 : 1.1176049709320068
Loss at iteration 150 : 0.8878969550132751
Loss at iteration 200 : 0.8379354476928711
Loss at iteration 250 : 0.7790616750717163
Loss at iteration 300 : 0.8521029949188232
Loss at iteration 350 : 0.5540130138397217
Mean training loss eporch  750 :  0.8422897290142756
Loss at iteration 50 : 1.1016117334365845
Loss at iteration 100 : 0.8828604221343994
Loss at iteration 150 : 0.9095311164855957
Loss at iteration 200 : 1.3219842910766602
Loss at iteration 250 : 0.7005243301391602
Loss at iteration 300 : 0.7138873338699341
Loss at iteration 350 : 0.8061645030975342
Mean training loss eporch  751 :  0.8414644186616574
Loss at iteration 50 : 0.8262740969657898
Loss at iteration 100 : 0.7184661626815796
Loss at iteration 150 : 0.937675952911377
Loss at iteration 200 : 0.7849090099334717
Loss at iteration 250 : 0.7748981714248657
Loss at iteration 300 : 0.6886229515075684
Loss at iteration 350 : 0.6492396593093872
Mean training loss eporch  752 :  0.8417996362088218
Loss at iteration 50 : 1.1195000410079956
Loss at iteration 100 : 0.7026401162147522
Loss at iteration 150 : 1.0597261190414429
Loss at iteration 200 : 0.8506481647491455
Loss at iteration 250 : 0.9909644722938538
Loss at iteration 300 : 1.0912147760391235
Loss at iteration 350 : 0.7752571105957031
Mean training loss eporch  753 :  0.8423433046807688
Loss at iteration 50 : 0.7658524513244629
Loss at iteration 100 : 0.9042949676513672
Loss at iteration 150 : 0.8147366642951965
Loss at iteration 200 : 0.7846420407295227
Loss at iteration 250 : 0.7383570671081543
Loss at iteration 300 : 0.7377205491065979
Loss at iteration 350 : 0.7021220922470093
Mean training loss eporch  754 :  0.8413507659283895
Loss at iteration 50 : 0.9265540838241577
Loss at iteration 100 : 0.981185793876648
Loss at iteration 150 : 0.6453592777252197
Loss at iteration 200 : 0.7356772422790527
Loss at iteration 250 : 1.1287437677383423
Loss at iteration 300 : 0.7629281878471375
Loss at iteration 350 : 0.8011749982833862
Mean training loss eporch  755 :  0.8413458826049925
Loss at iteration 50 : 0.7952654957771301
Loss at iteration 100 : 1.170788049697876
Loss at iteration 150 : 0.7178311944007874
Loss at iteration 200 : 0.8685302138328552
Loss at iteration 250 : 0.9567520022392273
Loss at iteration 300 : 0.8645553588867188
Loss at iteration 350 : 0.7004122734069824
Mean training loss eporch  756 :  0.8420003943500065
Loss at iteration 50 : 0.6459482908248901
Loss at iteration 100 : 1.1889989376068115
Loss at iteration 150 : 0.7865486145019531
Loss at iteration 200 : 1.041602373123169
Loss at iteration 250 : 0.8008238673210144
Loss at iteration 300 : 0.8303505182266235
Loss at iteration 350 : 0.41285115480422974
Mean training loss eporch  757 :  0.842161394300915
Loss at iteration 50 : 1.3729369640350342
Loss at iteration 100 : 0.6235363483428955
Loss at iteration 150 : 1.1092661619186401
Loss at iteration 200 : 0.9233514070510864
Loss at iteration 250 : 0.788336455821991
Loss at iteration 300 : 1.0411937236785889
Loss at iteration 350 : 0.7880944013595581
Mean training loss eporch  758 :  0.8422924828119379
Loss at iteration 50 : 0.6904408931732178
Loss at iteration 100 : 0.8067368268966675
Loss at iteration 150 : 0.7501435875892639
Loss at iteration 200 : 1.0771217346191406
Loss at iteration 250 : 0.9770344495773315
Loss at iteration 300 : 0.6559090614318848
Loss at iteration 350 : 1.277116298675537
Mean training loss eporch  759 :  0.842202925650531
Loss at iteration 50 : 0.5666341781616211
Loss at iteration 100 : 0.7112380266189575
Loss at iteration 150 : 0.7948194742202759
Loss at iteration 200 : 0.7562562227249146
Loss at iteration 250 : 0.9200760126113892
Loss at iteration 300 : 0.7831549644470215
Loss at iteration 350 : 0.6037166118621826
Mean training loss eporch  760 :  0.8418423621742813
Loss at iteration 50 : 0.6603599786758423
Loss at iteration 100 : 0.6814860105514526
Loss at iteration 150 : 0.8047068119049072
Loss at iteration 200 : 0.7659476399421692
Loss at iteration 250 : 1.2138545513153076
Loss at iteration 300 : 0.8264975547790527
Loss at iteration 350 : 0.8425555229187012
Mean training loss eporch  761 :  0.8416403691289286
Loss at iteration 50 : 0.8262457847595215
Loss at iteration 100 : 0.9399765729904175
Loss at iteration 150 : 0.823879063129425
Loss at iteration 200 : 0.673760175704956
Loss at iteration 250 : 0.8876007795333862
Loss at iteration 300 : 0.8800305128097534
Loss at iteration 350 : 0.7795438766479492
Mean training loss eporch  762 :  0.8416937674794879
Loss at iteration 50 : 0.7406653165817261
Loss at iteration 100 : 0.8178216218948364
Loss at iteration 150 : 1.1627395153045654
Loss at iteration 200 : 0.7837332487106323
Loss at iteration 250 : 0.7607468962669373
Loss at iteration 300 : 0.9383598566055298
Loss at iteration 350 : 0.8448463082313538
Mean training loss eporch  763 :  0.8414378683403055
Loss at iteration 50 : 0.7513167262077332
Loss at iteration 100 : 0.8799983263015747
Loss at iteration 150 : 0.7460925579071045
Loss at iteration 200 : 0.9207376837730408
Loss at iteration 250 : 0.6029102802276611
Loss at iteration 300 : 0.8882967233657837
Loss at iteration 350 : 1.1990139484405518
Mean training loss eporch  764 :  0.8420574370988463
Loss at iteration 50 : 0.8259632587432861
Loss at iteration 100 : 0.5455082654953003
Loss at iteration 150 : 0.8855170607566833
Loss at iteration 200 : 0.8193506598472595
Loss at iteration 250 : 0.6197545528411865
Loss at iteration 300 : 0.9150550365447998
Loss at iteration 350 : 1.0259535312652588
Mean training loss eporch  765 :  0.8416647179416878
Loss at iteration 50 : 0.908536434173584
Loss at iteration 100 : 0.7842919826507568
Loss at iteration 150 : 0.9449162483215332
Loss at iteration 200 : 0.8017480969429016
Loss at iteration 250 : 0.8663671612739563
Loss at iteration 300 : 0.8595540523529053
Loss at iteration 350 : 0.7267897129058838
Mean training loss eporch  766 :  0.8414380783757205
Loss at iteration 50 : 1.0646153688430786
Loss at iteration 100 : 1.245796799659729
Loss at iteration 150 : 0.8564314246177673
Loss at iteration 200 : 0.9782857298851013
Loss at iteration 250 : 0.6845192909240723
Loss at iteration 300 : 0.789849042892456
Loss at iteration 350 : 0.8396192789077759
Mean training loss eporch  767 :  0.841978024238001
Loss at iteration 50 : 0.9961822628974915
Loss at iteration 100 : 0.7493173480033875
Loss at iteration 150 : 0.8742738962173462
Loss at iteration 200 : 0.8732457160949707
Loss at iteration 250 : 1.2378833293914795
Loss at iteration 300 : 0.7825963497161865
Loss at iteration 350 : 0.9583461284637451
Mean training loss eporch  768 :  0.8411661704223623
Loss at iteration 50 : 0.8757880926132202
Loss at iteration 100 : 1.017317771911621
Loss at iteration 150 : 0.582607626914978
Loss at iteration 200 : 0.8198676705360413
Loss at iteration 250 : 0.7532013654708862
Loss at iteration 300 : 0.8698265552520752
Loss at iteration 350 : 0.8674037456512451
Mean training loss eporch  769 :  0.8415532916311234
Loss at iteration 50 : 0.6031031608581543
Loss at iteration 100 : 0.8244266510009766
Loss at iteration 150 : 0.6980379819869995
Loss at iteration 200 : 0.9460386037826538
Loss at iteration 250 : 0.6546279191970825
Loss at iteration 300 : 0.6082167029380798
Loss at iteration 350 : 0.7756986021995544
Mean training loss eporch  770 :  0.8414816024599883
Loss at iteration 50 : 0.8307519555091858
Loss at iteration 100 : 0.8928656578063965
Loss at iteration 150 : 0.8327313661575317
Loss at iteration 200 : 1.062686562538147
Loss at iteration 250 : 0.7231707572937012
Loss at iteration 300 : 0.781012237071991
Loss at iteration 350 : 0.9507001638412476
Mean training loss eporch  771 :  0.8433520100892536
Loss at iteration 50 : 0.8209749460220337
Loss at iteration 100 : 0.8524776697158813
Loss at iteration 150 : 0.7763071060180664
Loss at iteration 200 : 0.6908080577850342
Loss at iteration 250 : 0.781575083732605
Loss at iteration 300 : 0.9372186064720154
Loss at iteration 350 : 1.0352814197540283
Mean training loss eporch  772 :  0.8425991713369965
Loss at iteration 50 : 0.735753059387207
Loss at iteration 100 : 1.0467092990875244
Loss at iteration 150 : 0.6285918951034546
Loss at iteration 200 : 0.6357674598693848
Loss at iteration 250 : 0.7018394470214844
Loss at iteration 300 : 0.7239580154418945
Loss at iteration 350 : 0.6926926374435425
Mean training loss eporch  773 :  0.8415491454815739
Loss at iteration 50 : 0.7590495944023132
Loss at iteration 100 : 0.8859161734580994
Loss at iteration 150 : 1.1620447635650635
Loss at iteration 200 : 0.961363673210144
Loss at iteration 250 : 0.949011504650116
Loss at iteration 300 : 0.888978898525238
Loss at iteration 350 : 0.793810248374939
Mean training loss eporch  774 :  0.8413171072012533
Loss at iteration 50 : 1.326522707939148
Loss at iteration 100 : 0.6613132953643799
Loss at iteration 150 : 0.6870797872543335
Loss at iteration 200 : 0.8979533910751343
Loss at iteration 250 : 0.9620517492294312
Loss at iteration 300 : 0.6596246957778931
Loss at iteration 350 : 1.193279504776001
Mean training loss eporch  775 :  0.841125685544241
Loss at iteration 50 : 1.1122052669525146
Loss at iteration 100 : 0.6658254861831665
Loss at iteration 150 : 0.8958768844604492
Loss at iteration 200 : 0.6748939752578735
Loss at iteration 250 : 1.0369040966033936
Loss at iteration 300 : 0.9514977931976318
Loss at iteration 350 : 1.2857258319854736
Mean training loss eporch  776 :  0.8422075303458663
Loss at iteration 50 : 0.5305941104888916
Loss at iteration 100 : 0.8851170539855957
Loss at iteration 150 : 0.5930294990539551
Loss at iteration 200 : 0.6363041400909424
Loss at iteration 250 : 0.9221614003181458
Loss at iteration 300 : 0.772182047367096
Loss at iteration 350 : 0.6881009340286255
Mean training loss eporch  777 :  0.8416823695103327
Loss at iteration 50 : 0.696020781993866
Loss at iteration 100 : 1.1217867136001587
Loss at iteration 150 : 0.8439694046974182
Loss at iteration 200 : 0.5908737778663635
Loss at iteration 250 : 1.3221156597137451
Loss at iteration 300 : 0.5883756875991821
Loss at iteration 350 : 0.7045506238937378
Mean training loss eporch  778 :  0.8417139853592273
Loss at iteration 50 : 0.7870582342147827
Loss at iteration 100 : 1.3268202543258667
Loss at iteration 150 : 0.973343014717102
Loss at iteration 200 : 0.6174829006195068
Loss at iteration 250 : 0.9025110006332397
Loss at iteration 300 : 0.7055093050003052
Loss at iteration 350 : 0.6104535460472107
Mean training loss eporch  779 :  0.8422160323650117
Loss at iteration 50 : 0.9721609354019165
Loss at iteration 100 : 0.7342426776885986
Loss at iteration 150 : 0.7752685546875
Loss at iteration 200 : 1.1307865381240845
Loss at iteration 250 : 0.7143065929412842
Loss at iteration 300 : 0.9770871996879578
Loss at iteration 350 : 0.8675895929336548
Mean training loss eporch  780 :  0.841546970858145
Loss at iteration 50 : 0.929237961769104
Loss at iteration 100 : 0.7368807792663574
Loss at iteration 150 : 0.7875990271568298
Loss at iteration 200 : 0.6917545795440674
Loss at iteration 250 : 0.6188101768493652
Loss at iteration 300 : 0.5647814273834229
Loss at iteration 350 : 0.9655020236968994
Mean training loss eporch  781 :  0.8414455105861028
Loss at iteration 50 : 1.1505579948425293
Loss at iteration 100 : 0.7188433408737183
Loss at iteration 150 : 0.749390721321106
Loss at iteration 200 : 0.5598864555358887
Loss at iteration 250 : 0.6125526428222656
Loss at iteration 300 : 0.8048780560493469
Loss at iteration 350 : 0.6643733978271484
Mean training loss eporch  782 :  0.841823623924659
Loss at iteration 50 : 0.8094198107719421
Loss at iteration 100 : 0.9662787914276123
Loss at iteration 150 : 0.9231780767440796
Loss at iteration 200 : 1.0010654926300049
Loss at iteration 250 : 0.6165947914123535
Loss at iteration 300 : 0.8235774040222168
Loss at iteration 350 : 0.7009916305541992
Mean training loss eporch  783 :  0.8422574400113373
Loss at iteration 50 : 0.8582372665405273
Loss at iteration 100 : 0.8667476177215576
Loss at iteration 150 : 0.9828590154647827
Loss at iteration 200 : 0.8890340328216553
Loss at iteration 250 : 0.74277663230896
Loss at iteration 300 : 0.7504614591598511
Loss at iteration 350 : 0.8857015371322632
Mean training loss eporch  784 :  0.8421585360374401
Loss at iteration 50 : 1.0050456523895264
Loss at iteration 100 : 0.5608100891113281
Loss at iteration 150 : 0.9865217208862305
Loss at iteration 200 : 0.8059467673301697
Loss at iteration 250 : 0.6496973037719727
Loss at iteration 300 : 0.8793508410453796
Loss at iteration 350 : 0.857641339302063
Mean training loss eporch  785 :  0.84248118678098
Loss at iteration 50 : 0.8946846723556519
Loss at iteration 100 : 0.9319217205047607
Loss at iteration 150 : 0.7025661468505859
Loss at iteration 200 : 0.7583519220352173
Loss at iteration 250 : 0.7334622144699097
Loss at iteration 300 : 0.9083555936813354
Loss at iteration 350 : 0.6927052736282349
Mean training loss eporch  786 :  0.8424148007675454
Loss at iteration 50 : 0.7223964929580688
Loss at iteration 100 : 0.8399087190628052
Loss at iteration 150 : 0.797066867351532
Loss at iteration 200 : 0.9651740789413452
Loss at iteration 250 : 0.6838376522064209
Loss at iteration 300 : 0.9388625621795654
Loss at iteration 350 : 0.9194830656051636
Mean training loss eporch  787 :  0.8423886879411324
Loss at iteration 50 : 1.1091866493225098
Loss at iteration 100 : 0.619364857673645
Loss at iteration 150 : 0.6944772005081177
Loss at iteration 200 : 0.8862742185592651
Loss at iteration 250 : 0.8060352206230164
Loss at iteration 300 : 1.3978248834609985
Loss at iteration 350 : 0.8318280577659607
Mean training loss eporch  788 :  0.8416431802448141
Loss at iteration 50 : 1.0933706760406494
Loss at iteration 100 : 1.1057405471801758
Loss at iteration 150 : 0.9146596193313599
Loss at iteration 200 : 0.8740224838256836
Loss at iteration 250 : 0.6698967218399048
Loss at iteration 300 : 0.921249270439148
Loss at iteration 350 : 0.8862544894218445
Mean training loss eporch  789 :  0.8414703061971714
Loss at iteration 50 : 0.9889835119247437
Loss at iteration 100 : 1.032386064529419
Loss at iteration 150 : 0.946524977684021
Loss at iteration 200 : 1.0664485692977905
Loss at iteration 250 : 0.800965428352356
Loss at iteration 300 : 0.7405451536178589
Loss at iteration 350 : 0.8129557371139526
Mean training loss eporch  790 :  0.8415328144396423
Loss at iteration 50 : 0.7948012351989746
Loss at iteration 100 : 1.119164228439331
Loss at iteration 150 : 0.8938262462615967
Loss at iteration 200 : 0.7531035542488098
Loss at iteration 250 : 0.6963326930999756
Loss at iteration 300 : 0.8829135298728943
Loss at iteration 350 : 0.849257230758667
Mean training loss eporch  791 :  0.8421453354219911
Loss at iteration 50 : 0.8570675849914551
Loss at iteration 100 : 0.7496063709259033
Loss at iteration 150 : 0.8281081914901733
Loss at iteration 200 : 0.6327379941940308
Loss at iteration 250 : 0.8854637145996094
Loss at iteration 300 : 0.8122981190681458
Loss at iteration 350 : 0.6096582412719727
Mean training loss eporch  792 :  0.8423425961266119
Loss at iteration 50 : 0.8897542953491211
Loss at iteration 100 : 0.6316441893577576
Loss at iteration 150 : 0.970700740814209
Loss at iteration 200 : 1.000533103942871
Loss at iteration 250 : 0.8234246969223022
Loss at iteration 300 : 0.7566429972648621
Loss at iteration 350 : 1.0939717292785645
Mean training loss eporch  793 :  0.8422220244451806
Loss at iteration 50 : 0.48935872316360474
Loss at iteration 100 : 0.7045938968658447
Loss at iteration 150 : 0.8434414863586426
Loss at iteration 200 : 1.2686293125152588
Loss at iteration 250 : 0.7363160848617554
Loss at iteration 300 : 0.8815538287162781
Loss at iteration 350 : 1.0160837173461914
Mean training loss eporch  794 :  0.8419911938684957
Loss at iteration 50 : 1.4453684091567993
Loss at iteration 100 : 0.6457833051681519
Loss at iteration 150 : 0.9828184843063354
Loss at iteration 200 : 0.9643144607543945
Loss at iteration 250 : 0.9437201023101807
Loss at iteration 300 : 0.968950629234314
Loss at iteration 350 : 1.0685603618621826
Mean training loss eporch  795 :  0.8417706554213529
Loss at iteration 50 : 0.9839843511581421
Loss at iteration 100 : 0.8714909553527832
Loss at iteration 150 : 0.6274806261062622
Loss at iteration 200 : 0.9692623615264893
Loss at iteration 250 : 0.7626340389251709
Loss at iteration 300 : 0.6723799109458923
Loss at iteration 350 : 0.7926381826400757
Mean training loss eporch  796 :  0.8428336320415376
Loss at iteration 50 : 0.6590366959571838
Loss at iteration 100 : 0.7762423753738403
Loss at iteration 150 : 1.409538984298706
Loss at iteration 200 : 0.9202874898910522
Loss at iteration 250 : 0.7475852966308594
Loss at iteration 300 : 0.7913179993629456
Loss at iteration 350 : 0.9210261106491089
Mean training loss eporch  797 :  0.8419143335213737
Loss at iteration 50 : 0.9485817551612854
Loss at iteration 100 : 0.7871506214141846
Loss at iteration 150 : 0.9751358032226562
Loss at iteration 200 : 0.7715018391609192
Loss at iteration 250 : 0.8183566331863403
Loss at iteration 300 : 1.3888723850250244
Loss at iteration 350 : 0.8594216108322144
Mean training loss eporch  798 :  0.84153241581387
Loss at iteration 50 : 0.7493324279785156
Loss at iteration 100 : 0.6576597690582275
Loss at iteration 150 : 0.6214436292648315
Loss at iteration 200 : 0.761428952217102
Loss at iteration 250 : 1.0756926536560059
Loss at iteration 300 : 0.8755627870559692
Loss at iteration 350 : 1.0901741981506348
Mean training loss eporch  799 :  0.8412472870614793
Loss at iteration 50 : 0.883228063583374
Loss at iteration 100 : 0.7401533126831055
Loss at iteration 150 : 0.9469718933105469
Loss at iteration 200 : 0.8434913754463196
Loss at iteration 250 : 0.653630793094635
Loss at iteration 300 : 0.9188585877418518
Loss at iteration 350 : 0.6102983355522156
Mean training loss eporch  800 :  0.8423728294788845
Loss at iteration 50 : 0.8685648441314697
Loss at iteration 100 : 0.9153139591217041
Loss at iteration 150 : 1.1125186681747437
Loss at iteration 200 : 1.1868805885314941
Loss at iteration 250 : 0.7962415814399719
Loss at iteration 300 : 0.9866359829902649
Loss at iteration 350 : 0.7946174740791321
Mean training loss eporch  801 :  0.8421956109937536
Loss at iteration 50 : 0.7598556280136108
Loss at iteration 100 : 0.6810834407806396
Loss at iteration 150 : 1.0321340560913086
Loss at iteration 200 : 0.771568238735199
Loss at iteration 250 : 0.8898075819015503
Loss at iteration 300 : 1.0266317129135132
Loss at iteration 350 : 0.5916900634765625
Mean training loss eporch  802 :  0.8414292090311253
Loss at iteration 50 : 0.818724513053894
Loss at iteration 100 : 1.2311906814575195
Loss at iteration 150 : 1.3807485103607178
Loss at iteration 200 : 1.2165560722351074
Loss at iteration 250 : 0.7153798341751099
Loss at iteration 300 : 0.7207283973693848
Loss at iteration 350 : 0.8306663036346436
Mean training loss eporch  803 :  0.8421714545557739
Loss at iteration 50 : 0.7767948508262634
Loss at iteration 100 : 0.6846006512641907
Loss at iteration 150 : 1.0627073049545288
Loss at iteration 200 : 0.8570244312286377
Loss at iteration 250 : 0.8457895517349243
Loss at iteration 300 : 0.7432676553726196
Loss at iteration 350 : 1.085111141204834
Mean training loss eporch  804 :  0.8420598555021185
Loss at iteration 50 : 0.7191876769065857
Loss at iteration 100 : 1.015092134475708
Loss at iteration 150 : 0.7125751972198486
Loss at iteration 200 : 1.0990684032440186
Loss at iteration 250 : 1.094325065612793
Loss at iteration 300 : 0.6746596097946167
Loss at iteration 350 : 0.5413181185722351
Mean training loss eporch  805 :  0.8412978682253096
Loss at iteration 50 : 1.0810245275497437
Loss at iteration 100 : 0.7082479000091553
Loss at iteration 150 : 0.6590675711631775
Loss at iteration 200 : 0.7548520565032959
Loss at iteration 250 : 0.7359569668769836
Loss at iteration 300 : 1.1291331052780151
Loss at iteration 350 : 0.8247897624969482
Mean training loss eporch  806 :  0.8432124775868876
Loss at iteration 50 : 0.9960377812385559
Loss at iteration 100 : 1.149158239364624
Loss at iteration 150 : 0.9226778149604797
Loss at iteration 200 : 0.8518659472465515
Loss at iteration 250 : 0.7870219945907593
Loss at iteration 300 : 1.0834887027740479
Loss at iteration 350 : 1.1202192306518555
Mean training loss eporch  807 :  0.8423652989523751
Loss at iteration 50 : 0.8324394822120667
Loss at iteration 100 : 0.7489582300186157
Loss at iteration 150 : 0.7446870803833008
Loss at iteration 200 : 0.7604365348815918
Loss at iteration 250 : 1.002500295639038
Loss at iteration 300 : 0.8150032162666321
Loss at iteration 350 : 0.9049559831619263
Mean training loss eporch  808 :  0.8415872042298947
Loss at iteration 50 : 0.8708664178848267
Loss at iteration 100 : 0.7803634405136108
Loss at iteration 150 : 0.7370998859405518
Loss at iteration 200 : 0.9195621013641357
Loss at iteration 250 : 0.6532977819442749
Loss at iteration 300 : 0.7776514291763306
Loss at iteration 350 : 0.9369769096374512
Mean training loss eporch  809 :  0.8421637394598552
Loss at iteration 50 : 0.7007615566253662
Loss at iteration 100 : 0.5531144142150879
Loss at iteration 150 : 1.062257170677185
Loss at iteration 200 : 0.662990152835846
Loss at iteration 250 : 0.5463503003120422
Loss at iteration 300 : 1.1409053802490234
Loss at iteration 350 : 0.8414360880851746
Mean training loss eporch  810 :  0.841294549523838
Loss at iteration 50 : 1.3830615282058716
Loss at iteration 100 : 0.8161513209342957
Loss at iteration 150 : 0.5513944625854492
Loss at iteration 200 : 0.6953563690185547
Loss at iteration 250 : 1.1429495811462402
Loss at iteration 300 : 0.9959328770637512
Loss at iteration 350 : 0.8343195915222168
Mean training loss eporch  811 :  0.8414428782841515
Loss at iteration 50 : 0.7032443284988403
Loss at iteration 100 : 0.6398868560791016
Loss at iteration 150 : 0.9755659103393555
Loss at iteration 200 : 0.629831075668335
Loss at iteration 250 : 1.2548049688339233
Loss at iteration 300 : 0.8924911022186279
Loss at iteration 350 : 0.6882228851318359
Mean training loss eporch  812 :  0.8415491189117785
Loss at iteration 50 : 0.7905178070068359
Loss at iteration 100 : 0.9663493633270264
Loss at iteration 150 : 0.8647245168685913
Loss at iteration 200 : 0.7770854234695435
Loss at iteration 250 : 0.8223073482513428
Loss at iteration 300 : 1.1300406455993652
Loss at iteration 350 : 1.0908541679382324
Mean training loss eporch  813 :  0.8425839388023608
Loss at iteration 50 : 1.0629197359085083
Loss at iteration 100 : 1.2169526815414429
Loss at iteration 150 : 0.8149130344390869
Loss at iteration 200 : 0.7411110997200012
Loss at iteration 250 : 0.9716174602508545
Loss at iteration 300 : 1.0943434238433838
Loss at iteration 350 : 0.8962847590446472
Mean training loss eporch  814 :  0.8419364369104779
Loss at iteration 50 : 0.8554894924163818
Loss at iteration 100 : 0.9887558221817017
Loss at iteration 150 : 1.2324835062026978
Loss at iteration 200 : 0.5674797296524048
Loss at iteration 250 : 0.9025654196739197
Loss at iteration 300 : 0.9991183876991272
Loss at iteration 350 : 0.8252037763595581
Mean training loss eporch  815 :  0.8418704255548104
Loss at iteration 50 : 0.8433219194412231
Loss at iteration 100 : 0.7906343936920166
Loss at iteration 150 : 0.5142257809638977
Loss at iteration 200 : 0.7017428874969482
Loss at iteration 250 : 0.9845086336135864
Loss at iteration 300 : 0.78287672996521
Loss at iteration 350 : 0.8974040150642395
Mean training loss eporch  816 :  0.8419880315109536
Loss at iteration 50 : 0.6110185384750366
Loss at iteration 100 : 0.8857871294021606
Loss at iteration 150 : 0.8451100587844849
Loss at iteration 200 : 1.1358487606048584
Loss at iteration 250 : 0.9530916213989258
Loss at iteration 300 : 1.0104483366012573
Loss at iteration 350 : 0.8786325454711914
Mean training loss eporch  817 :  0.841757017941702
Loss at iteration 50 : 0.5740227699279785
Loss at iteration 100 : 1.1638271808624268
Loss at iteration 150 : 0.608224630355835
Loss at iteration 200 : 1.011798620223999
Loss at iteration 250 : 1.0471274852752686
Loss at iteration 300 : 0.8889015913009644
Loss at iteration 350 : 0.831277072429657
Mean training loss eporch  818 :  0.8415935977741524
Loss at iteration 50 : 0.7309969663619995
Loss at iteration 100 : 0.9951222538948059
Loss at iteration 150 : 1.2338478565216064
Loss at iteration 200 : 1.1409697532653809
Loss at iteration 250 : 0.7907856702804565
Loss at iteration 300 : 0.740706205368042
Loss at iteration 350 : 0.7286806106567383
Mean training loss eporch  819 :  0.8426789354394983
Loss at iteration 50 : 1.0161755084991455
Loss at iteration 100 : 0.8978586196899414
Loss at iteration 150 : 0.8176790475845337
Loss at iteration 200 : 0.7210367918014526
Loss at iteration 250 : 0.9270024299621582
Loss at iteration 300 : 0.8922694325447083
Loss at iteration 350 : 0.6901402473449707
Mean training loss eporch  820 :  0.8420345061828219
Loss at iteration 50 : 0.825038492679596
Loss at iteration 100 : 1.086960792541504
Loss at iteration 150 : 0.8651217818260193
Loss at iteration 200 : 0.9311180710792542
Loss at iteration 250 : 0.904519259929657
Loss at iteration 300 : 0.711185097694397
Loss at iteration 350 : 0.9343505501747131
Mean training loss eporch  821 :  0.8419054052817128
Loss at iteration 50 : 0.7826749086380005
Loss at iteration 100 : 0.7235471606254578
Loss at iteration 150 : 0.7130541205406189
Loss at iteration 200 : 0.8399512767791748
Loss at iteration 250 : 0.7029792070388794
Loss at iteration 300 : 0.7313193082809448
Loss at iteration 350 : 0.718539834022522
Mean training loss eporch  822 :  0.8421212631873983
Loss at iteration 50 : 0.7164019346237183
Loss at iteration 100 : 0.8574591279029846
Loss at iteration 150 : 0.8551721572875977
Loss at iteration 200 : 0.8049815893173218
Loss at iteration 250 : 1.4693984985351562
Loss at iteration 300 : 0.8765460252761841
Loss at iteration 350 : 0.8114680051803589
Mean training loss eporch  823 :  0.8411840091622065
Loss at iteration 50 : 0.7800757884979248
Loss at iteration 100 : 0.7589089274406433
Loss at iteration 150 : 1.00504732131958
Loss at iteration 200 : 1.1208523511886597
Loss at iteration 250 : 0.8501102328300476
Loss at iteration 300 : 0.8058602809906006
Loss at iteration 350 : 0.6523178815841675
Mean training loss eporch  824 :  0.8423495048252994
Loss at iteration 50 : 0.7568997144699097
Loss at iteration 100 : 0.8301681280136108
Loss at iteration 150 : 0.8476513624191284
Loss at iteration 200 : 0.542479395866394
Loss at iteration 250 : 0.7960061430931091
Loss at iteration 300 : 0.8008334636688232
Loss at iteration 350 : 0.8724303245544434
Mean training loss eporch  825 :  0.8412563475982222
Loss at iteration 50 : 0.9143518209457397
Loss at iteration 100 : 0.6411213278770447
Loss at iteration 150 : 0.7532126903533936
Loss at iteration 200 : 0.9931185245513916
Loss at iteration 250 : 0.923055112361908
Loss at iteration 300 : 0.5935571193695068
Loss at iteration 350 : 0.7554694414138794
Mean training loss eporch  826 :  0.8417882526677752
Loss at iteration 50 : 1.0749492645263672
Loss at iteration 100 : 0.5702881813049316
Loss at iteration 150 : 0.9867918491363525
Loss at iteration 200 : 0.8753491640090942
Loss at iteration 250 : 0.7464935779571533
Loss at iteration 300 : 0.832996129989624
Loss at iteration 350 : 0.7770414352416992
Mean training loss eporch  827 :  0.841097776378904
Loss at iteration 50 : 0.8194108605384827
Loss at iteration 100 : 0.7749522924423218
Loss at iteration 150 : 0.8307367563247681
Loss at iteration 200 : 1.0812830924987793
Loss at iteration 250 : 0.9653556942939758
Loss at iteration 300 : 0.6888173818588257
Loss at iteration 350 : 0.9953082799911499
Mean training loss eporch  828 :  0.8414442239615022
Loss at iteration 50 : 0.6476091742515564
Loss at iteration 100 : 0.6782055497169495
Loss at iteration 150 : 0.6005139350891113
Loss at iteration 200 : 0.601766049861908
Loss at iteration 250 : 0.7972896099090576
Loss at iteration 300 : 0.9411032795906067
Loss at iteration 350 : 0.9622212052345276
Mean training loss eporch  829 :  0.8420066530742343
Loss at iteration 50 : 0.9095234274864197
Loss at iteration 100 : 1.292409896850586
Loss at iteration 150 : 0.9265857934951782
Loss at iteration 200 : 0.6677602529525757
Loss at iteration 250 : 0.8576000928878784
Loss at iteration 300 : 0.9915577173233032
Loss at iteration 350 : 0.7687276005744934
Mean training loss eporch  830 :  0.8418085486800583
Loss at iteration 50 : 0.7394716143608093
Loss at iteration 100 : 0.7680752277374268
Loss at iteration 150 : 0.5444238781929016
Loss at iteration 200 : 0.78566575050354
Loss at iteration 250 : 0.8120599389076233
Loss at iteration 300 : 1.1466715335845947
Loss at iteration 350 : 0.7018388509750366
Mean training loss eporch  831 :  0.8415299994604928
Loss at iteration 50 : 0.6957714557647705
Loss at iteration 100 : 0.6627041101455688
Loss at iteration 150 : 0.5898026823997498
Loss at iteration 200 : 1.2111178636550903
Loss at iteration 250 : 0.7041254043579102
Loss at iteration 300 : 0.6733698844909668
Loss at iteration 350 : 0.728889524936676
Mean training loss eporch  832 :  0.8419394888890483
Loss at iteration 50 : 1.0282299518585205
Loss at iteration 100 : 0.8791629672050476
Loss at iteration 150 : 0.5732465386390686
Loss at iteration 200 : 0.9256170988082886
Loss at iteration 250 : 0.7520920634269714
Loss at iteration 300 : 0.6623184680938721
Loss at iteration 350 : 0.7739167213439941
Mean training loss eporch  833 :  0.8420606833444071
Loss at iteration 50 : 0.6683573722839355
Loss at iteration 100 : 0.9267069101333618
Loss at iteration 150 : 0.5656895637512207
Loss at iteration 200 : 1.0481288433074951
Loss at iteration 250 : 0.7862687706947327
Loss at iteration 300 : 1.0261907577514648
Loss at iteration 350 : 0.712548017501831
Mean training loss eporch  834 :  0.8417347655409858
Loss at iteration 50 : 0.8205156326293945
Loss at iteration 100 : 0.6013253331184387
Loss at iteration 150 : 1.090543270111084
Loss at iteration 200 : 0.7383301258087158
Loss at iteration 250 : 0.6295465230941772
Loss at iteration 300 : 1.1031701564788818
Loss at iteration 350 : 0.7270004749298096
Mean training loss eporch  835 :  0.8423708449438135
Loss at iteration 50 : 0.6903758645057678
Loss at iteration 100 : 0.5840115547180176
Loss at iteration 150 : 0.7776919603347778
Loss at iteration 200 : 0.8225165605545044
Loss at iteration 250 : 0.9923725128173828
Loss at iteration 300 : 0.5264452695846558
Loss at iteration 350 : 0.9842532277107239
Mean training loss eporch  836 :  0.8417302021589229
Loss at iteration 50 : 0.8707787990570068
Loss at iteration 100 : 0.8614621758460999
Loss at iteration 150 : 0.7689329385757446
Loss at iteration 200 : 0.9984204769134521
Loss at iteration 250 : 0.7415204644203186
Loss at iteration 300 : 0.684388279914856
Loss at iteration 350 : 0.8835991621017456
Mean training loss eporch  837 :  0.8417129626192114
Loss at iteration 50 : 0.7942586541175842
Loss at iteration 100 : 0.7793031930923462
Loss at iteration 150 : 1.11341392993927
Loss at iteration 200 : 0.7193747758865356
Loss at iteration 250 : 0.9498547315597534
Loss at iteration 300 : 0.7373262047767639
Loss at iteration 350 : 0.6460161805152893
Mean training loss eporch  838 :  0.841424969926713
Loss at iteration 50 : 0.8148881196975708
Loss at iteration 100 : 0.8894367218017578
Loss at iteration 150 : 0.9550045728683472
Loss at iteration 200 : 0.654340386390686
Loss at iteration 250 : 0.8758347630500793
Loss at iteration 300 : 0.929227888584137
Loss at iteration 350 : 0.7076636552810669
Mean training loss eporch  839 :  0.8415096950909448
Loss at iteration 50 : 0.8747965097427368
Loss at iteration 100 : 0.8662210702896118
Loss at iteration 150 : 0.6816368699073792
Loss at iteration 200 : 0.7252471446990967
Loss at iteration 250 : 0.8675982356071472
Loss at iteration 300 : 0.6546612977981567
Loss at iteration 350 : 0.7507486343383789
Mean training loss eporch  840 :  0.841585107344799
Loss at iteration 50 : 0.8439784049987793
Loss at iteration 100 : 0.8410078883171082
Loss at iteration 150 : 0.9532809853553772
Loss at iteration 200 : 0.5910906791687012
Loss at iteration 250 : 0.8951811790466309
Loss at iteration 300 : 0.7250058054924011
Loss at iteration 350 : 0.9453104734420776
Mean training loss eporch  841 :  0.8426165640669525
Loss at iteration 50 : 0.8731849789619446
Loss at iteration 100 : 1.1002415418624878
Loss at iteration 150 : 0.710402250289917
Loss at iteration 200 : 0.9495656490325928
Loss at iteration 250 : 1.0528236627578735
Loss at iteration 300 : 0.8190762400627136
Loss at iteration 350 : 0.9271970987319946
Mean training loss eporch  842 :  0.8422584996494666
Loss at iteration 50 : 0.8662990927696228
Loss at iteration 100 : 0.7182300090789795
Loss at iteration 150 : 0.6869000196456909
Loss at iteration 200 : 0.863621711730957
Loss at iteration 250 : 0.7507336139678955
Loss at iteration 300 : 0.6938453912734985
Loss at iteration 350 : 0.8273320198059082
Mean training loss eporch  843 :  0.8412486593874674
Loss at iteration 50 : 0.7417015433311462
Loss at iteration 100 : 0.8424763083457947
Loss at iteration 150 : 0.8060258626937866
Loss at iteration 200 : 1.1352028846740723
Loss at iteration 250 : 0.8539426922798157
Loss at iteration 300 : 0.9117671847343445
Loss at iteration 350 : 0.5850806832313538
Mean training loss eporch  844 :  0.8422487672989961
Loss at iteration 50 : 0.7573094367980957
Loss at iteration 100 : 0.7013988494873047
Loss at iteration 150 : 0.8056538105010986
Loss at iteration 200 : 0.9362111687660217
Loss at iteration 250 : 0.8643082976341248
Loss at iteration 300 : 1.1861088275909424
Loss at iteration 350 : 0.8161759376525879
Mean training loss eporch  845 :  0.8418198022104445
Loss at iteration 50 : 0.9410799741744995
Loss at iteration 100 : 0.6740590333938599
Loss at iteration 150 : 0.6349000334739685
Loss at iteration 200 : 0.7937002182006836
Loss at iteration 250 : 0.6793130040168762
Loss at iteration 300 : 0.5059120059013367
Loss at iteration 350 : 0.6108188629150391
Mean training loss eporch  846 :  0.842175202158393
Loss at iteration 50 : 1.0462727546691895
Loss at iteration 100 : 0.9634249210357666
Loss at iteration 150 : 0.8716105222702026
Loss at iteration 200 : 0.8734802603721619
Loss at iteration 250 : 0.9471498727798462
Loss at iteration 300 : 0.9039172530174255
Loss at iteration 350 : 0.9105835556983948
Mean training loss eporch  847 :  0.8408399216397099
Loss at iteration 50 : 1.0564842224121094
Loss at iteration 100 : 0.7593989968299866
Loss at iteration 150 : 0.6155632734298706
Loss at iteration 200 : 1.027853012084961
Loss at iteration 250 : 1.062725305557251
Loss at iteration 300 : 1.0253188610076904
Loss at iteration 350 : 0.7206003665924072
Mean training loss eporch  848 :  0.8419046771747095
Loss at iteration 50 : 0.7147160768508911
Loss at iteration 100 : 0.6680534482002258
Loss at iteration 150 : 0.8325693011283875
Loss at iteration 200 : 0.8130565881729126
Loss at iteration 250 : 0.7340432405471802
Loss at iteration 300 : 0.993398904800415
Loss at iteration 350 : 0.6361949443817139
Mean training loss eporch  849 :  0.8418268332721064
Loss at iteration 50 : 0.924990177154541
Loss at iteration 100 : 0.7841907739639282
Loss at iteration 150 : 1.2350949048995972
Loss at iteration 200 : 0.8510336875915527
Loss at iteration 250 : 0.9007601141929626
Loss at iteration 300 : 0.9667036533355713
Loss at iteration 350 : 0.9942058324813843
Mean training loss eporch  850 :  0.8417030716383899
Loss at iteration 50 : 0.7373406887054443
Loss at iteration 100 : 0.7369874119758606
Loss at iteration 150 : 0.5955432057380676
Loss at iteration 200 : 1.2778302431106567
Loss at iteration 250 : 0.8802273273468018
Loss at iteration 300 : 0.914402961730957
Loss at iteration 350 : 0.7588038444519043
Mean training loss eporch  851 :  0.8411636542548578
Loss at iteration 50 : 0.7599880695343018
Loss at iteration 100 : 0.5304458141326904
Loss at iteration 150 : 0.9060207009315491
Loss at iteration 200 : 0.6856862306594849
Loss at iteration 250 : 0.8775497674942017
Loss at iteration 300 : 0.5665791630744934
Loss at iteration 350 : 0.9458540678024292
Mean training loss eporch  852 :  0.8411005343551989
Loss at iteration 50 : 0.5954068899154663
Loss at iteration 100 : 0.5801807045936584
Loss at iteration 150 : 0.8037828207015991
Loss at iteration 200 : 0.7384408712387085
Loss at iteration 250 : 0.9340782165527344
Loss at iteration 300 : 1.0681679248809814
Loss at iteration 350 : 0.9325279593467712
Mean training loss eporch  853 :  0.8420630355991384
Loss at iteration 50 : 0.8748350143432617
Loss at iteration 100 : 0.9038931131362915
Loss at iteration 150 : 0.636763870716095
Loss at iteration 200 : 0.9528517723083496
Loss at iteration 250 : 0.9371577501296997
Loss at iteration 300 : 0.736666202545166
Loss at iteration 350 : 0.6728554368019104
Mean training loss eporch  854 :  0.8421787455599145
Loss at iteration 50 : 0.7923872470855713
Loss at iteration 100 : 0.9266557097434998
Loss at iteration 150 : 0.7264893054962158
Loss at iteration 200 : 0.4862514138221741
Loss at iteration 250 : 0.9981935620307922
Loss at iteration 300 : 0.9653233289718628
Loss at iteration 350 : 0.7549672722816467
Mean training loss eporch  855 :  0.8421095470902781
Loss at iteration 50 : 0.6660094857215881
Loss at iteration 100 : 1.0118138790130615
Loss at iteration 150 : 0.7147606611251831
Loss at iteration 200 : 0.8443565368652344
Loss at iteration 250 : 0.9467378258705139
Loss at iteration 300 : 0.9155845046043396
Loss at iteration 350 : 0.6654747128486633
Mean training loss eporch  856 :  0.8414915961720956
Loss at iteration 50 : 1.0806217193603516
Loss at iteration 100 : 0.5963798761367798
Loss at iteration 150 : 0.8573541641235352
Loss at iteration 200 : 0.9224468469619751
Loss at iteration 250 : 0.6966797113418579
Loss at iteration 300 : 1.1073429584503174
Loss at iteration 350 : 0.7415466904640198
Mean training loss eporch  857 :  0.8412446381238402
Loss at iteration 50 : 0.8988565802574158
Loss at iteration 100 : 1.141873836517334
Loss at iteration 150 : 0.7349835634231567
Loss at iteration 200 : 0.5984984636306763
Loss at iteration 250 : 0.6826227903366089
Loss at iteration 300 : 0.5942304134368896
Loss at iteration 350 : 0.9369238615036011
Mean training loss eporch  858 :  0.8409067110882865
Loss at iteration 50 : 0.6717546582221985
Loss at iteration 100 : 1.176731824874878
Loss at iteration 150 : 0.8876888751983643
Loss at iteration 200 : 1.0341538190841675
Loss at iteration 250 : 0.8511664271354675
Loss at iteration 300 : 0.8156236410140991
Loss at iteration 350 : 0.8598710298538208
Mean training loss eporch  859 :  0.8415154100410522
Loss at iteration 50 : 0.762846827507019
Loss at iteration 100 : 0.548832893371582
Loss at iteration 150 : 1.0269224643707275
Loss at iteration 200 : 0.713249921798706
Loss at iteration 250 : 0.9312412738800049
Loss at iteration 300 : 0.6433594226837158
Loss at iteration 350 : 0.7168070077896118
Mean training loss eporch  860 :  0.8415747317214491
Loss at iteration 50 : 1.1175005435943604
Loss at iteration 100 : 0.7431241869926453
Loss at iteration 150 : 0.8892878890037537
Loss at iteration 200 : 0.6586068868637085
Loss at iteration 250 : 1.0655663013458252
Loss at iteration 300 : 0.7967188358306885
Loss at iteration 350 : 0.7916313409805298
Mean training loss eporch  861 :  0.8414666953856352
Loss at iteration 50 : 0.842619776725769
Loss at iteration 100 : 1.1122047901153564
Loss at iteration 150 : 0.7033852338790894
Loss at iteration 200 : 0.5743402242660522
Loss at iteration 250 : 1.0355582237243652
Loss at iteration 300 : 1.1552491188049316
Loss at iteration 350 : 0.8105666041374207
Mean training loss eporch  862 :  0.8413212782649137
Loss at iteration 50 : 0.6441563367843628
Loss at iteration 100 : 0.9116351008415222
Loss at iteration 150 : 0.6048024296760559
Loss at iteration 200 : 0.9921476244926453
Loss at iteration 250 : 0.6522512435913086
Loss at iteration 300 : 0.7307939529418945
Loss at iteration 350 : 0.8227708339691162
Mean training loss eporch  863 :  0.8414037038409521
Loss at iteration 50 : 0.7566393613815308
Loss at iteration 100 : 0.7272274494171143
Loss at iteration 150 : 0.7539659738540649
Loss at iteration 200 : 0.8108822703361511
Loss at iteration 250 : 0.930498480796814
Loss at iteration 300 : 0.7934972643852234
Loss at iteration 350 : 0.8930480480194092
Mean training loss eporch  864 :  0.8414724954852352
Loss at iteration 50 : 0.5904266834259033
Loss at iteration 100 : 0.683866560459137
Loss at iteration 150 : 0.7334272265434265
Loss at iteration 200 : 1.2588063478469849
Loss at iteration 250 : 1.0580222606658936
Loss at iteration 300 : 0.7779946327209473
Loss at iteration 350 : 1.0001676082611084
Mean training loss eporch  865 :  0.8419199481054589
Loss at iteration 50 : 0.6427987813949585
Loss at iteration 100 : 0.8944302797317505
Loss at iteration 150 : 1.0576170682907104
Loss at iteration 200 : 0.7661387920379639
Loss at iteration 250 : 0.9193774461746216
Loss at iteration 300 : 1.0078010559082031
Loss at iteration 350 : 0.9015729427337646
Mean training loss eporch  866 :  0.8410834395696246
Loss at iteration 50 : 0.8029417395591736
Loss at iteration 100 : 1.154474139213562
Loss at iteration 150 : 0.9811322093009949
Loss at iteration 200 : 0.7984337210655212
Loss at iteration 250 : 0.8364542722702026
Loss at iteration 300 : 0.7796590328216553
Loss at iteration 350 : 0.9193201065063477
Mean training loss eporch  867 :  0.8423169449208274
Loss at iteration 50 : 0.5811262130737305
Loss at iteration 100 : 0.8767348527908325
Loss at iteration 150 : 0.9981698989868164
Loss at iteration 200 : 1.076507329940796
Loss at iteration 250 : 0.7585715055465698
Loss at iteration 300 : 0.8237180709838867
Loss at iteration 350 : 0.8737919330596924
Mean training loss eporch  868 :  0.8409966025402937
Loss at iteration 50 : 0.8440048694610596
Loss at iteration 100 : 0.9728519916534424
Loss at iteration 150 : 0.8999722003936768
Loss at iteration 200 : 0.663573145866394
Loss at iteration 250 : 0.8172943592071533
Loss at iteration 300 : 0.8673901557922363
Loss at iteration 350 : 0.9252066612243652
Mean training loss eporch  869 :  0.8424655356735149
Loss at iteration 50 : 1.0669593811035156
Loss at iteration 100 : 0.8215982913970947
Loss at iteration 150 : 0.9785695672035217
Loss at iteration 200 : 0.894200325012207
Loss at iteration 250 : 0.8345166444778442
Loss at iteration 300 : 1.0380232334136963
Loss at iteration 350 : 0.7445797920227051
Mean training loss eporch  870 :  0.8420440793510467
Loss at iteration 50 : 0.8837870359420776
Loss at iteration 100 : 0.670252799987793
Loss at iteration 150 : 0.7518139481544495
Loss at iteration 200 : 0.8544456958770752
Loss at iteration 250 : 0.9686928987503052
Loss at iteration 300 : 0.8206356167793274
Loss at iteration 350 : 0.9094183444976807
Mean training loss eporch  871 :  0.841680692223014
Loss at iteration 50 : 0.974583625793457
Loss at iteration 100 : 0.9283584952354431
Loss at iteration 150 : 0.5773458480834961
Loss at iteration 200 : 0.7878580093383789
Loss at iteration 250 : 0.6248767971992493
Loss at iteration 300 : 0.9458038210868835
Loss at iteration 350 : 0.674422025680542
Mean training loss eporch  872 :  0.841119029613399
Loss at iteration 50 : 0.8548132181167603
Loss at iteration 100 : 0.8124970197677612
Loss at iteration 150 : 0.9056276679039001
Loss at iteration 200 : 0.8454064130783081
Loss at iteration 250 : 0.825595498085022
Loss at iteration 300 : 0.7845914363861084
Loss at iteration 350 : 0.7887197732925415
Mean training loss eporch  873 :  0.8415391028085083
Loss at iteration 50 : 0.7980674505233765
Loss at iteration 100 : 1.1305854320526123
Loss at iteration 150 : 1.065972089767456
Loss at iteration 200 : 0.8368638157844543
Loss at iteration 250 : 0.9251017570495605
Loss at iteration 300 : 0.819164514541626
Loss at iteration 350 : 0.8444386720657349
Mean training loss eporch  874 :  0.8412767121243099
Loss at iteration 50 : 1.4140074253082275
Loss at iteration 100 : 0.43018418550491333
Loss at iteration 150 : 0.7157704830169678
Loss at iteration 200 : 1.331125259399414
Loss at iteration 250 : 0.5444068312644958
Loss at iteration 300 : 0.621559739112854
Loss at iteration 350 : 0.6926302313804626
Mean training loss eporch  875 :  0.8414674656731742
Loss at iteration 50 : 0.5546619892120361
Loss at iteration 100 : 0.8753440380096436
Loss at iteration 150 : 0.8140150308609009
Loss at iteration 200 : 0.7701047658920288
Loss at iteration 250 : 1.081228256225586
Loss at iteration 300 : 0.8496946096420288
Loss at iteration 350 : 0.9673486948013306
Mean training loss eporch  876 :  0.8418232498187868
Loss at iteration 50 : 0.8518564701080322
Loss at iteration 100 : 0.7955830097198486
Loss at iteration 150 : 0.8046666383743286
Loss at iteration 200 : 0.7165620923042297
Loss at iteration 250 : 0.6584434509277344
Loss at iteration 300 : 0.881661057472229
Loss at iteration 350 : 1.1211163997650146
Mean training loss eporch  877 :  0.8418794274330139
Loss at iteration 50 : 0.816875696182251
Loss at iteration 100 : 0.5774523019790649
Loss at iteration 150 : 0.8571427464485168
Loss at iteration 200 : 0.8219758868217468
Loss at iteration 250 : 0.5413408875465393
Loss at iteration 300 : 0.7737677097320557
Loss at iteration 350 : 0.7868841290473938
Mean training loss eporch  878 :  0.8417417669580096
Loss at iteration 50 : 1.2790840864181519
Loss at iteration 100 : 0.8494589924812317
Loss at iteration 150 : 0.816422164440155
Loss at iteration 200 : 0.7645726799964905
Loss at iteration 250 : 0.9412180185317993
Loss at iteration 300 : 1.0358119010925293
Loss at iteration 350 : 0.928627073764801
Mean training loss eporch  879 :  0.8411839678489342
Loss at iteration 50 : 1.0372247695922852
Loss at iteration 100 : 0.8534830808639526
Loss at iteration 150 : 0.971609354019165
Loss at iteration 200 : 0.8997992873191833
Loss at iteration 250 : 0.6232367753982544
Loss at iteration 300 : 0.8386430144309998
Loss at iteration 350 : 0.7637268304824829
Mean training loss eporch  880 :  0.8416965551792629
Loss at iteration 50 : 1.0481338500976562
Loss at iteration 100 : 0.8547061085700989
Loss at iteration 150 : 0.9386358857154846
Loss at iteration 200 : 1.1830781698226929
Loss at iteration 250 : 0.6278742551803589
Loss at iteration 300 : 0.8515629768371582
Loss at iteration 350 : 0.7016147971153259
Mean training loss eporch  881 :  0.8416317518425998
Loss at iteration 50 : 1.0897860527038574
Loss at iteration 100 : 0.8312572240829468
Loss at iteration 150 : 0.8530840277671814
Loss at iteration 200 : 0.6489677429199219
Loss at iteration 250 : 1.1479346752166748
Loss at iteration 300 : 0.8856561183929443
Loss at iteration 350 : 0.6782369613647461
Mean training loss eporch  882 :  0.8425685867430672
Loss at iteration 50 : 0.7461778521537781
Loss at iteration 100 : 0.8172095417976379
Loss at iteration 150 : 1.053719401359558
Loss at iteration 200 : 0.5420008897781372
Loss at iteration 250 : 1.0031845569610596
Loss at iteration 300 : 0.8477445244789124
Loss at iteration 350 : 0.7522684335708618
Mean training loss eporch  883 :  0.8419920828134294
Loss at iteration 50 : 0.7649093866348267
Loss at iteration 100 : 0.6751448512077332
Loss at iteration 150 : 1.103706955909729
Loss at iteration 200 : 0.9342126846313477
Loss at iteration 250 : 0.6105998754501343
Loss at iteration 300 : 0.8612020015716553
Loss at iteration 350 : 0.8427186012268066
Mean training loss eporch  884 :  0.8420468265259707
Loss at iteration 50 : 0.7879839539527893
Loss at iteration 100 : 0.6785348653793335
Loss at iteration 150 : 0.7453578114509583
Loss at iteration 200 : 0.8828157186508179
Loss at iteration 250 : 1.120133638381958
Loss at iteration 300 : 1.165442943572998
Loss at iteration 350 : 1.1898579597473145
Mean training loss eporch  885 :  0.8414467797077522
Loss at iteration 50 : 0.8461544513702393
Loss at iteration 100 : 1.09707510471344
Loss at iteration 150 : 0.5912666320800781
Loss at iteration 200 : 0.8016241192817688
Loss at iteration 250 : 0.9229351282119751
Loss at iteration 300 : 1.0223796367645264
Loss at iteration 350 : 0.7328711748123169
Mean training loss eporch  886 :  0.841721492390784
Loss at iteration 50 : 0.6075414419174194
Loss at iteration 100 : 0.7190948128700256
Loss at iteration 150 : 0.7172349095344543
Loss at iteration 200 : 0.9265668392181396
Loss at iteration 250 : 1.136298418045044
Loss at iteration 300 : 0.8741894960403442
Loss at iteration 350 : 0.6733852624893188
Mean training loss eporch  887 :  0.8417428443356166
Loss at iteration 50 : 0.914996862411499
Loss at iteration 100 : 0.6430708169937134
Loss at iteration 150 : 1.031333565711975
Loss at iteration 200 : 0.8197211027145386
Loss at iteration 250 : 0.8868963122367859
Loss at iteration 300 : 0.7211779356002808
Loss at iteration 350 : 1.0888702869415283
Mean training loss eporch  888 :  0.841611922417999
Loss at iteration 50 : 1.0119402408599854
Loss at iteration 100 : 0.7406342029571533
Loss at iteration 150 : 0.8937094211578369
Loss at iteration 200 : 1.272007703781128
Loss at iteration 250 : 0.8119720220565796
Loss at iteration 300 : 0.8867720365524292
Loss at iteration 350 : 0.686223030090332
Mean training loss eporch  889 :  0.8412407644526668
Loss at iteration 50 : 0.9150751829147339
Loss at iteration 100 : 1.0003679990768433
Loss at iteration 150 : 0.7345733642578125
Loss at iteration 200 : 0.8906298875808716
Loss at iteration 250 : 0.8041806221008301
Loss at iteration 300 : 0.7406964302062988
Loss at iteration 350 : 0.6473783850669861
Mean training loss eporch  890 :  0.8415508284455254
Loss at iteration 50 : 1.0474494695663452
Loss at iteration 100 : 0.7327573895454407
Loss at iteration 150 : 0.6241660118103027
Loss at iteration 200 : 1.1617971658706665
Loss at iteration 250 : 0.8458026647567749
Loss at iteration 300 : 0.6658644676208496
Loss at iteration 350 : 0.4863446354866028
Mean training loss eporch  891 :  0.8423366925073048
Loss at iteration 50 : 0.8080611228942871
Loss at iteration 100 : 0.8570737838745117
Loss at iteration 150 : 0.8012068271636963
Loss at iteration 200 : 0.8694824576377869
Loss at iteration 250 : 0.7270244359970093
Loss at iteration 300 : 0.8293188810348511
Loss at iteration 350 : 0.7546128034591675
Mean training loss eporch  892 :  0.8411442984348882
Loss at iteration 50 : 0.7899742126464844
Loss at iteration 100 : 0.8878942131996155
Loss at iteration 150 : 0.6957197189331055
Loss at iteration 200 : 0.867079496383667
Loss at iteration 250 : 1.077502965927124
Loss at iteration 300 : 0.7278038263320923
Loss at iteration 350 : 0.6637100577354431
Mean training loss eporch  893 :  0.8416060821089164
Loss at iteration 50 : 0.6092486381530762
Loss at iteration 100 : 0.8951284885406494
Loss at iteration 150 : 0.5447965264320374
Loss at iteration 200 : 0.8367941379547119
Loss at iteration 250 : 0.6955472230911255
Loss at iteration 300 : 0.7838095426559448
Loss at iteration 350 : 0.7836532592773438
Mean training loss eporch  894 :  0.8417406038001731
Loss at iteration 50 : 0.8683096170425415
Loss at iteration 100 : 0.6096290349960327
Loss at iteration 150 : 0.6478679180145264
Loss at iteration 200 : 0.8444334268569946
Loss at iteration 250 : 0.7715888619422913
Loss at iteration 300 : 0.5904556512832642
Loss at iteration 350 : 0.7560780644416809
Mean training loss eporch  895 :  0.8414211070569104
Loss at iteration 50 : 0.7890722751617432
Loss at iteration 100 : 0.8037844896316528
Loss at iteration 150 : 0.9972357153892517
Loss at iteration 200 : 0.7582431435585022
Loss at iteration 250 : 0.723982036113739
Loss at iteration 300 : 0.7982714176177979
Loss at iteration 350 : 1.0945428609848022
Mean training loss eporch  896 :  0.8415772351953719
Loss at iteration 50 : 0.6181696057319641
Loss at iteration 100 : 0.9674039483070374
Loss at iteration 150 : 1.035827875137329
Loss at iteration 200 : 0.6990127563476562
Loss at iteration 250 : 0.8689379692077637
Loss at iteration 300 : 0.6067501306533813
Loss at iteration 350 : 1.0792462825775146
Mean training loss eporch  897 :  0.840864848601755
Loss at iteration 50 : 0.7832797169685364
Loss at iteration 100 : 1.0778477191925049
Loss at iteration 150 : 0.8942834138870239
Loss at iteration 200 : 0.8620315790176392
Loss at iteration 250 : 0.8332489728927612
Loss at iteration 300 : 0.7210204601287842
Loss at iteration 350 : 0.8011347651481628
Mean training loss eporch  898 :  0.8415002477547479
Loss at iteration 50 : 0.8193144202232361
Loss at iteration 100 : 0.6741917133331299
Loss at iteration 150 : 0.5829007625579834
Loss at iteration 200 : 0.6248224973678589
Loss at iteration 250 : 0.6727066040039062
Loss at iteration 300 : 0.7466991543769836
Loss at iteration 350 : 1.153493881225586
Mean training loss eporch  899 :  0.8416177572081329
Loss at iteration 50 : 0.8225892186164856
Loss at iteration 100 : 0.9495137929916382
Loss at iteration 150 : 1.0112847089767456
Loss at iteration 200 : 1.076261043548584
Loss at iteration 250 : 0.9455745220184326
Loss at iteration 300 : 0.7784155607223511
Loss at iteration 350 : 0.7534741163253784
Mean training loss eporch  900 :  0.8411798114499087
Loss at iteration 50 : 0.723423957824707
Loss at iteration 100 : 0.7366722822189331
Loss at iteration 150 : 0.9271783828735352
Loss at iteration 200 : 0.8436920642852783
Loss at iteration 250 : 0.6939934492111206
Loss at iteration 300 : 0.6975663304328918
Loss at iteration 350 : 0.9367928504943848
Mean training loss eporch  901 :  0.8412015706931473
Loss at iteration 50 : 0.7871904373168945
Loss at iteration 100 : 0.5648912191390991
Loss at iteration 150 : 0.671071469783783
Loss at iteration 200 : 0.6401535868644714
Loss at iteration 250 : 0.7496356964111328
Loss at iteration 300 : 0.6382188200950623
Loss at iteration 350 : 0.9870349168777466
Mean training loss eporch  902 :  0.8413208344626049
Loss at iteration 50 : 0.6009184122085571
Loss at iteration 100 : 1.0659823417663574
Loss at iteration 150 : 0.7531478404998779
Loss at iteration 200 : 0.9099019765853882
Loss at iteration 250 : 0.6328881978988647
Loss at iteration 300 : 1.067132830619812
Loss at iteration 350 : 0.6434170007705688
Mean training loss eporch  903 :  0.8425823291615834
Loss at iteration 50 : 0.7889107465744019
Loss at iteration 100 : 0.7554957866668701
Loss at iteration 150 : 1.2939209938049316
Loss at iteration 200 : 0.8015213012695312
Loss at iteration 250 : 0.7197332382202148
Loss at iteration 300 : 0.8559560775756836
Loss at iteration 350 : 0.5667897462844849
Mean training loss eporch  904 :  0.8414158747782783
Loss at iteration 50 : 0.9246749877929688
Loss at iteration 100 : 1.0007400512695312
Loss at iteration 150 : 1.1127243041992188
Loss at iteration 200 : 0.7190642356872559
Loss at iteration 250 : 0.7456912994384766
Loss at iteration 300 : 0.9408391714096069
Loss at iteration 350 : 0.9452468156814575
Mean training loss eporch  905 :  0.8415187002805175
Loss at iteration 50 : 1.1086406707763672
Loss at iteration 100 : 0.9664502143859863
Loss at iteration 150 : 0.6654344797134399
Loss at iteration 200 : 0.696750283241272
Loss at iteration 250 : 0.8432042002677917
Loss at iteration 300 : 0.6927522420883179
Loss at iteration 350 : 0.8523168563842773
Mean training loss eporch  906 :  0.8414719076383681
Loss at iteration 50 : 0.4824821650981903
Loss at iteration 100 : 0.94292151927948
Loss at iteration 150 : 0.7409855723381042
Loss at iteration 200 : 0.9213062524795532
Loss at iteration 250 : 0.8911333084106445
Loss at iteration 300 : 0.7387698888778687
Loss at iteration 350 : 0.6675146222114563
Mean training loss eporch  907 :  0.8429107152753406
Loss at iteration 50 : 0.977219820022583
Loss at iteration 100 : 0.7063758373260498
Loss at iteration 150 : 0.673374354839325
Loss at iteration 200 : 0.7340010404586792
Loss at iteration 250 : 0.8578388690948486
Loss at iteration 300 : 0.7568939924240112
Loss at iteration 350 : 0.7151743173599243
Mean training loss eporch  908 :  0.84196842260777
Loss at iteration 50 : 0.899825930595398
Loss at iteration 100 : 0.8055036067962646
Loss at iteration 150 : 0.7671754360198975
Loss at iteration 200 : 1.0100617408752441
Loss at iteration 250 : 0.7115525007247925
Loss at iteration 300 : 0.5881319046020508
Loss at iteration 350 : 0.6529869437217712
Mean training loss eporch  909 :  0.8407413197099847
Loss at iteration 50 : 0.618903398513794
Loss at iteration 100 : 1.1251730918884277
Loss at iteration 150 : 0.574804961681366
Loss at iteration 200 : 0.7838658094406128
Loss at iteration 250 : 0.8453773856163025
Loss at iteration 300 : 0.6630008816719055
Loss at iteration 350 : 0.8054602146148682
Mean training loss eporch  910 :  0.8418610666794751
Loss at iteration 50 : 0.9512485265731812
Loss at iteration 100 : 0.7793787717819214
Loss at iteration 150 : 0.8016529083251953
Loss at iteration 200 : 0.876275897026062
Loss at iteration 250 : 0.6525885462760925
Loss at iteration 300 : 0.9701964855194092
Loss at iteration 350 : 0.9002587795257568
Mean training loss eporch  911 :  0.8417459820944165
Loss at iteration 50 : 1.0069270133972168
Loss at iteration 100 : 0.8003567457199097
Loss at iteration 150 : 0.5192619562149048
Loss at iteration 200 : 0.6647204756736755
Loss at iteration 250 : 0.7231832146644592
Loss at iteration 300 : 0.6738144755363464
Loss at iteration 350 : 0.8574672937393188
Mean training loss eporch  912 :  0.8418534909764295
Loss at iteration 50 : 0.577667772769928
Loss at iteration 100 : 0.7047964334487915
Loss at iteration 150 : 0.8903909921646118
Loss at iteration 200 : 0.6447868347167969
Loss at iteration 250 : 0.9079520106315613
Loss at iteration 300 : 0.959820032119751
Loss at iteration 350 : 0.721484899520874
Mean training loss eporch  913 :  0.8413679417636659
Loss at iteration 50 : 0.7611298561096191
Loss at iteration 100 : 0.7528327107429504
Loss at iteration 150 : 0.9254066944122314
Loss at iteration 200 : 0.9490710496902466
Loss at iteration 250 : 0.6959477663040161
Loss at iteration 300 : 0.626300036907196
Loss at iteration 350 : 1.3828308582305908
Mean training loss eporch  914 :  0.8415555944518437
Loss at iteration 50 : 0.8061541318893433
Loss at iteration 100 : 1.0307148694992065
Loss at iteration 150 : 0.7158266305923462
Loss at iteration 200 : 0.9513919353485107
Loss at iteration 250 : 0.6418683528900146
Loss at iteration 300 : 0.6489630341529846
Loss at iteration 350 : 0.8195772171020508
Mean training loss eporch  915 :  0.840897428453284
Loss at iteration 50 : 1.0277763605117798
Loss at iteration 100 : 1.1360371112823486
Loss at iteration 150 : 1.1609623432159424
Loss at iteration 200 : 0.5954292416572571
Loss at iteration 250 : 0.9460070133209229
Loss at iteration 300 : 1.0497153997421265
Loss at iteration 350 : 1.1331336498260498
Mean training loss eporch  916 :  0.841718791496186
Loss at iteration 50 : 1.032956838607788
Loss at iteration 100 : 1.062190294265747
Loss at iteration 150 : 0.7811973094940186
Loss at iteration 200 : 0.6752223968505859
Loss at iteration 250 : 1.0706287622451782
Loss at iteration 300 : 0.745061457157135
Loss at iteration 350 : 0.6688794493675232
Mean training loss eporch  917 :  0.8416871345705457
Loss at iteration 50 : 0.8508903980255127
Loss at iteration 100 : 0.7894755005836487
Loss at iteration 150 : 0.8273151516914368
Loss at iteration 200 : 0.8582371473312378
Loss at iteration 250 : 0.6805843710899353
Loss at iteration 300 : 0.8495532870292664
Loss at iteration 350 : 0.9273177981376648
Mean training loss eporch  918 :  0.8412478957226668
Loss at iteration 50 : 0.663000762462616
Loss at iteration 100 : 0.545866847038269
Loss at iteration 150 : 0.8500816822052002
Loss at iteration 200 : 0.5758524537086487
Loss at iteration 250 : 0.8866782784461975
Loss at iteration 300 : 0.6633851528167725
Loss at iteration 350 : 0.7977168560028076
Mean training loss eporch  919 :  0.8408139638957524
Loss at iteration 50 : 0.8019710779190063
Loss at iteration 100 : 1.3464205265045166
Loss at iteration 150 : 0.673943281173706
Loss at iteration 200 : 0.7686086297035217
Loss at iteration 250 : 0.8573799133300781
Loss at iteration 300 : 0.8106026649475098
Loss at iteration 350 : 0.887401282787323
Mean training loss eporch  920 :  0.8407519445532844
Loss at iteration 50 : 0.935523509979248
Loss at iteration 100 : 0.647141695022583
Loss at iteration 150 : 1.034841537475586
Loss at iteration 200 : 0.7214683294296265
Loss at iteration 250 : 0.9039410948753357
Loss at iteration 300 : 0.7752602696418762
Loss at iteration 350 : 0.8527534008026123
Mean training loss eporch  921 :  0.8425194636854545
Loss at iteration 50 : 1.0693031549453735
Loss at iteration 100 : 0.9200054407119751
Loss at iteration 150 : 0.6253925561904907
Loss at iteration 200 : 0.9544817209243774
Loss at iteration 250 : 1.1869021654129028
Loss at iteration 300 : 0.6087867021560669
Loss at iteration 350 : 0.606671154499054
Mean training loss eporch  922 :  0.8422448682406593
Loss at iteration 50 : 0.9958306550979614
Loss at iteration 100 : 0.7783969044685364
Loss at iteration 150 : 0.8487424850463867
Loss at iteration 200 : 0.7342623472213745
Loss at iteration 250 : 0.9449961185455322
Loss at iteration 300 : 0.986077606678009
Loss at iteration 350 : 0.9719704985618591
Mean training loss eporch  923 :  0.8413100967962275
Loss at iteration 50 : 0.504413366317749
Loss at iteration 100 : 0.7660178542137146
Loss at iteration 150 : 0.7942550182342529
Loss at iteration 200 : 1.1123794317245483
Loss at iteration 250 : 0.6656696796417236
Loss at iteration 300 : 0.7697217464447021
Loss at iteration 350 : 0.7347593903541565
Mean training loss eporch  924 :  0.8410826673898747
Loss at iteration 50 : 0.8662136197090149
Loss at iteration 100 : 0.6613016724586487
Loss at iteration 150 : 0.8593893051147461
Loss at iteration 200 : 1.2168505191802979
Loss at iteration 250 : 0.9188772439956665
Loss at iteration 300 : 0.8055105209350586
Loss at iteration 350 : 0.991416335105896
Mean training loss eporch  925 :  0.8422667674286656
Loss at iteration 50 : 0.8870879411697388
Loss at iteration 100 : 1.1846145391464233
Loss at iteration 150 : 0.821835994720459
Loss at iteration 200 : 0.9306983947753906
Loss at iteration 250 : 1.0544952154159546
Loss at iteration 300 : 0.6978998184204102
Loss at iteration 350 : 0.7036244869232178
Mean training loss eporch  926 :  0.8421704859802963
Loss at iteration 50 : 0.6130990386009216
Loss at iteration 100 : 1.0840867757797241
Loss at iteration 150 : 1.3274224996566772
Loss at iteration 200 : 0.6857941150665283
Loss at iteration 250 : 0.9454733729362488
Loss at iteration 300 : 0.6860591173171997
Loss at iteration 350 : 0.7379699945449829
Mean training loss eporch  927 :  0.8413465999894671
Loss at iteration 50 : 0.9159119129180908
Loss at iteration 100 : 1.1676105260849
Loss at iteration 150 : 1.0219571590423584
Loss at iteration 200 : 1.0308427810668945
Loss at iteration 250 : 0.6473016738891602
Loss at iteration 300 : 0.9673780202865601
Loss at iteration 350 : 0.961612343788147
Mean training loss eporch  928 :  0.8419804500524329
Loss at iteration 50 : 0.8459124565124512
Loss at iteration 100 : 0.8924687504768372
Loss at iteration 150 : 0.9443745613098145
Loss at iteration 200 : 0.9229471683502197
Loss at iteration 250 : 0.7659140825271606
Loss at iteration 300 : 0.9628729820251465
Loss at iteration 350 : 0.8699686527252197
Mean training loss eporch  929 :  0.8410029020258989
Loss at iteration 50 : 0.6627938747406006
Loss at iteration 100 : 1.2231459617614746
Loss at iteration 150 : 0.937742292881012
Loss at iteration 200 : 0.8566133975982666
Loss at iteration 250 : 1.0592401027679443
Loss at iteration 300 : 0.7650536298751831
Loss at iteration 350 : 1.0392684936523438
Mean training loss eporch  930 :  0.8420513054681202
Loss at iteration 50 : 0.5561416149139404
Loss at iteration 100 : 0.9200129508972168
Loss at iteration 150 : 0.8059709072113037
Loss at iteration 200 : 1.0137547254562378
Loss at iteration 250 : 0.7579888105392456
Loss at iteration 300 : 0.7596445679664612
Loss at iteration 350 : 0.8607151508331299
Mean training loss eporch  931 :  0.8411843209039598
Loss at iteration 50 : 0.7897330522537231
Loss at iteration 100 : 0.9574615359306335
Loss at iteration 150 : 0.6840885877609253
Loss at iteration 200 : 1.000775694847107
Loss at iteration 250 : 1.0181010961532593
Loss at iteration 300 : 1.111525297164917
Loss at iteration 350 : 1.150944471359253
Mean training loss eporch  932 :  0.8412715863613855
Loss at iteration 50 : 1.0980631113052368
Loss at iteration 100 : 0.6827301979064941
Loss at iteration 150 : 0.7755106687545776
Loss at iteration 200 : 0.7592270374298096
Loss at iteration 250 : 1.070357322692871
Loss at iteration 300 : 0.9629237055778503
Loss at iteration 350 : 0.770427942276001
Mean training loss eporch  933 :  0.8409174551408758
Loss at iteration 50 : 0.842818021774292
Loss at iteration 100 : 0.9750264883041382
Loss at iteration 150 : 0.9569662809371948
Loss at iteration 200 : 0.9571306109428406
Loss at iteration 250 : 0.7476022839546204
Loss at iteration 300 : 0.9333742260932922
Loss at iteration 350 : 0.6730780601501465
Mean training loss eporch  934 :  0.8413709096176915
Loss at iteration 50 : 1.192479133605957
Loss at iteration 100 : 0.9633803963661194
Loss at iteration 150 : 0.8889701962471008
Loss at iteration 200 : 0.8670448660850525
Loss at iteration 250 : 0.9196652173995972
Loss at iteration 300 : 0.8396286964416504
Loss at iteration 350 : 0.8611012101173401
Mean training loss eporch  935 :  0.84158579413853
Loss at iteration 50 : 0.881627082824707
Loss at iteration 100 : 1.0765478610992432
Loss at iteration 150 : 0.8540207743644714
Loss at iteration 200 : 1.1218769550323486
Loss at iteration 250 : 0.7446759939193726
Loss at iteration 300 : 0.5725933313369751
Loss at iteration 350 : 1.0485860109329224
Mean training loss eporch  936 :  0.8418377002395651
Loss at iteration 50 : 0.8306875228881836
Loss at iteration 100 : 0.8889542818069458
Loss at iteration 150 : 0.7733213901519775
Loss at iteration 200 : 0.8401651382446289
Loss at iteration 250 : 0.7388968467712402
Loss at iteration 300 : 0.9330732822418213
Loss at iteration 350 : 0.9103321433067322
Mean training loss eporch  937 :  0.8414304947096204
Loss at iteration 50 : 0.9207543730735779
Loss at iteration 100 : 0.9355964064598083
Loss at iteration 150 : 0.8853587508201599
Loss at iteration 200 : 1.165184736251831
Loss at iteration 250 : 0.800270676612854
Loss at iteration 300 : 1.0789122581481934
Loss at iteration 350 : 0.7920014262199402
Mean training loss eporch  938 :  0.8414295441889889
Loss at iteration 50 : 0.7613916993141174
Loss at iteration 100 : 1.2289005517959595
Loss at iteration 150 : 0.9056791067123413
Loss at iteration 200 : 0.7965663075447083
Loss at iteration 250 : 1.023060917854309
Loss at iteration 300 : 0.6489835977554321
Loss at iteration 350 : 0.8897044062614441
Mean training loss eporch  939 :  0.8419369129592149
Loss at iteration 50 : 0.6719461679458618
Loss at iteration 100 : 0.6185942888259888
Loss at iteration 150 : 0.7554669976234436
Loss at iteration 200 : 0.7279353737831116
Loss at iteration 250 : 0.7650241851806641
Loss at iteration 300 : 1.1653001308441162
Loss at iteration 350 : 0.7250444293022156
Mean training loss eporch  940 :  0.84110295977542
Loss at iteration 50 : 0.749701201915741
Loss at iteration 100 : 0.9850529432296753
Loss at iteration 150 : 0.901594340801239
Loss at iteration 200 : 0.9941133260726929
Loss at iteration 250 : 0.6200686693191528
Loss at iteration 300 : 1.0601940155029297
Loss at iteration 350 : 1.1011481285095215
Mean training loss eporch  941 :  0.8419763667400552
Loss at iteration 50 : 0.6939991116523743
Loss at iteration 100 : 0.8761870861053467
Loss at iteration 150 : 0.9830329418182373
Loss at iteration 200 : 1.041570782661438
Loss at iteration 250 : 0.8802227973937988
Loss at iteration 300 : 0.6748718023300171
Loss at iteration 350 : 0.7760433554649353
Mean training loss eporch  942 :  0.8411576844081676
Loss at iteration 50 : 0.7499957084655762
Loss at iteration 100 : 0.8653856515884399
Loss at iteration 150 : 0.7935521006584167
Loss at iteration 200 : 0.8442656993865967
Loss at iteration 250 : 0.7421495318412781
Loss at iteration 300 : 0.7894675731658936
Loss at iteration 350 : 1.305052399635315
Mean training loss eporch  943 :  0.8416414733916994
Loss at iteration 50 : 0.7859780192375183
Loss at iteration 100 : 0.7275687456130981
Loss at iteration 150 : 1.2270920276641846
Loss at iteration 200 : 0.7606443166732788
Loss at iteration 250 : 0.7962002158164978
Loss at iteration 300 : 0.716064989566803
Loss at iteration 350 : 0.8685437440872192
Mean training loss eporch  944 :  0.8413517328481825
Loss at iteration 50 : 0.7222491502761841
Loss at iteration 100 : 0.5989348292350769
Loss at iteration 150 : 0.783324658870697
Loss at iteration 200 : 1.2693148851394653
Loss at iteration 250 : 0.80255126953125
Loss at iteration 300 : 0.6988357305526733
Loss at iteration 350 : 0.8280898928642273
Mean training loss eporch  945 :  0.8416452628594858
Loss at iteration 50 : 0.9373072385787964
Loss at iteration 100 : 1.1549392938613892
Loss at iteration 150 : 0.7727715969085693
Loss at iteration 200 : 0.8772349953651428
Loss at iteration 250 : 0.9311147928237915
Loss at iteration 300 : 0.7851780652999878
Loss at iteration 350 : 0.9450470209121704
Mean training loss eporch  946 :  0.8409216563222269
Loss at iteration 50 : 0.9127674102783203
Loss at iteration 100 : 0.683107852935791
Loss at iteration 150 : 0.7874965667724609
Loss at iteration 200 : 0.8143724203109741
Loss at iteration 250 : 0.8174077272415161
Loss at iteration 300 : 0.8594598770141602
Loss at iteration 350 : 0.7553344964981079
Mean training loss eporch  947 :  0.8413934289778351
Loss at iteration 50 : 0.7126657962799072
Loss at iteration 100 : 1.079815149307251
Loss at iteration 150 : 0.9342411756515503
Loss at iteration 200 : 0.6605578660964966
Loss at iteration 250 : 0.6777184009552002
Loss at iteration 300 : 0.8870134353637695
Loss at iteration 350 : 0.8507100939750671
Mean training loss eporch  948 :  0.8411065194972609
Loss at iteration 50 : 0.8329559564590454
Loss at iteration 100 : 0.7826338410377502
Loss at iteration 150 : 0.9579065442085266
Loss at iteration 200 : 1.1979279518127441
Loss at iteration 250 : 1.0350770950317383
Loss at iteration 300 : 0.779011607170105
Loss at iteration 350 : 0.7457504272460938
Mean training loss eporch  949 :  0.8413051324231284
Loss at iteration 50 : 0.8772417902946472
Loss at iteration 100 : 1.0165308713912964
Loss at iteration 150 : 0.8966072797775269
Loss at iteration 200 : 0.6779570579528809
Loss at iteration 250 : 0.7729841470718384
Loss at iteration 300 : 0.81984543800354
Loss at iteration 350 : 1.132426142692566
Mean training loss eporch  950 :  0.841099261054917
Loss at iteration 50 : 0.7660952210426331
Loss at iteration 100 : 1.145330548286438
Loss at iteration 150 : 1.0839811563491821
Loss at iteration 200 : 0.7645823955535889
Loss at iteration 250 : 1.0638716220855713
Loss at iteration 300 : 0.8516956567764282
Loss at iteration 350 : 0.6314085721969604
Mean training loss eporch  951 :  0.8413122063749051
Loss at iteration 50 : 0.8214401006698608
Loss at iteration 100 : 1.2042630910873413
Loss at iteration 150 : 0.838676929473877
Loss at iteration 200 : 1.0167524814605713
Loss at iteration 250 : 0.8280849456787109
Loss at iteration 300 : 0.8007494807243347
Loss at iteration 350 : 0.919445276260376
Mean training loss eporch  952 :  0.8417536592672742
Loss at iteration 50 : 0.9223430156707764
Loss at iteration 100 : 0.6573108434677124
Loss at iteration 150 : 0.6176853775978088
Loss at iteration 200 : 0.5416339635848999
Loss at iteration 250 : 0.6629638075828552
Loss at iteration 300 : 1.0425328016281128
Loss at iteration 350 : 1.094754934310913
Mean training loss eporch  953 :  0.8425551536221983
Loss at iteration 50 : 0.9408764839172363
Loss at iteration 100 : 0.7678073644638062
Loss at iteration 150 : 0.7914305925369263
Loss at iteration 200 : 0.8197537660598755
Loss at iteration 250 : 0.9596402645111084
Loss at iteration 300 : 1.098321795463562
Loss at iteration 350 : 1.125555157661438
Mean training loss eporch  954 :  0.8419191593688632
Loss at iteration 50 : 0.7067728042602539
Loss at iteration 100 : 0.8107627630233765
Loss at iteration 150 : 0.6403444409370422
Loss at iteration 200 : 0.7772325873374939
Loss at iteration 250 : 0.6652313470840454
Loss at iteration 300 : 0.9114157557487488
Loss at iteration 350 : 0.857876718044281
Mean training loss eporch  955 :  0.8410194856779916
Loss at iteration 50 : 0.76161789894104
Loss at iteration 100 : 1.1244750022888184
Loss at iteration 150 : 0.7066757678985596
Loss at iteration 200 : 1.1394398212432861
Loss at iteration 250 : 0.9891785979270935
Loss at iteration 300 : 0.737183690071106
Loss at iteration 350 : 0.6022027730941772
Mean training loss eporch  956 :  0.8412136284920274
Loss at iteration 50 : 0.9885067939758301
Loss at iteration 100 : 0.6789841651916504
Loss at iteration 150 : 0.983350932598114
Loss at iteration 200 : 0.7560359239578247
Loss at iteration 250 : 0.7710398435592651
Loss at iteration 300 : 0.7553236484527588
Loss at iteration 350 : 0.8435629606246948
Mean training loss eporch  957 :  0.8413400139127459
Loss at iteration 50 : 0.7715699076652527
Loss at iteration 100 : 1.0137648582458496
Loss at iteration 150 : 0.8439725041389465
Loss at iteration 200 : 0.9474253058433533
Loss at iteration 250 : 0.8195796012878418
Loss at iteration 300 : 1.075502872467041
Loss at iteration 350 : 0.7716819643974304
Mean training loss eporch  958 :  0.8426577589972309
Loss at iteration 50 : 0.7908310890197754
Loss at iteration 100 : 0.8923890590667725
Loss at iteration 150 : 0.8239521384239197
Loss at iteration 200 : 0.5676791071891785
Loss at iteration 250 : 0.9793365001678467
Loss at iteration 300 : 0.6692227125167847
Loss at iteration 350 : 0.9537712335586548
Mean training loss eporch  959 :  0.8412364257706536
Loss at iteration 50 : 0.8531458377838135
Loss at iteration 100 : 0.8359554409980774
Loss at iteration 150 : 0.5489765405654907
Loss at iteration 200 : 1.206383228302002
Loss at iteration 250 : 0.5753172039985657
Loss at iteration 300 : 1.1822121143341064
Loss at iteration 350 : 0.6533501744270325
Mean training loss eporch  960 :  0.8416526043225848
Loss at iteration 50 : 0.9840502738952637
Loss at iteration 100 : 0.799864649772644
Loss at iteration 150 : 0.7401089668273926
Loss at iteration 200 : 0.920767068862915
Loss at iteration 250 : 0.9271574020385742
Loss at iteration 300 : 0.9242630004882812
Loss at iteration 350 : 0.8049303889274597
Mean training loss eporch  961 :  0.840402285100291
Loss at iteration 50 : 0.6694402694702148
Loss at iteration 100 : 0.7778692245483398
Loss at iteration 150 : 1.2549786567687988
Loss at iteration 200 : 1.2168869972229004
Loss at iteration 250 : 0.5216551423072815
Loss at iteration 300 : 0.8873738050460815
Loss at iteration 350 : 1.2441258430480957
Mean training loss eporch  962 :  0.841713392860675
Loss at iteration 50 : 0.6214996576309204
Loss at iteration 100 : 0.8401733040809631
Loss at iteration 150 : 0.8507388830184937
Loss at iteration 200 : 0.8692113161087036
Loss at iteration 250 : 1.1678378582000732
Loss at iteration 300 : 0.793372631072998
Loss at iteration 350 : 0.6663999557495117
Mean training loss eporch  963 :  0.8424358710883155
Loss at iteration 50 : 0.8224053978919983
Loss at iteration 100 : 0.6486256122589111
Loss at iteration 150 : 1.2007471323013306
Loss at iteration 200 : 0.6138285398483276
Loss at iteration 250 : 0.8357734084129333
Loss at iteration 300 : 1.0128880739212036
Loss at iteration 350 : 0.986620306968689
Mean training loss eporch  964 :  0.8406419774527272
Loss at iteration 50 : 0.6389985680580139
Loss at iteration 100 : 0.8236565589904785
Loss at iteration 150 : 0.7271864414215088
Loss at iteration 200 : 0.9580453634262085
Loss at iteration 250 : 0.9876035451889038
Loss at iteration 300 : 0.6618339419364929
Loss at iteration 350 : 1.0605766773223877
Mean training loss eporch  965 :  0.8415716984284618
Loss at iteration 50 : 0.9685778617858887
Loss at iteration 100 : 0.7623893022537231
Loss at iteration 150 : 0.7190021872520447
Loss at iteration 200 : 0.6877811551094055
Loss at iteration 250 : 0.9038525223731995
Loss at iteration 300 : 0.7262491583824158
Loss at iteration 350 : 0.8595119714736938
Mean training loss eporch  966 :  0.8411384653004389
Loss at iteration 50 : 0.6891650557518005
Loss at iteration 100 : 0.7605735063552856
Loss at iteration 150 : 0.8902933597564697
Loss at iteration 200 : 0.5965777635574341
Loss at iteration 250 : 0.6228614449501038
Loss at iteration 300 : 0.8703460693359375
Loss at iteration 350 : 0.8491929769515991
Mean training loss eporch  967 :  0.8406409250680732
Loss at iteration 50 : 0.7291393280029297
Loss at iteration 100 : 0.7238671779632568
Loss at iteration 150 : 0.8511397242546082
Loss at iteration 200 : 0.8597124218940735
Loss at iteration 250 : 0.6835856437683105
Loss at iteration 300 : 0.8798123598098755
Loss at iteration 350 : 0.7652000188827515
Mean training loss eporch  968 :  0.8416916116993264
Loss at iteration 50 : 0.9644290208816528
Loss at iteration 100 : 0.920386552810669
Loss at iteration 150 : 0.6483573317527771
Loss at iteration 200 : 0.7557563781738281
Loss at iteration 250 : 0.9926325082778931
Loss at iteration 300 : 0.8667169809341431
Loss at iteration 350 : 1.0525554418563843
Mean training loss eporch  969 :  0.8411276427210954
Loss at iteration 50 : 0.7477133870124817
Loss at iteration 100 : 0.7114551663398743
Loss at iteration 150 : 0.6288555860519409
Loss at iteration 200 : 0.762830376625061
Loss at iteration 250 : 0.8509697914123535
Loss at iteration 300 : 1.0588369369506836
Loss at iteration 350 : 0.818010687828064
Mean training loss eporch  970 :  0.8423497725731481
Loss at iteration 50 : 1.0981662273406982
Loss at iteration 100 : 0.9064844846725464
Loss at iteration 150 : 0.608103334903717
Loss at iteration 200 : 1.0532426834106445
Loss at iteration 250 : 0.7432079911231995
Loss at iteration 300 : 1.138667106628418
Loss at iteration 350 : 1.0538839101791382
Mean training loss eporch  971 :  0.8408584134288566
Loss at iteration 50 : 0.6268411874771118
Loss at iteration 100 : 0.7608981728553772
Loss at iteration 150 : 0.9308493137359619
Loss at iteration 200 : 0.6881601810455322
Loss at iteration 250 : 0.6847699284553528
Loss at iteration 300 : 0.8703060150146484
Loss at iteration 350 : 0.7631820440292358
Mean training loss eporch  972 :  0.8409208690047895
Loss at iteration 50 : 0.7525842189788818
Loss at iteration 100 : 0.7129489183425903
Loss at iteration 150 : 0.5746086835861206
Loss at iteration 200 : 0.9912399053573608
Loss at iteration 250 : 0.9242297410964966
Loss at iteration 300 : 0.8378024101257324
Loss at iteration 350 : 0.9322553873062134
Mean training loss eporch  973 :  0.8414986354333384
Loss at iteration 50 : 0.9117703437805176
Loss at iteration 100 : 1.1496546268463135
Loss at iteration 150 : 0.7139874696731567
Loss at iteration 200 : 0.9988802075386047
Loss at iteration 250 : 0.5807920694351196
Loss at iteration 300 : 0.9684665203094482
Loss at iteration 350 : 1.124496579170227
Mean training loss eporch  974 :  0.8418230414390564
Loss at iteration 50 : 0.7138565182685852
Loss at iteration 100 : 0.8547936677932739
Loss at iteration 150 : 0.902127742767334
Loss at iteration 200 : 0.9297382235527039
Loss at iteration 250 : 1.0035874843597412
Loss at iteration 300 : 0.7453337907791138
Loss at iteration 350 : 0.5812492966651917
Mean training loss eporch  975 :  0.840877347679996
Loss at iteration 50 : 0.6977826952934265
Loss at iteration 100 : 0.6104223728179932
Loss at iteration 150 : 0.9013782143592834
Loss at iteration 200 : 0.6291255354881287
Loss at iteration 250 : 0.5898275375366211
Loss at iteration 300 : 0.9320864081382751
Loss at iteration 350 : 0.6398968696594238
Mean training loss eporch  976 :  0.8407888757804084
Loss at iteration 50 : 0.9597760438919067
Loss at iteration 100 : 0.9584072828292847
Loss at iteration 150 : 1.4061583280563354
Loss at iteration 200 : 0.5702906250953674
Loss at iteration 250 : 0.9654291868209839
Loss at iteration 300 : 0.7491849660873413
Loss at iteration 350 : 0.7170121669769287
Mean training loss eporch  977 :  0.8410851051094671
Loss at iteration 50 : 0.6121411323547363
Loss at iteration 100 : 0.8513082265853882
Loss at iteration 150 : 0.8043537139892578
Loss at iteration 200 : 0.6961814165115356
Loss at iteration 250 : 0.8362443447113037
Loss at iteration 300 : 0.8540526628494263
Loss at iteration 350 : 1.0032219886779785
Mean training loss eporch  978 :  0.8410777012822489
Loss at iteration 50 : 0.6980265974998474
Loss at iteration 100 : 0.906474769115448
Loss at iteration 150 : 0.7972719669342041
Loss at iteration 200 : 1.0357537269592285
Loss at iteration 250 : 0.4904218912124634
Loss at iteration 300 : 0.6326801776885986
Loss at iteration 350 : 0.8074862957000732
Mean training loss eporch  979 :  0.8415225439916842
Loss at iteration 50 : 0.7607364058494568
Loss at iteration 100 : 0.7829515933990479
Loss at iteration 150 : 0.5967258214950562
Loss at iteration 200 : 1.1411535739898682
Loss at iteration 250 : 0.7681953310966492
Loss at iteration 300 : 1.384344458580017
Loss at iteration 350 : 0.9749500751495361
Mean training loss eporch  980 :  0.8415263039725167
Loss at iteration 50 : 0.9619004726409912
Loss at iteration 100 : 0.978337287902832
Loss at iteration 150 : 0.8250651359558105
Loss at iteration 200 : 1.0896574258804321
Loss at iteration 250 : 1.152612566947937
Loss at iteration 300 : 0.9813127517700195
Loss at iteration 350 : 0.650310754776001
Mean training loss eporch  981 :  0.841420713634718
Loss at iteration 50 : 0.8000176548957825
Loss at iteration 100 : 0.637442946434021
Loss at iteration 150 : 0.859576940536499
Loss at iteration 200 : 0.8480731844902039
Loss at iteration 250 : 0.7006743550300598
Loss at iteration 300 : 0.6763433218002319
Loss at iteration 350 : 0.8335286974906921
Mean training loss eporch  982 :  0.8425263048164429
Loss at iteration 50 : 0.9841057062149048
Loss at iteration 100 : 0.560528576374054
Loss at iteration 150 : 0.7346800565719604
Loss at iteration 200 : 1.0102779865264893
Loss at iteration 250 : 1.1272146701812744
Loss at iteration 300 : 0.9150158166885376
Loss at iteration 350 : 0.8999592065811157
Mean training loss eporch  983 :  0.8413467475030788
Loss at iteration 50 : 0.8701233863830566
Loss at iteration 100 : 0.6651588678359985
Loss at iteration 150 : 0.6966687440872192
Loss at iteration 200 : 0.6203362345695496
Loss at iteration 250 : 0.8136564493179321
Loss at iteration 300 : 0.9315603971481323
Loss at iteration 350 : 0.5946603417396545
Mean training loss eporch  984 :  0.8420756012989731
Loss at iteration 50 : 1.0906696319580078
Loss at iteration 100 : 0.626773476600647
Loss at iteration 150 : 0.6933963894844055
Loss at iteration 200 : 0.8487078547477722
Loss at iteration 250 : 0.6171740293502808
Loss at iteration 300 : 1.0427446365356445
Loss at iteration 350 : 0.8298559188842773
Mean training loss eporch  985 :  0.8415778644343532
Loss at iteration 50 : 0.9916751384735107
Loss at iteration 100 : 0.6798859238624573
Loss at iteration 150 : 0.8880674242973328
Loss at iteration 200 : 1.1912596225738525
Loss at iteration 250 : 0.9074493646621704
Loss at iteration 300 : 1.0454578399658203
Loss at iteration 350 : 0.7395185232162476
Mean training loss eporch  986 :  0.8426207228312417
Loss at iteration 50 : 0.7907193899154663
Loss at iteration 100 : 0.5273825526237488
Loss at iteration 150 : 0.9316009283065796
Loss at iteration 200 : 0.47097843885421753
Loss at iteration 250 : 0.6217606067657471
Loss at iteration 300 : 0.5846129655838013
Loss at iteration 350 : 0.7954124212265015
Mean training loss eporch  987 :  0.8415299788038567
Loss at iteration 50 : 0.649513304233551
Loss at iteration 100 : 0.9129188656806946
Loss at iteration 150 : 0.8085744380950928
Loss at iteration 200 : 0.7465502023696899
Loss at iteration 250 : 0.7157549262046814
Loss at iteration 300 : 0.6982144713401794
Loss at iteration 350 : 0.7998918890953064
Mean training loss eporch  988 :  0.8422608787893618
Loss at iteration 50 : 0.7014131546020508
Loss at iteration 100 : 0.9403089284896851
Loss at iteration 150 : 0.7173879146575928
Loss at iteration 200 : 0.6124616861343384
Loss at iteration 250 : 0.7358108758926392
Loss at iteration 300 : 0.8272868990898132
Loss at iteration 350 : 0.7520474195480347
Mean training loss eporch  989 :  0.8408958823592575
Loss at iteration 50 : 1.0095326900482178
Loss at iteration 100 : 0.9831456542015076
Loss at iteration 150 : 0.7674238681793213
Loss at iteration 200 : 0.7922245264053345
Loss at iteration 250 : 0.8790592551231384
Loss at iteration 300 : 0.6790035963058472
Loss at iteration 350 : 1.0189096927642822
Mean training loss eporch  990 :  0.8415403307745697
Loss at iteration 50 : 0.8402526378631592
Loss at iteration 100 : 1.1128551959991455
Loss at iteration 150 : 0.8724877834320068
Loss at iteration 200 : 1.1295263767242432
Loss at iteration 250 : 0.8871282339096069
Loss at iteration 300 : 0.8295894861221313
Loss at iteration 350 : 0.7311749458312988
Mean training loss eporch  991 :  0.8413072637622319
Loss at iteration 50 : 0.717287540435791
Loss at iteration 100 : 0.9471019506454468
Loss at iteration 150 : 0.7069331407546997
Loss at iteration 200 : 0.7834013104438782
Loss at iteration 250 : 0.7178987860679626
Loss at iteration 300 : 0.7502895593643188
Loss at iteration 350 : 0.6798825263977051
Mean training loss eporch  992 :  0.8410218760134682
Loss at iteration 50 : 0.6325696110725403
Loss at iteration 100 : 0.7738519906997681
Loss at iteration 150 : 0.8296302556991577
Loss at iteration 200 : 0.6057938933372498
Loss at iteration 250 : 0.7096272706985474
Loss at iteration 300 : 1.0146465301513672
Loss at iteration 350 : 0.810011625289917
Mean training loss eporch  993 :  0.8413587974965888
Loss at iteration 50 : 0.8764796257019043
Loss at iteration 100 : 0.6278267502784729
Loss at iteration 150 : 0.5343919992446899
Loss at iteration 200 : 0.9126387238502502
Loss at iteration 250 : 0.94888836145401
Loss at iteration 300 : 0.7841228246688843
Loss at iteration 350 : 1.1218364238739014
Mean training loss eporch  994 :  0.8410258562791915
Loss at iteration 50 : 0.6237514019012451
Loss at iteration 100 : 0.6980531811714172
Loss at iteration 150 : 0.8743270039558411
Loss at iteration 200 : 0.9061107039451599
Loss at iteration 250 : 0.7236188054084778
Loss at iteration 300 : 0.9793587923049927
Loss at iteration 350 : 0.8175453543663025
Mean training loss eporch  995 :  0.8405132583840184
Loss at iteration 50 : 0.7977021336555481
Loss at iteration 100 : 1.0210988521575928
Loss at iteration 150 : 0.8070325255393982
Loss at iteration 200 : 1.084669828414917
Loss at iteration 250 : 0.863475501537323
Loss at iteration 300 : 0.7754757404327393
Loss at iteration 350 : 0.729983389377594
Mean training loss eporch  996 :  0.8412081282290201
Loss at iteration 50 : 0.7319243550300598
Loss at iteration 100 : 0.6439282894134521
Loss at iteration 150 : 1.0221267938613892
Loss at iteration 200 : 0.9721078872680664
Loss at iteration 250 : 0.7988234162330627
Loss at iteration 300 : 1.1143770217895508
Loss at iteration 350 : 0.5947940349578857
Mean training loss eporch  997 :  0.8408133277975062
Loss at iteration 50 : 0.734533429145813
Loss at iteration 100 : 0.7552342414855957
Loss at iteration 150 : 1.1183671951293945
Loss at iteration 200 : 0.872184157371521
Loss at iteration 250 : 0.6955579519271851
Loss at iteration 300 : 1.1071983575820923
Loss at iteration 350 : 0.7001215219497681
Mean training loss eporch  998 :  0.8417330850999822
Loss at iteration 50 : 0.8591430187225342
Loss at iteration 100 : 0.6464493274688721
Loss at iteration 150 : 0.8895645141601562
Loss at iteration 200 : 1.0101194381713867
Loss at iteration 250 : 0.6793521046638489
Loss at iteration 300 : 0.5891283750534058
Loss at iteration 350 : 0.7183725833892822
Mean training loss eporch  999 :  0.8421095862748131
Min training loss at epoch  962 :  0.840402285100291
